{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps with Amazon SageMaker: Getting Started\n",
    "\n",
    "> *This notebook works well with the `Python 3 (Data Science)` kernel on SageMaker Studio*\n",
    "\n",
    "Welcome to this short workshop on MLOps with Amazon SageMaker!\n",
    "\n",
    "First we'll install a couple of useful packages for later, in case they're not already available in the kernel environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting altair\n",
      "  Downloading altair-4.1.0-py3-none-any.whl (727 kB)\n",
      "\u001b[K     |████████████████████████████████| 727 kB 11.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from altair) (0.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from altair) (2.11.1)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.7/site-packages (from altair) (0.10.0)\n",
      "Requirement already satisfied: pandas>=0.18 in /opt/conda/lib/python3.7/site-packages (from altair) (1.0.1)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.7/site-packages (from altair) (3.2.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from altair) (1.18.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->altair) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.18->altair) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.18->altair) (2019.3)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from jsonschema->altair) (1.5.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema->altair) (0.15.7)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema->altair) (19.3.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema->altair) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from jsonschema->altair) (45.2.0.post20200210)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema->altair) (2.2.0)\n",
      "Installing collected packages: altair\n",
      "Successfully installed altair-4.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install altair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locating our project environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<util.project.ProjectSession(\n",
       "  project_id=creditmodel,\n",
       "  role=arn:aws:iam::024103970757:role/mlopsintro-SageMakerExecutionRole-1CERTWL51GJ97,\n",
       "  raw_bucket=creditmodel-mlrawdata-024103970757-ap-northeast-1,\n",
       "  sandbox_bucket=creditmodel-mlsandbox-024103970757-ap-northeast-1\n",
       ") at 0x7f02f823b310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import util\n",
    "\n",
    "project_id = \"creditmodel\"\n",
    "\n",
    "project_config = util.project.init(project_id)\n",
    "project_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data bucket: s3://creditmodel-mlrawdata-024103970757-ap-northeast-1/\n",
      "Sandbox bucket: s3://creditmodel-mlsandbox-024103970757-ap-northeast-1/\n"
     ]
    }
   ],
   "source": [
    "print(f\"Raw data bucket: s3://{project_config.raw_bucket}/\")\n",
    "print(f\"Sandbox bucket: s3://{project_config.sandbox_bucket}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data with SageMaker Data Wrangler\n",
    "\n",
    "- Open `credit-data.flow`\n",
    "- Build the flow\n",
    "- Export the final node to the feature store?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an initial model with SageMaker XGBoost Algorithm\n",
    "\n",
    "- Query the feature store to realise separate training/val/test sets?\n",
    "- XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap-northeast-1\n"
     ]
    }
   ],
   "source": [
    "# Python Built-Ins:\n",
    "\n",
    "# External Dependencies:\n",
    "import sagemaker\n",
    "\n",
    "smsess = sagemaker.Session()\n",
    "region = smsess.boto_region_name\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354813040037.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3\n"
     ]
    }
   ],
   "source": [
    "training_image = sagemaker.image_uris.retrieve(\"xgboost\", region=region, version=\"1.0-1\")\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data s3://creditmodel-mlsandbox-024103970757-ap-northeast-1/???\n",
      "Validation data: s3://creditmodel-mlsandbox-024103970757-ap-northeast-1/???\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace '???' with the path where you saved your training file in S3\n",
    "train_uri = f\"s3://{project_config.sandbox_bucket}/???\"\n",
    "print(f\"Training data: {train_uri}\")\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(train_uri, content_type=\"csv\")\n",
    "\n",
    "# TODO: Replace '???' with the path where you saved your training file in S3\n",
    "val_uri = f\"s3://{project_config.sandbox_bucket}/???\"\n",
    "print(f\"Validation data: {val_uri}\")\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(val_uri, content_type=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an XGBoost estimator object\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=training_image,  # XGBoost algorithm container\n",
    "    instance_type=\"ml.m5.xlarge\",  # type of training instance\n",
    "    instance_count=1,  # number of instances to be used\n",
    "    role=sgmk_role,  # IAM role to be used\n",
    "    max_run=20*60,  # Maximum allowed active runtime\n",
    "    use_spot_instances=True,  # Use spot instances to reduce cost\n",
    "    max_wait=30*60,  # Maximum clock time (including spot delays)\n",
    ")\n",
    "\n",
    "# define its hyperparameters\n",
    "estimator.set_hyperparameters(\n",
    "    num_round=150,  # int: [1,300]\n",
    "    max_depth=5,  # int: [1,10]\n",
    "    alpha=2.5,  # float: [0,5]\n",
    "    eta=0.5,  # float: [0,1]\n",
    "    objective=\"binary:logistic\",\n",
    ")\n",
    "\n",
    "# start a training (fitting) job\n",
    "estimator.fit({ \"train\": s3_input_train, \"validation\": s3_input_validation })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model with SageMaker Batch Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = estimator.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    output_path=f\"s3://{project_config.sandbox_bucket}/batch-results/\",\n",
    ")\n",
    "\n",
    "# calls that object's transform method to create a transform job\n",
    "transformer.transform(\n",
    "    data=s3_batch_input,\n",
    "    data_type=\"S3Prefix\",\n",
    "    content_type=\"text/csv\",\n",
    "    split_type=\"Line\",\n",
    ")\n",
    "\n",
    "# wait=True by default right? Or transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plotting.generate_classification_report(\n",
    "    y_real=,\n",
    "    y_predict_proba=, \n",
    "    decision_threshold=0.5,\n",
    "    class_names_list=[...],\n",
    "    title=\"Initial model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-1:102112518831:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
