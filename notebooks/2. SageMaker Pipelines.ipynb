{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing the Build/Train/Deploy MLOps Project Template\n",
    "\n",
    "At Re:Invent 2020, AWS announced [Amazon SageMaker Pipelines](https://aws.amazon.com/sagemaker/pipelines/): the first \n",
    "purpose-built, easy-to-use Continuous Integration and Continuous Delivery (CI/CD) service for machine learning. \n",
    "SageMaker Pipelines has three main components which improves the operational resilience and reproducibility of your \n",
    "workflows: Pipelines, Model Registry, and Projects. \n",
    "\n",
    "SageMaker Projects introduce MLOps templates that automatically provision the underlying resources needed to enable \n",
    "CI/CD capabilities for your Machine Learning Development Lifecycle (MLDC). Customers can use a number of built-in \n",
    "templates or create your own custom templates.\n",
    "\n",
    "This example will focus on using one of the MLOps templates to bootstrap your ML project and establish a CI/CD \n",
    "pattern from seed code. We’ll show how to use the built-in Build/Train/Deploy Project template as a base for a \n",
    "customer churn classification example. This base template will enable CI/CD for training machine learning models, \n",
    "registering model artifacts to the Model Registry, and automating model deployment with manual approval and automated \n",
    "testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the MLOps template for build, train, and deploy\n",
    "\n",
    "We will package what whe did in the previous session as an automated pipeline (data processing, model training, model evaluation and model deployment). Our starting point will be the output of the Data Wrangler job we defined previously.\n",
    "\n",
    "We’ll start by taking a detailed look at what AWS services are launched when this build, train, deploy MLOps template \n",
    "is launched. Later, we’ll discuss how the skeleton can be modified for a custom use case. \n",
    "\n",
    "To get started with SageMaker Projects, [they must be first enabled in the SageMaker Studio console](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-projects-studio-updates.html). \n",
    "This can be done for existing users or while creating new ones:\n",
    "\n",
    "<img src=\"img/enable_projects.png\">\n",
    "\n",
    "Within Amazon SageMaker Studio, you can now select “Projects” from a drop-down menu on the “Components and registries” \n",
    "tab as shown below:\n",
    "\n",
    "<img src=\"img/select_projects.png\">\n",
    "\n",
    "From the projects page you’ll have the option to launch a pre-configured SageMaker MLOps template. We'll select the build, train and deploy template:\n",
    "\n",
    "<img src=\"img/create_project.png\">\n",
    "\n",
    "> **NOTE:** Launching this template will kick off a model building pipeline by default and will train a regression model. This will incur a small cost.\n",
    "\n",
    "Once the project is created from the MLOps template, the following architecture will be deployed:\n",
    "\n",
    "<img src=\"img/deep_dive.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the seed code for our custom use case\n",
    "\n",
    "The SageMaker-provided template has initialized with seed code for a generic demo use case (the Abalone dataset).\n",
    "\n",
    "Once the project has been created, you'll be able to see:\n",
    "\n",
    "- The visualization of the SageMaker Pipeline from the \"Pipelines\" drop down menu within SageMaker Studio\n",
    "- CI/CD pipelines in [AWS CodePipeline](https://console.aws.amazon.com/codesuite/codepipeline/pipelines) defining the overall process flow, within which the SageMaker Pipeline execution is one step.\n",
    "\n",
    "In order to modify the seed code from this launched template to match our own (credit default) example, we’ll first need to clone the AWS CodeCommit repositories to our local SageMaker Studio instance.\n",
    "\n",
    "▶️ **Select** the SageMaker Project that was just created from the list of projects. \n",
    "\n",
    "▶️ **Clone both** the AWS CodeCommit repositories to your notebook, by clicking the hyperlinks in the “Repositories” tab of the project.\n",
    "\n",
    "▶️ **Copy** the `Repository local path` from the dialog for each repo and paste it into the cell below.\n",
    "\n",
    "<img src=\"img/clone_repos.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_build_repo_local_path = \"\"  # TODO: Update\n",
    "model_deploy_repo_local_path = \"\"  # TODO: Update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelBuild Repo\n",
    "\n",
    "The “ModelBuild” repository contains the code for preprocessing, training, and evaluating the model. \n",
    "\n",
    "<img src=\"img/repo_directory.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, we'll rename the `abalone` directory to `credit_default`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(model_build_repo_abs_path):\n",
    "    raise ValueError(\n",
    "        \"Couldn't find repository at {}. Did you clone the repo and update the cell?\".format(\n",
    "            model_build_repo_abs_path,\n",
    "        )\n",
    "    )\n",
    "\n",
    "if os.path.isdir(f\"{model_build_repo_abs_path}/pipelines/abalone\"):\n",
    "    os.rename(\n",
    "        f\"{model_build_repo_abs_path}/pipelines/abalone\",\n",
    "        f\"{model_build_repo_abs_path}/pipelines/credit_default\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll update the `codebuild-buildspec.yml` (which defines the commands run to define and execute the SageMaker Pipeline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_build_repo_abs_path = f\"/root/{model_build_repo_local_path}\"\n",
    "\n",
    "with open(f\"{model_build_repo_abs_path}/codebuild-buildspec.yml\", \"r\") as f:\n",
    "    newspec = f.read().replace(\"abalone\", \"credit_default\")\n",
    "\n",
    "with open(f\"{model_build_repo_abs_path}/codebuild-buildspec.yml\", \"w\") as f:\n",
    "    f.write(newspec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we'll overwrite the project's pipeline definition with modified files this local folder.\n",
    "\n",
    "First though, you'll need to manually update one of the files with the specific location of our project's data from the last notebook - as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r flow_output_s3uri\n",
    "print(flow_output_s3uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "▶️ **Open** `modelbuild/pipelines/pipeline.py` from this notebook's folder\n",
    "\n",
    "▶️ **Edit** the `default_value` of the *InputDataUrl parameter* to match the S3 URI above. The final result will look something like:\n",
    "\n",
    "```python\n",
    "    input_data = ParameterString(\n",
    "        name=\"InputDataUrl\",\n",
    "        default_value=f\"s3://creditmodel-myname-mlsandbox/data-wrangler/credit-flow-2048-01-01/.../default/\",  # Change this to point to the s3 location of your raw input data.\n",
    "    )\n",
    "```\n",
    "\n",
    "▶️ **Confirm** that you've done it by editing the cell below to continue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_UPDATED_THE_INPUT_DATA_URL_DEFAULT_VALUE = False\n",
    "\n",
    "if not I_UPDATED_THE_INPUT_DATA_URL_DEFAULT_VALUE:\n",
    "    raise ValueError(\n",
    "        \"Follow the instructions above to edit pipeline.py and then confirm here to continue!\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now be ready to run the below to copy the modified files into your local copy of the model-build repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for item in os.listdir(\"modelbuild/pipelines/credit_default\"):\n",
    "    their_item_path = f\"{model_build_repo_abs_path}/pipelines/credit_default/{item}\"\n",
    "    if os.path.isdir(their_item_path):\n",
    "        shutil.rmtree(their_item_path)\n",
    "    elif os.path.isfile(their_item_path):\n",
    "        os.remove(their_item_path)\n",
    "\n",
    "    our_item_path = f\"modelbuild/pipelines/credit_default/{item}\"\n",
    "    if os.path.isdir(our_item_path):\n",
    "        shutil.copytree(our_item_path, their_item_path)\n",
    "    else:\n",
    "        shutil.copyfile(our_item_path, their_item_path)\n",
    "    print(f\"Copied {our_item_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigger a new Pipeline execution through git commit\n",
    "\n",
    "In the previous section we updated your local copy of the model build repository - but didn't yet commit and push these changes to source control.\n",
    "\n",
    "By committing and pushing these changes to the AWS CodeCommit repository, a new pipeline execution will be triggered ([via Amazon EventBridge](https://docs.aws.amazon.com/codecommit/latest/userguide/monitoring-events.html))\n",
    "\n",
    "▶️ **Navigate** to your local copy of the `modelbuild` repository using the folder tab in SageMaker Studio, then **switch** to the source control tab as shown before (to see git status for the correct repository).\n",
    "\n",
    "▶️ **Stage**, **Commit** and **push** the changes as shown below:\n",
    "\n",
    "<img src=\"img/git_push.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few moments, a new execution of the SageMaker pipeline will be triggered and we can monitor the execution by selecting your Pipeline inside of the SageMaker Project:\n",
    "\n",
    "<img src=\"img/execute_pipeline.png\">\n",
    "\n",
    "<img src=\"img/dag.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the registered model\n",
    "\n",
    "When the pipeline above completes, you'll have a trained and evaluated model stored in the SageMaker Model Registry (refer to the \"Model groups\" section in the SageMaker Studio Components & Registries tab).\n",
    "\n",
    "However, before we approve the model to trigger deployment, we'll also customize the deployment infrastructure.\n",
    "\n",
    "### Customizing the deployment infrastructure\n",
    "\n",
    "We'd like to enable data capture on our deployed endpoints, but will need to configure a location in Amazon S3.\n",
    "\n",
    "▶️ **Run** the cell below to generate a data capture URI using the default SageMaker bucket, and **copy** the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "data_capture_s3uri = f\"s3://{sagemaker.Session().default_bucket()}/mlopsdemo/capture\"\n",
    "data_capture_s3uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "▶️ **Edit** the `modeldeploy/endpoint-config-template.yml` file to set the DestinationS3Uri for data capture to the value above\n",
    "\n",
    "When you're done, update the below to confirm and run the cell to copy this file to your local copy of the ModelDeploy repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_UPDATED_THE_DATA_CAPTURE_URI = True\n",
    "\n",
    "if not I_UPDATED_THE_DATA_CAPTURE_URI:\n",
    "    raise ValueError(\n",
    "        \"Follow the instructions above to edit endpoint-config-template.yml and then confirm here to continue!\"\n",
    "    )\n",
    "\n",
    "\n",
    "shutil.copyfile(\n",
    "    \"modeldeploy/endpoint-config-template.yml\",\n",
    "    f\"/root/{model_deploy_repo_local_path}/endpoint-config-template.yml\"\n",
    ")\n",
    "print(f\"Copied modeldeploy/endpoint-config-template.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "▶️ **Commit and push** your change to the `modeldeploy` repository like we previously did for the `modelbuild` repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approving the model\n",
    "\n",
    "Although pushing the change should trigger the ModelDeploy CodePipeline already, we'll also need to **approve the model** which will re-trigger again and actually enable deployment.\n",
    "\n",
    "▶️ **Open** the “Model groups” section in the SageMaker Studio UI and inspect the metadata attached to the model artifacts. From there, approve the model for deployment:\n",
    "\n",
    "<img src=\"img/model_metrics.png\">\n",
    "\n",
    "<img src=\"img/approve_model.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approval will trigger the ModelDeploy [CodePipeline](https://console.aws.amazon.com/codesuite/codepipeline/pipelines) and create a `staging` endpoint for real time inference.\n",
    "\n",
    "After verifying the endpoint, you can approve *promotion* of the model via the ***ModelDeploy CodePipeline***, to trigger deployment of a `prod` endpoint as well:\n",
    "\n",
    "<img src=\"img/endpoints.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigger a new Pipeline Execution through SDK\n",
    "\n",
    "Alternatively you can also retrieve and execute an existing pipeline through the sagemaker SDK. The template created a \n",
    "file `get_pipeline` which you can use to trigger an execution in your own notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "```\n",
    "# This is the module name or the path to your pipeline.py file.\n",
    "from pipelines.customer_churn.pipeline import get_pipeline\n",
    "\n",
    "model_package_group_name = f\"CustomerChurnPackageGroup\"\n",
    "pipeline_name = f\"CustomerChurnDemo-p-ewf8t7lvhivm\"\n",
    "\n",
    "\n",
    "# These variables were defined the IAM role.\n",
    "pipeline = get_pipeline(\n",
    "    region=region,\n",
    "    role=role,\n",
    "    default_bucket=default_bucket,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    pipeline_name=pipeline_name,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Submit the pipeline to SageMaker and start execution\n",
    "\n",
    "Let's submit our pipeline definition to the workflow service. The role passed in will be used by the workflow service to create all the jobs defined in the steps.\n",
    "\n",
    "```\n",
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline.start()\n",
    "\n",
    "execution.describe()\n",
    "execution.wait()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Parametrized Executions\n",
    "\n",
    "We can run additional executions of the pipeline specifying different pipeline parameters. The parameters argument is a \n",
    "dictionary whose names are the parameter names, and whose values are the primitive values to use as overrides of the defaults.\n",
    "\n",
    "Of particular note, based on the performance of the model, we may want to kick off another pipeline execution, but this \n",
    "time on a compute-optimized instance type and set the model approval status automatically be \"Approved\". This means \n",
    "that the model package version generated by the `RegisterModel` step will automatically be ready for deployment through \n",
    "CI/CD pipelines, such as with SageMaker Projects.\n",
    "\n",
    "```\n",
    "# Note: You can change the ModelApprovalStatus to \"PendingManualApproval\". This is the default set in the pipeline.py file.\n",
    "\n",
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        ProcessingInstanceType=\"ml.c5.xlarge\",\n",
    "        ModelApprovalStatus=\"Approved\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "execution.wait()\n",
    "execution.list_steps()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time inference\n",
    "\n",
    "Once the staging endpoint is deployed, we can query it for real-time inference requests using the same data we did for batch transform testing in notebook 1.\n",
    "\n",
    "First, we'll re-load the data from the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r test_result_df\n",
    "\n",
    "# Optionally drop any fields that might have snuck in but shouldn't be there:\n",
    "test_result_df = test_result_df.drop(columns=[\"credit_default_staging\"], errors=\"ignore\")\n",
    "# Drop the previous testing results:\n",
    "input_df = test_result_df.drop(columns=[\"credit_default\", \"credit_default_pred\"])\n",
    "\n",
    "# Create an alternative *biased* set by selecting only defaulted records:\n",
    "skewed_df = test_result_df[\n",
    "    test_result_df[\"credit_default\"] == 1\n",
    "].drop(columns=[\"credit_default\", \"credit_default_pred\"])\n",
    "\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conveniently send data through the endpoint from Python, we can use the `Predictor` class from the high-level SageMaker Python SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_staging = sagemaker.predictor.Predictor(\n",
    "    \"mlopsdemo-staging\",  # Replace with your 'endpoint name' from above\n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    deserializer=sagemaker.deserializers.CSVDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this Predictor, we can send the records to the endpoint one by one (or in manageable batches) - and then plot a classification accuracy report similarly to notebook 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_results = [\n",
    "    # df.iterrows messes up data types. First element of a itertuple row is index\n",
    "    # Returns a 2D array of 1 string element, so we take [0][0]\n",
    "    float(predictor_staging.predict(rowtuple[1:])[0][0])\n",
    "    for rowtuple in input_df.itertuples()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "\n",
    "output_df = test_result_df.copy()\n",
    "output_df[\"credit_default_staging\"] = staging_results\n",
    "\n",
    "util.plotting.generate_classification_report(\n",
    "    y_real=output_df[\"credit_default\"],\n",
    "    y_predict_proba=output_df[\"credit_default_staging\"],\n",
    "    decision_threshold=0.5,\n",
    "    class_names_list=[\"good\", \"default\"],\n",
    "    title=\"Staging pipeline credit risk model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data drift monitoring\n",
    "\n",
    "Because our endpoint has data capture enabled, you'll be able to configure *Data Quality Monitoring* via the SageMaker Studio UI.\n",
    "\n",
    "First, we need a representative **baseline dataset** which future captured data will be compared to.\n",
    "\n",
    "While we could use the training data for this, the training data has a very unrealistic distribution of output variables (ground truth values '1' or '0') as compared to real inference data (where a floating point score e.g. '0.23' would be output).\n",
    "\n",
    "It is possible to baseline from live capture data, but for this example let's create and upload a simple CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = input_df.copy()\n",
    "baseline_df[\"credit_default\"] = staging_results\n",
    "baseline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_baseline_s3uri = f\"s3://{sagemaker.Session().default_bucket()}/mlopsdemo/data-drift-baseline/baseline.csv\"\n",
    "\n",
    "baseline_df.to_csv(drift_baseline_s3uri, index=False)\n",
    "print(f\"Uploaded baseline file to {drift_baseline_s3uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "▶️ **Open** your `staging` endpoint from the *Endpoints* view in SageMaker Studio and click \"Create monitoring schedule\" for data quality:\n",
    "\n",
    "![](img/create_monitoring_schedule.png \"Screenshot of SMStudio Create Model Monitoring option\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "▶️ **Configure** the schedule as follows:\n",
    "\n",
    "- Set *Schedule Expression* to `hourly`\n",
    "- Set *S3 Output Configuration* S3 bucket name and prefix as per output of the following notebook cell\n",
    "- Set *Baseline dataset S3 location* bucket name and prefix as per the below\n",
    "- Set *Baseline S3 output location* bucket name and prefix as per the below\n",
    "- Leave other parameters as default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_output_s3uri = f\"s3://{sagemaker.Session().default_bucket()}/mlopsdemo/data-drift\"\n",
    "print(f\"S3 Output Configuration:\\n{drift_output_s3uri}\\n\")\n",
    "\n",
    "print(f\"Baseline dataset S3 location:\\n{drift_baseline_s3uri}\\n\")\n",
    "\n",
    "drift_baseline_output_s3uri = f\"s3://{sagemaker.Session().default_bucket()}/mlopsdemo/data-drift-baseline/output\"\n",
    "print(f\"Baseline S3 Output:\\n{drift_baseline_output_s3uri}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once monitoring is enabled on your endpoint, reports will be generated every hour: With generation kicked off between 0 and 20 minutes after the hour.\n",
    "\n",
    "To explore the results you can:\n",
    "\n",
    "▶️ **In the initial hour's window**, repeat the \"Real time inference\" steps above to generate normal traffic to the endpoint\n",
    "\n",
    "▶️ **In the next hour's window**, use code like the below to generate biased data using only a sample of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(20):\n",
    "    skewed_results = [\n",
    "        # df.iterrows messes up data types. First element of a itertuple row is index\n",
    "        # Returns a 2D array of 1 string element, so we take [0][0]\n",
    "        float(predictor_staging.predict(rowtuple[1:])[0][0])\n",
    "        for rowtuple in skewed_df.itertuples()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The monitoring results can be viewed from the Endpoint's detail page in SageMaker Studio."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
