{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps with Amazon SageMaker: Getting Started\n",
    "\n",
    "> *This notebook works well with the `Python 3 (Data Science)` kernel on SageMaker Studio*\n",
    "\n",
    "Welcome to this short workshop on MLOps with Amazon SageMaker!\n",
    "\n",
    "First we'll install a couple of useful packages for later, in case they're not already available in the kernel environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting altair\n",
      "  Downloading altair-4.1.0-py3-none-any.whl (727 kB)\n",
      "\u001b[K     |████████████████████████████████| 727 kB 41.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: toolz in /opt/conda/lib/python3.7/site-packages (from altair) (0.10.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.7/site-packages (from altair) (3.2.0)\n",
      "Requirement already satisfied: pandas>=0.18 in /opt/conda/lib/python3.7/site-packages (from altair) (1.0.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from altair) (2.11.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from altair) (0.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from altair) (1.18.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from jsonschema->altair) (1.5.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema->altair) (19.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from jsonschema->altair) (45.2.0.post20200210)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema->altair) (0.15.7)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema->altair) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.18->altair) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.18->altair) (2019.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->altair) (1.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema->altair) (2.2.0)\n",
      "Installing collected packages: altair\n",
      "Successfully installed altair-4.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install altair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locating our project environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<util.project.ProjectSession(\n",
       "  project_id=creditmodel,\n",
       "  role=arn:aws:iam::024103970757:role/mlopsintro-SageMakerExecutionRole-TK3Y6YQI58VH,\n",
       "  raw_bucket=creditmodel-mlrawdata-024103970757-ap-northeast-1,\n",
       "  sandbox_bucket=creditmodel-mlsandbox-024103970757-ap-northeast-1\n",
       ") at 0x7f1ad8a83850>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import util\n",
    "\n",
    "project_id = \"creditmodel\"  # TODO: Change this if you set a different Project ID in service catalog!\n",
    "\n",
    "project_config = util.project.init(project_id)\n",
    "project_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data bucket: s3://creditmodel-mlrawdata-024103970757-ap-northeast-1/\n",
      "Sandbox bucket: s3://creditmodel-mlsandbox-024103970757-ap-northeast-1/\n"
     ]
    }
   ],
   "source": [
    "print(f\"Raw data bucket: s3://{project_config.raw_bucket}/\")\n",
    "print(f\"Sandbox bucket: s3://{project_config.sandbox_bucket}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data with SageMaker Data Wrangler\n",
    "\n",
    "### Create the data flow\n",
    "\n",
    "(Old initial quick model got to 0.708 F1 before we ran ordinal encodes)\n",
    "\n",
    "(Goes down to 0.692 raw after change to mapping and up to 0.703 after all ordinals, before any one-hots)\n",
    "\n",
    "- Open `credit-data.flow`\n",
    "- Select the input CSV from the raw data bucket as source\n",
    "- Create analysis: `missing.py`\n",
    "- Create analysis: Initial quick model\n",
    "- `credit_risk` strings to int(bool) and move to front `cast(credit_risk == \"bad\" as int)`, move `credit_default` to start, drop `credit_risk`\n",
    "- (Unguided) do same for `telephone` -> `has_telephone` and `foreign_worker` -> `is_foreign_worker` (no need to bring to front)\n",
    "- `checking_acct_status` extract `\\d+` to get the band number, fill with 0 for \"no account\" -> `checking_acct_band`\n",
    "- (Unguided) do same for `savings_status` -> `savings_band` and `highest_property` -> `highest_property_band` (doesn't need filling)\n",
    "- Split `marital_status_and_gender` on ` : `\n",
    "    - 'Matches' for male -> gender_is_male\n",
    "    - Do we need to cast this gender field?\n",
    "    - Split on ` : ` up to 2 splits\n",
    "    - Extract second one to `marital_status_text` text field\n",
    "    - *Featurize Text > Vectorize* with custom tokenizer on regex `/`, no IDF, output as `marital_status` columns (not vector)\n",
    "    - Drop `marital_status_text`\n",
    "- One-hot the `purpose` field\n",
    "- Either one-hot or custom encode these fields:\n",
    "    - `other_parties`? (none / co-applicant / guarantor)\n",
    "    - `other_installment_plans` (bank / stores / none)\n",
    "    - `housing` (rent / own / for free)\n",
    "\n",
    "Train-Test Split (Custom SQL steps):\n",
    "- `random(1337)` as `random_01`\n",
    "- `row_number() over (partition by credit_default order by random_01)` as `stratum_row_num`\n",
    "- `max(stratum_row_num) over (partition by credit_default)` as `stratum_size`\n",
    "- `stratum_row_num / stratum_size` as `stratum_rank_pct`\n",
    "- `case when (stratum_rank_pct < 0.7) then \"train\" when (stratum_rank_pct < 0.85) then \"validation\" else \"test\" end` as `dataset`\n",
    "\n",
    "Wrapping up:\n",
    "- Create target leakage report\n",
    "\n",
    "Extension:\n",
    "- `credit_amount` logscale via `log10(credit_amount)`?\n",
    "\n",
    "\n",
    "Finally:\n",
    "- Export the final node to the feature store?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_uri = # TODO: Get from the example notebook\n",
    "target_output_name = # TODO: Get from 'output_name' in the example notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap-northeast-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "smsess = sagemaker.Session()\n",
    "region = smsess.boto_region_name\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = sagemaker.Processor(\n",
    "    role=sagemaker.get_execution_role(),  # Just use the current notebook's IAM role\n",
    "    image_uri=container_uri,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Processing job with name credit-flow-2021-03-12-03-14-57\n",
      "Uploading flow file to s3://creditmodel-mlsandbox-024103970757-ap-northeast-1/data-wrangler/credit-flow-2021-03-12-03-14-57/flow/credit-data.flow\n",
      "Storing results to s3://creditmodel-mlsandbox-024103970757-ap-northeast-1/data-wrangler/credit-flow-2021-03-10-14-52-24/006869ca-e5fe-4c4d-b290-c1fe8127513b/default/\n",
      "Uploaded credit-data.flow to s3://creditmodel-mlsandbox-024103970757-ap-northeast-1/data-wrangler/credit-flow-2021-03-12-03-14-57/flow/credit-data.flow\n",
      "\n",
      "Job Name:  credit-flow-2021-03-12-03-14-57\n",
      "Inputs:  [{'InputName': 'flow', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://creditmodel-mlsandbox-024103970757-ap-northeast-1/data-wrangler/credit-flow-2021-03-12-03-14-57/flow/credit-data.flow', 'LocalPath': '/opt/ml/processing/flow', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'german.csv', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://creditmodel-mlrawdata-024103970757-ap-northeast-1/german.csv', 'LocalPath': '/opt/ml/processing/german.csv', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'e4adff78-b977-4b75-b975-ef25e26f348f.default', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://creditmodel-mlsandbox-024103970757-ap-northeast-1/data-wrangler', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "..............................\u001b[34mSPARK_HOME=/usr/lib/spark\u001b[0m\n",
      "\u001b[34mHOSTNAME=ip-10-0-174-129.ap-northeast-1.compute.internal\u001b[0m\n",
      "\u001b[34mNB_USER=sagemaker-user\u001b[0m\n",
      "\u001b[34mSHELL=/bin/bash\u001b[0m\n",
      "\u001b[34mHADOOP_HOME=/usr/lib/hadoop\u001b[0m\n",
      "\u001b[34mYARN_RESOURCEMANAGER_USER=root\u001b[0m\n",
      "\u001b[34mAWS_CONTAINER_CREDENTIALS_RELATIVE_URI=/v2/credentials/yxZebBd-GjwktwGs2YWIfnReDURPX3pesJqpEzrCGg8\u001b[0m\n",
      "\u001b[34mPYTHONUNBUFFERED=1\u001b[0m\n",
      "\u001b[34mLC_ALL=en_US.UTF-8\u001b[0m\n",
      "\u001b[34mPYTHONIOENCODING=UTF-8\u001b[0m\n",
      "\u001b[34mPYSPARK_PYTHON=/usr/bin/python3\u001b[0m\n",
      "\u001b[34mSPARK_NO_DAEMONIZE=TRUE\u001b[0m\n",
      "\u001b[34mYARN_NODEMANAGER_USER=root\u001b[0m\n",
      "\u001b[34mHDFS_NAMENODE_USER=root\u001b[0m\n",
      "\u001b[34mPYTHONHASHSEED=0\u001b[0m\n",
      "\u001b[34mPATH=/usr/bin:/opt/program:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\u001b[0m\n",
      "\u001b[34mHDFS_SECONDARYNAMENODE_USER=root\u001b[0m\n",
      "\u001b[34mPWD=/home/sagemaker-user\u001b[0m\n",
      "\u001b[34mLANG=en_US.UTF-8\u001b[0m\n",
      "\u001b[34mHADOOP_CONF_DIR=/usr/lib/hadoop/etc/hadoop\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG_FILE=/opt/ml/config/resourceconfig.json\u001b[0m\n",
      "\u001b[34mAWS_REGION=ap-northeast-1\u001b[0m\n",
      "\u001b[34mAWS_METADATA_SERVICE_TIMEOUT=3\u001b[0m\n",
      "\u001b[34mPYTHONDONTWRITEBYTECODE=1\u001b[0m\n",
      "\u001b[34mHDFS_DATANODE_USER=root\u001b[0m\n",
      "\u001b[34mSHLVL=1\u001b[0m\n",
      "\u001b[34mAWS_METADATA_SERVICE_NUM_ATTEMPTS=3\u001b[0m\n",
      "\u001b[34mHOME=/home/sagemaker-user\u001b[0m\n",
      "\u001b[34mLANGUAGE=en_US.UTF-8\u001b[0m\n",
      "\u001b[34mSM_PROCESSING_CONFIG_FILE=/opt/ml/config/processingjobconfig.json\u001b[0m\n",
      "\u001b[34mPIP_DISABLE_PIP_VERSION_CHECK=1\u001b[0m\n",
      "\u001b[34mHDFS_PORT=8020\u001b[0m\n",
      "\u001b[34mNB_GID=100\u001b[0m\n",
      "\u001b[34mNB_UID=1000\u001b[0m\n",
      "\u001b[34m_=/usr/bin/printenv\u001b[0m\n",
      "\u001b[34mStarting DataPrep Container in Processing Job Mode\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark.cli  INFO     Parsing arguments. argv: ['/usr/local/bin/smspark-submit', '/entrypoint/processing_entrypoint.py', '--output-config', '{\"e4adff78-b977-4b75-b975-ef25e26f348f.default\": {\"content_type\": \"CSV\"}}']\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark.cli  INFO     Raw spark options before processing: {'class_': None, 'jars': None, 'py_files': None, 'files': None, 'verbose': False}\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark.cli  INFO     App and app arguments: ['/entrypoint/processing_entrypoint.py', '--output-config', '{\"e4adff78-b977-4b75-b975-ef25e26f348f.default\": {\"content_type\": \"CSV\"}}']\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark.cli  INFO     Rendered spark options: {'class_': None, 'jars': None, 'py_files': None, 'files': None, 'verbose': False}\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark.cli  INFO     Initializing processing job.\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     {'current_host': 'algo-1', 'hosts': ['algo-1']}\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     {'ProcessingJobArn': 'arn:aws:sagemaker:ap-northeast-1:024103970757:processing-job/credit-flow-2021-03-12-03-14-57', 'ProcessingJobName': 'credit-flow-2021-03-12-03-14-57', 'AppSpecification': {'ImageUri': '649008135260.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-data-wrangler-container:1.3.0', 'ContainerEntrypoint': None, 'ContainerArguments': ['--output-config \\'{\"e4adff78-b977-4b75-b975-ef25e26f348f.default\": {\"content_type\": \"CSV\"}}\\'']}, 'ProcessingInputs': [{'InputName': 'flow', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/flow', 'S3Uri': 's3://creditmodel-mlsandbox-024103970757-ap-northeast-1/data-wrangler/credit-flow-2021-03-12-03-14-57/flow/credit-data.flow', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinition': None}, {'InputName': 'german.csv', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/german.csv', 'S3Uri': 's3://creditmodel-mlrawdata-024103970757-ap-northeast-1/german.csv', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinition': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'e4adff78-b977-4b75-b975-ef25e26f348f.default', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://creditmodel-mlsandbox-024103970757-ap-northeast-1/data-wrangler', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.4xlarge', 'VolumeSizeInGB': 30, 'VolumeKmsKeyId': None}}, 'RoleArn': 'arn:aws:iam::024103970757:role/mlopsintro-SageMakerExecutionRole-TK3Y6YQI58VH', 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}}\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark.cli  INFO     running spark submit command: spark-submit --master yarn --deploy-mode client /entrypoint/processing_entrypoint.py --output-config '{\"e4adff78-b977-4b75-b975-ef25e26f348f.default\": {\"content_type\": \"CSV\"}}'\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     waiting for hosts\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     starting status server\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     Status server listening on algo-1:5555\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     bootstrapping cluster\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     transitioning from status INITIALIZING to BOOTSTRAPPING\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     copying aws jars\u001b[0m\n",
      "\u001b[34mServing on http://algo-1:5555\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     Found hadoop jar hadoop-aws.jar\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     Optional jar jets3t-0.9.0.jar in /usr/lib/hadoop/lib does not exist\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     copying cluster config\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     copying /opt/hadoop-config/hdfs-site.xml to /usr/lib/hadoop/etc/hadoop/hdfs-site.xml\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     copying /opt/hadoop-config/core-site.xml to /usr/lib/hadoop/etc/hadoop/core-site.xml\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     copying /opt/hadoop-config/yarn-site.xml to /usr/lib/hadoop/etc/hadoop/yarn-site.xml\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     copying /opt/hadoop-config/spark-defaults.conf to /usr/lib/spark/conf/spark-defaults.conf\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     copying /opt/hadoop-config/spark-env.sh to /usr/lib/spark/conf/spark-env.sh\u001b[0m\n",
      "\u001b[34m03-12 03:19 root         INFO     Detected instance type: m5.4xlarge with total memory: 65536M and total cores: 16\u001b[0m\n",
      "\u001b[34m03-12 03:19 root         INFO     Writing default config to /usr/lib/hadoop/etc/hadoop/yarn-site.xml\u001b[0m\n",
      "\u001b[34m03-12 03:19 root         INFO     Configuration at /usr/lib/hadoop/etc/hadoop/yarn-site.xml is: \u001b[0m\n",
      "\u001b[34m<?xml version=\"1.0\"?>\u001b[0m\n",
      "\u001b[34m<!-- Site specific YARN configuration properties -->\n",
      " <configuration>\n",
      "     <property>\n",
      "         <name>yarn.resourcemanager.hostname</name>\n",
      "         <value>10.0.174.129</value>\n",
      "         <description>The hostname of the RM.</description>\n",
      "     </property>\n",
      "     <property>\n",
      "         <name>yarn.nodemanager.hostname</name>\n",
      "         <value>algo-1</value>\n",
      "         <description>The hostname of the NM.</description>\n",
      "     </property>\n",
      "     <property>\n",
      "         <name>yarn.nodemanager.webapp.address</name>\n",
      "         <value>algo-1:8042</value>\n",
      "     </property>\n",
      "     <property>\n",
      "         <name>yarn.nodemanager.vmem-pmem-ratio</name>\n",
      "         <value>5</value>\n",
      "         <description>Ratio between virtual memory to physical memory.</description>\n",
      "     </property>\n",
      "     <property>\n",
      "         <name>yarn.resourcemanager.am.max-attempts</name>\n",
      "         <value>1</value>\n",
      "         <description>The maximum number of application attempts.</description>\n",
      "     </property>\n",
      "     <property>\n",
      "         <name>yarn.nodemanager.env-whitelist</name>\n",
      "         <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,YARN_HOME,AWS_CONTAINER_CREDENTIALS_RELATIVE_URI</value>\n",
      "         <description>Environment variable whitelist</description>\n",
      "     </property>\n",
      "\n",
      " \n",
      "  <property>\n",
      "    <name>yarn.scheduler.minimum-allocation-mb</name>\n",
      "    <value>1</value>\n",
      "  </property>\n",
      "  <property>\n",
      "    <name>yarn.scheduler.maximum-allocation-mb</name>\n",
      "    <value>63569</value>\n",
      "  </property>\n",
      "  <property>\n",
      "    <name>yarn.scheduler.minimum-allocation-vcores</name>\n",
      "    <value>1</value>\n",
      "  </property>\n",
      "  <property>\n",
      "    <name>yarn.scheduler.maximum-allocation-vcores</name>\n",
      "    <value>16</value>\n",
      "  </property>\n",
      "  <property>\n",
      "    <name>yarn.nodemanager.resource.memory-mb</name>\n",
      "    <value>63569</value>\n",
      "  </property>\n",
      "  <property>\n",
      "    <name>yarn.nodemanager.resource.cpu-vcores</name>\n",
      "    <value>16</value>\n",
      "  </property>\u001b[0m\n",
      "\u001b[34m</configuration>\n",
      "\u001b[0m\n",
      "\u001b[34m03-12 03:19 root         INFO     Writing default config to /usr/lib/spark/conf/spark-defaults.conf\u001b[0m\n",
      "\u001b[34m03-12 03:19 root         INFO     Configuration at /usr/lib/spark/conf/spark-defaults.conf is: \u001b[0m\n",
      "\u001b[34mspark.driver.extraClassPath      /usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar\u001b[0m\n",
      "\u001b[34mspark.driver.extraLibraryPath    /usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native\u001b[0m\n",
      "\u001b[34mspark.executor.extraClassPath    /usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar\u001b[0m\n",
      "\u001b[34mspark.executor.extraLibraryPath  /usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native\u001b[0m\n",
      "\u001b[34mspark.driver.host=10.0.174.129\u001b[0m\n",
      "\u001b[34mspark.hadoop.mapreduce.fileoutputcommitter.algorithm.version=2\u001b[0m\n",
      "\u001b[34mspark.driver.memory 2048m\u001b[0m\n",
      "\u001b[34mspark.driver.memoryOverhead 204m\u001b[0m\n",
      "\u001b[34mspark.driver.defaultJavaOptions -XX:OnOutOfMemoryError='kill -9 %p' -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:MaxHeapFreeRatio=70 -XX:+CMSClassUnloadingEnabled\u001b[0m\n",
      "\u001b[34mspark.executor.memory 55742m\u001b[0m\n",
      "\u001b[34mspark.executor.memoryOverhead 5574m\u001b[0m\n",
      "\u001b[34mspark.executor.cores 16\u001b[0m\n",
      "\u001b[34mspark.executor.defaultJavaOptions -verbose:gc -XX:OnOutOfMemoryError='kill -9 %p' -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+UseParallelGC -XX:InitiatingHeapOccupancyPercent=70 -XX:ConcGCThreads=4 -XX:ParallelGCThreads=12 \u001b[0m\n",
      "\u001b[34mspark.executor.instances 1\u001b[0m\n",
      "\u001b[34mspark.default.parallelism 32\n",
      "\u001b[0m\n",
      "\u001b[34m03-12 03:19 root         INFO     Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[34m03-12 03:19 root         INFO     No file at /opt/ml/processing/input/conf/configuration.json exists, skipping user configuration\u001b[0m\n",
      "\u001b[34mWARNING: /usr/lib/hadoop/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,044 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.174.129\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.2.1-amzn-1\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/lib/hadoop/etc/hadoop:/usr/lib/hadoop/lib/jersey-json-1.19.jar:/usr/lib/hadoop/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop/lib/jsch-0.1.54.jar:/usr/lib/hadoop/lib/token-provider-1.0.1.jar:/usr/lib/hadoop/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop/lib/jackson-core-2.10.0.jar:/usr/lib/hadoop/lib/httpclient-4.5.9.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop/lib/jackson-annotations-2.10.0.jar:/usr/lib/hadoop/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-codec-1.11.jar:/usr/lib/hadoop/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop/lib/re2j-1.1.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.25.jar:/usr/lib/hadoop/lib/json-smart-2.3.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop/lib/commons-lang3-3.7.jar:/usr/lib/hadoop/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/avro-1.7.7.jar:/usr/lib/hadoop/lib/commons-io-2.5.jar:/usr/lib/hadoop/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop/lib/asm-5.0.4.jar:/usr/lib/hadoop/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop/lib/curator-client-2.13.0.jar:/usr/lib/hadoop/lib/commons-text-1.4.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/jersey-server-1.19.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/commons-compress-1.18.jar:/usr/lib/hadoop/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop/lib/commons-net-3.6.jar:/usr/lib/hadoop/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/jersey-core-1.19.jar:/usr/lib/hadoop/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/httpcore-4.4.11.jar:/usr/lib/hadoop/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop/lib/jackson-databind-2.10.0.jar:/usr/lib/hadoop/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop/lib/accessors-smart-1.2.jar:/usr/lib/hadoop/lib/jul-to-slf4j-1.7.25.jar:/usr/lib/hadoop/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//hadoop-archives.jar:/usr/lib/hadoop/.//hadoop-gridmix.jar:/usr/lib/hadoop/.//hadoop-archive-logs-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-datajoin-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-fs2img.jar:/usr/lib/hadoop/.//hadoop-kms.jar:/usr/lib/hadoop/.//hadoop-fs2img-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-resourceestimator-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-aliyun.jar:/usr/lib/hadoop/.//hadoop-auth-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-resourceestimator.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-datajoin.jar:/usr/lib/hadoop/.//hadoop-openstack.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-nfs-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-openstack-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-distcp-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-streaming-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-azure-datalake-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-aliyun-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-extras.jar:/usr/lib/hadoop/.//hadoop-distcp.jar:/usr/lib/hadoop/.//hadoop-kafka.jar:/usr/lib/hadoop/.//hadoop-extras-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-rumen.jar:/usr/lib/hadoop/.//hadoop-streaming.jar:/usr/lib/hadoop/.//hadoop-rumen-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-archive-logs.jar:/usr/lib/hadoop/.//hadoop-azure-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-azure-datalake.jar:/usr/lib/hadoop/.//hadoop-annotations-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-sls.jar:/usr/lib/hadoop/.//hadoop-azure.jar:/usr/lib/hadoop/.//hadoop-kms-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-sls-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-archives-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-kafka-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-aws-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-gridmix-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/jersey-json-1.19.jar:/usr/lib/hadoop-hdfs/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/okhttp-2.7.5.jar:/usr/lib/hadoop-hdfs/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop-hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop-hdfs/lib/jsch-0.1.54.jar:/usr/lib/hadoop-hdfs/lib/token-provider-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-2.10.0.jar:/usr/lib/hadoop-hdfs/lib/httpclient-4.5.9.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-annotations-2.10.0.jar:/usr/lib/hadoop-hdfs/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.11.jar:/usr/lib/hadoop-hdfs/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/re2j-1.1.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/json-smart-2.3.jar:/usr/lib/hadoop-hdfs/lib/json-simple-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/paranamer-2.3.jar:/usr/lib/hadoop-hdfs/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop-hdfs/lib/gson-2.2.4.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.52.Final.jar:/usr/lib/hadoop-hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop-hdfs/lib/commons-lang3-3.7.jar:/usr/lib/hadoop-hdfs/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop-hdfs/lib/avro-1.7.7.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.5.jar:/usr/lib/hadoop-hdfs/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop-hdfs/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/asm-5.0.4.jar:/usr/lib/hadoop-hdfs/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop-hdfs/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/curator-client-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/commons-text-1.4.jar:/usr/lib/hadoop-hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.19.jar:/usr/lib/hadoop-hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop-hdfs/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/commons-compress-1.18.jar:/usr/lib/hadoop-hdfs/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop-hdfs/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-net-3.6.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop-hdfs/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-hdfs/lib/jettison-1.1.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop-hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.19.jar:/usr/lib/hadoop-hdfs/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/okio-1.6.0.jar:/usr/lib/hadoop-hdfs/lib/httpcore-4.4.11.jar:/usr/lib/hadoop-hdfs/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop-hdfs/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-databind-2.10.0.jar:/usr/lib/hadoop-hdfs/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/accessors-smart-1.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ecs-4.2.0.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-sts-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-sdk-oss-3.4.1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-core-3.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//wildfly-openssl-1.0.7.Final.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//jdom-1.1.jar:/usr/lib/hadoop-mapreduce/.//ojalgo-43.0.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-7.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//kafka-clients-2.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ram-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//aws-java-sdk-bundle-1.11.828.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//azure-keyvault-core-1.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//zstd-jni-1.4.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//lz4-java-1.6.0.jar:/usr/lib/hadoop-mapreduce/.//azure-data-lake-store-sdk-2.2.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.19.jar:/usr/lib/hadoop-yarn/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop-yarn/lib/objenesis-1.0.jar:/usr/lib/hadoop-yarn/lib/json-io-2.5.1.jar:/usr/lib/hadoop-yarn/lib/ehcache-3.3.1.jar:/usr/lib/hadoop-yarn/lib/HikariCP-java7-2.4.12.jar:/usr/lib/hadoop-yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-4.0.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-base-2.10.0.jar:/usr/lib/hadoop-yarn/lib/jackson-module-jaxb-annotations-2.10.0.jar:/usr/lib/hadoop-yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/usr/lib/hadoop-yarn/lib/fst-2.50.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-json-provider-2.10.0.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/guice-4.0.jar:/usr/lib/hadoop-yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.19.jar:/usr/lib/hadoop-yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/bcprov-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/java-util-1.9.0.jar:/usr/lib/hadoop-yarn/lib/jakarta.activation-api-1.2.1.jar:/usr/lib/hadoop-yarn/lib/snakeyaml-1.16.jar:/usr/lib/hadoop-yarn/lib/swagger-annotations-1.5.4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-\u001b[0m\n",
      "\u001b[34m3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = git@aws157git.com:/pkg/Aws157BigTop -r 520b97ed429ab8eb7a8d30068b0f34a8036c51a7; compiled by 'ec2-user' on 2020-07-30T08:02Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_272\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,051 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,105 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-80619f6d-ab67-46b9-8fd5-f0e5a460883f\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,446 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,458 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,459 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,460 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,464 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,464 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,464 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,464 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,507 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,519 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,519 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,523 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,523 INFO blockmanagement.BlockManager: The block deletion will start around 2021 Mar 12 03:19:50\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,525 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,525 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,526 INFO util.GSet: 2.0% max memory 13.7 GB = 280.3 MB\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,526 INFO util.GSet: capacity      = 2^25 = 33554432 entries\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,607 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,607 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,613 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,613 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,613 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,613 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,614 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,614 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,614 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,614 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,614 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,614 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,614 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,636 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,636 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,636 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,636 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,648 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,648 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,649 INFO util.GSet: 1.0% max memory 13.7 GB = 140.1 MB\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,649 INFO util.GSet: capacity      = 2^24 = 16777216 entries\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,686 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,686 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,686 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,686 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,691 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,693 INFO snapshot.SnapshotManager: SkipList is disabled\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,697 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,697 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,697 INFO util.GSet: 0.25% max memory 13.7 GB = 35.0 MB\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,697 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,714 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,714 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,714 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,717 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,718 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,719 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,719 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,719 INFO util.GSet: 0.029999999329447746% max memory 13.7 GB = 4.2 MB\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,719 INFO util.GSet: capacity      = 2^19 = 524288 entries\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,748 INFO namenode.FSImage: Allocated new BlockPoolId: BP-2026770010-10.0.174.129-1615519190741\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,763 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,787 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,894 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:50,902 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:51,035 INFO namenode.FSImage: FSImageSaver clean checkpoint: txid=0 when meet shutdown.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:51,035 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.0.174.129\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     waiting for cluster to be up\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:51,591 INFO nodemanager.NodeManager: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NodeManager\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.174.129\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = []\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.2.1-amzn-1\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/lib/hadoop/etc/hadoop:/usr/lib/hadoop/lib/jersey-json-1.19.jar:/usr/lib/hadoop/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop/lib/jsch-0.1.54.jar:/usr/lib/hadoop/lib/token-provider-1.0.1.jar:/usr/lib/hadoop/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop/lib/jackson-core-2.10.0.jar:/usr/lib/hadoop/lib/httpclient-4.5.9.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop/lib/jackson-annotations-2.10.0.jar:/usr/lib/hadoop/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-codec-1.11.jar:/usr/lib/hadoop/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop/lib/re2j-1.1.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.25.jar:/usr/lib/hadoop/lib/json-smart-2.3.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop/lib/commons-lang3-3.7.jar:/usr/lib/hadoop/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/avro-1.7.7.jar:/usr/lib/hadoop/lib/commons-io-2.5.jar:/usr/lib/hadoop/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop/lib/asm-5.0.4.jar:/usr/lib/hadoop/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop/lib/curator-client-2.13.0.jar:/usr/lib/hadoop/lib/commons-text-1.4.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/jersey-server-1.19.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/commons-compress-1.18.jar:/usr/lib/hadoop/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop/lib/commons-net-3.6.jar:/usr/lib/hadoop/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/jersey-core-1.19.jar:/usr/lib/hadoop/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/httpcore-4.4.11.jar:/usr/lib/hadoop/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop/lib/jackson-databind-2.10.0.jar:/usr/lib/hadoop/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop/lib/accessors-smart-1.2.jar:/usr/lib/hadoop/lib/jul-to-slf4j-1.7.25.jar:/usr/lib/hadoop/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//hadoop-archives.jar:/usr/lib/hadoop/.//hadoop-gridmix.jar:/usr/lib/hadoop/.//hadoop-archive-logs-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-datajoin-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-fs2img.jar:/usr/lib/hadoop/.//hadoop-kms.jar:/usr/lib/hadoop/.//hadoop-fs2img-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-resourceestimator-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-aliyun.jar:/usr/lib/hadoop/.//hadoop-auth-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-resourceestimator.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-datajoin.jar:/usr/lib/hadoop/.//hadoop-openstack.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-nfs-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-openstack-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-distcp-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-streaming-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-azure-datalake-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-aliyun-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-extras.jar:/usr/lib/hadoop/.//hadoop-distcp.jar:/usr/lib/hadoop/.//hadoop-kafka.jar:/usr/lib/hadoop/.//hadoop-extras-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-rumen.jar:/usr/lib/hadoop/.//hadoop-streaming.jar:/usr/lib/hadoop/.//hadoop-rumen-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-archive-logs.jar:/usr/lib/hadoop/.//hadoop-azure-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-azure-datalake.jar:/usr/lib/hadoop/.//hadoop-annotations-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-sls.jar:/usr/lib/hadoop/.//hadoop-azure.jar:/usr/lib/hadoop/.//hadoop-kms-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-sls-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-archives-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-kafka-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-aws-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-gridmix-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/jersey-json-1.19.jar:/usr/lib/hadoop-hdfs/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/okhttp-2.7.5.jar:/usr/lib/hadoop-hdfs/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop-hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop-hdfs/lib/jsch-0.1.54.jar:/usr/lib/hadoop-hdfs/lib/token-provider-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-2.10.0.jar:/usr/lib/hadoop-hdfs/lib/httpclient-4.5.9.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-annotations-2.10.0.jar:/usr/lib/hadoop-hdfs/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.11.jar:/usr/lib/hadoop-hdfs/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/re2j-1.1.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/json-smart-2.3.jar:/usr/lib/hadoop-hdfs/lib/json-simple-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/paranamer-2.3.jar:/usr/lib/hadoop-hdfs/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop-hdfs/lib/gson-2.2.4.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.52.Final.jar:/usr/lib/hadoop-hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop-hdfs/lib/commons-lang3-3.7.jar:/usr/lib/hadoop-hdfs/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop-hdfs/lib/avro-1.7.7.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.5.jar:/usr/lib/hadoop-hdfs/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop-hdfs/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/asm-5.0.4.jar:/usr/lib/hadoop-hdfs/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop-hdfs/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/curator-client-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/commons-text-1.4.jar:/usr/lib/hadoop-hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.19.jar:/usr/lib/hadoop-hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop-hdfs/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/commons-compress-1.18.jar:/usr/lib/hadoop-hdfs/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop-hdfs/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-net-3.6.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop-hdfs/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-hdfs/lib/jettison-1.1.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop-hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.19.jar:/usr/lib/hadoop-hdfs/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/okio-1.6.0.jar:/usr/lib/hadoop-hdfs/lib/httpcore-4.4.11.jar:/usr/lib/hadoop-hdfs/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop-hdfs/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-databind-2.10.0.jar:/usr/lib/hadoop-hdfs/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/accessors-smart-1.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ecs-4.2.0.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-sts-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-sdk-oss-3.4.1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-core-3.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//wildfly-openssl-1.0.7.Final.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//jdom-1.1.jar:/usr/lib/hadoop-mapreduce/.//ojalgo-43.0.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-7.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//kafka-clients-2.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ram-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//aws-java-sdk-bundle-1.11.828.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//azure-keyvault-core-1.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//zstd-jni-1.4.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//lz4-java-1.6.0.jar:/usr/lib/hadoop-mapreduce/.//azure-data-lake-store-sdk-2.2.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.19.jar:/usr/lib/hadoop-yarn/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop-yarn/lib/objenesis-1.0.jar:/usr/lib/hadoop-yarn/lib/json-io-2.5.1.jar:/usr/lib/hadoop-yarn/lib/ehcache-3.3.1.jar:/usr/lib/hadoop-yarn/lib/HikariCP-java7-2.4.12.jar:/usr/lib/hadoop-yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-4.0.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-base-2.10.0.jar:/usr/lib/hadoop-yarn/lib/jackson-module-jaxb-annotations-2.10.0.jar:/usr/lib/hadoop-yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/usr/lib/hadoop-yarn/lib/fst-2.50.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-json-provider-2.10.0.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/guice-4.0.jar:/usr/lib/hadoop-yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.19.jar:/usr/lib/hadoop-yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/bcprov-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/java-util-1.9.0.jar:/usr/lib/hadoop-yarn/lib/jakarta.activation-api-1.2.1.jar:/usr/lib/hadoop-yarn/lib/snakeyaml-1.16.jar:/usr/lib/hadoop-yarn/lib/swagger-annotations-1.5.4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-\u001b[0m\n",
      "\u001b[34m3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-annotations-1.2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-client-1.2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/commons-csv-1.0.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/jcodings-1.0.13.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-protocol-1.2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/metrics-core-2.2.0.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-common-1.2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/joni-2.1.2.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = git@aws157git.com:/pkg/Aws157BigTop -r 520b97ed429ab8eb7a8d30068b0f34a8036c51a7; compiled by 'ec2-user' on 2020-07-30T08:02Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_272\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:51,601 INFO nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:51,611 INFO resourcemanager.ResourceManager: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting ResourceManager\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.174.129\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = []\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.2.1-amzn-1\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/lib/hadoop/etc/hadoop:/usr/lib/hadoop/lib/jersey-json-1.19.jar:/usr/lib/hadoop/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop/lib/jsch-0.1.54.jar:/usr/lib/hadoop/lib/token-provider-1.0.1.jar:/usr/lib/hadoop/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop/lib/jackson-core-2.10.0.jar:/usr/lib/hadoop/lib/httpclient-4.5.9.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop/lib/jackson-annotations-2.10.0.jar:/usr/lib/hadoop/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-codec-1.11.jar:/usr/lib/hadoop/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop/lib/re2j-1.1.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.25.jar:/usr/lib/hadoop/lib/json-smart-2.3.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop/lib/commons-lang3-3.7.jar:/usr/lib/hadoop/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/avro-1.7.7.jar:/usr/lib/hadoop/lib/commons-io-2.5.jar:/usr/lib/hadoop/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop/lib/asm-5.0.4.jar:/usr/lib/hadoop/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop/lib/curator-client-2.13.0.jar:/usr/lib/hadoop/lib/commons-text-1.4.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/jersey-server-1.19.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/commons-compress-1.18.jar:/usr/lib/hadoop/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop/lib/commons-net-3.6.jar:/usr/lib/hadoop/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/jersey-core-1.19.jar:/usr/lib/hadoop/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/httpcore-4.4.11.jar:/usr/lib/hadoop/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop/lib/jackson-databind-2.10.0.jar:/usr/lib/hadoop/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop/lib/accessors-smart-1.2.jar:/usr/lib/hadoop/lib/jul-to-slf4j-1.7.25.jar:/usr/lib/hadoop/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//hadoop-archives.jar:/usr/lib/hadoop/.//hadoop-gridmix.jar:/usr/lib/hadoop/.//hadoop-archive-logs-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-datajoin-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-fs2img.jar:/usr/lib/hadoop/.//hadoop-kms.jar:/usr/lib/hadoop/.//hadoop-fs2img-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-resourceestimator-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-aliyun.jar:/usr/lib/hadoop/.//hadoop-auth-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-resourceestimator.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-datajoin.jar:/usr/lib/hadoop/.//hadoop-openstack.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-nfs-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-openstack-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-distcp-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-streaming-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-azure-datalake-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-aliyun-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-extras.jar:/usr/lib/hadoop/.//hadoop-distcp.jar:/usr/lib/hadoop/.//hadoop-kafka.jar:/usr/lib/hadoop/.//hadoop-extras-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-rumen.jar:/usr/lib/hadoop/.//hadoop-streaming.jar:/usr/lib/hadoop/.//hadoop-rumen-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-archive-logs.jar:/usr/lib/hadoop/.//hadoop-azure-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-azure-datalake.jar:/usr/lib/hadoop/.//hadoop-annotations-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-sls.jar:/usr/lib/hadoop/.//hadoop-azure.jar:/usr/lib/hadoop/.//hadoop-kms-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-sls-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-archives-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-kafka-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-aws-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-gridmix-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/jersey-json-1.19.jar:/usr/lib/hadoop-hdfs/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/okhttp-2.7.5.jar:/usr/lib/hadoop-hdfs/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop-hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop-hdfs/lib/jsch-0.1.54.jar:/usr/lib/hadoop-hdfs/lib/token-provider-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-2.10.0.jar:/usr/lib/hadoop-hdfs/lib/httpclient-4.5.9.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-annotations-2.10.0.jar:/usr/lib/hadoop-hdfs/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.11.jar:/usr/lib/hadoop-hdfs/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/re2j-1.1.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/json-smart-2.3.jar:/usr/lib/hadoop-hdfs/lib/json-simple-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/paranamer-2.3.jar:/usr/lib/hadoop-hdfs/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop-hdfs/lib/gson-2.2.4.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.52.Final.jar:/usr/lib/hadoop-hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop-hdfs/lib/commons-lang3-3.7.jar:/usr/lib/hadoop-hdfs/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop-hdfs/lib/avro-1.7.7.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.5.jar:/usr/lib/hadoop-hdfs/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop-hdfs/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/asm-5.0.4.jar:/usr/lib/hadoop-hdfs/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop-hdfs/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/curator-client-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/commons-text-1.4.jar:/usr/lib/hadoop-hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.19.jar:/usr/lib/hadoop-hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop-hdfs/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/commons-compress-1.18.jar:/usr/lib/hadoop-hdfs/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop-hdfs/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-net-3.6.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop-hdfs/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-hdfs/lib/jettison-1.1.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop-hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.19.jar:/usr/lib/hadoop-hdfs/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/okio-1.6.0.jar:/usr/lib/hadoop-hdfs/lib/httpcore-4.4.11.jar:/usr/lib/hadoop-hdfs/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop-hdfs/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-databind-2.10.0.jar:/usr/lib/hadoop-hdfs/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/accessors-smart-1.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ecs-4.2.0.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-sts-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-sdk-oss-3.4.1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-core-3.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//wildfly-openssl-1.0.7.Final.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//jdom-1.1.jar:/usr/lib/hadoop-mapreduce/.//ojalgo-43.0.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-7.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//kafka-clients-2.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ram-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//aws-java-sdk-bundle-1.11.828.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//azure-keyvault-core-1.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//zstd-jni-1.4.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//lz4-java-1.6.0.jar:/usr/lib/hadoop-mapreduce/.//azure-data-lake-store-sdk-2.2.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.19.jar:/usr/lib/hadoop-yarn/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop-yarn/lib/objenesis-1.0.jar:/usr/lib/hadoop-yarn/lib/json-io-2.5.1.jar:/usr/lib/hadoop-yarn/lib/ehcache-3.3.1.jar:/usr/lib/hadoop-yarn/lib/HikariCP-java7-2.4.12.jar:/usr/lib/hadoop-yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-4.0.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-base-2.10.0.jar:/usr/lib/hadoop-yarn/lib/jackson-module-jaxb-annotations-2.10.0.jar:/usr/lib/hadoop-yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/usr/lib/hadoop-yarn/lib/fst-2.50.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-json-provider-2.10.0.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/guice-4.0.jar:/usr/lib/hadoop-yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.19.jar:/usr/lib/hadoop-yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/bcprov-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/java-util-1.9.0.jar:/usr/lib/hadoop-yarn/lib/jakarta.activation-api-1.2.1.jar:/usr/lib/hadoop-yarn/lib/snakeyaml-1.16.jar:/usr/lib/hadoop-yarn/lib/swagger-annotations-1.5.4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-\u001b[0m\n",
      "\u001b[34m3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-annotations-1.2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-client-1.2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/commons-csv-1.0.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/jcodings-1.0.13.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-protocol-1.2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/metrics-core-2.2.0.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/hbase-common-1.2.6.jar:/usr/lib/hadoop-yarn/.//timelineservice/lib/joni-2.1.2.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = git@aws157git.com:/pkg/Aws157BigTop -r 520b97ed429ab8eb7a8d30068b0f34a8036c51a7; compiled by 'ec2-user' on 2020-07-30T08:02Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_272\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:51,622 INFO resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:51,655 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.174.129\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = []\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.2.1-amzn-1\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/lib/hadoop/etc/hadoop:/usr/lib/hadoop/lib/jersey-json-1.19.jar:/usr/lib/hadoop/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop/lib/jsch-0.1.54.jar:/usr/lib/hadoop/lib/token-provider-1.0.1.jar:/usr/lib/hadoop/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop/lib/jackson-core-2.10.0.jar:/usr/lib/hadoop/lib/httpclient-4.5.9.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop/lib/jackson-annotations-2.10.0.jar:/usr/lib/hadoop/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-codec-1.11.jar:/usr/lib/hadoop/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop/lib/re2j-1.1.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.25.jar:/usr/lib/hadoop/lib/json-smart-2.3.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop/lib/commons-lang3-3.7.jar:/usr/lib/hadoop/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/avro-1.7.7.jar:/usr/lib/hadoop/lib/commons-io-2.5.jar:/usr/lib/hadoop/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop/lib/asm-5.0.4.jar:/usr/lib/hadoop/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop/lib/curator-client-2.13.0.jar:/usr/lib/hadoop/lib/commons-text-1.4.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/jersey-server-1.19.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/commons-compress-1.18.jar:/usr/lib/hadoop/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop/lib/commons-net-3.6.jar:/usr/lib/hadoop/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/jersey-core-1.19.jar:/usr/lib/hadoop/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/httpcore-4.4.11.jar:/usr/lib/hadoop/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop/lib/jackson-databind-2.10.0.jar:/usr/lib/hadoop/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop/lib/accessors-smart-1.2.jar:/usr/lib/hadoop/lib/jul-to-slf4j-1.7.25.jar:/usr/lib/hadoop/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//hadoop-archives.jar:/usr/lib/hadoop/.//hadoop-gridmix.jar:/usr/lib/hadoop/.//hadoop-archive-logs-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-datajoin-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-fs2img.jar:/usr/lib/hadoop/.//hadoop-kms.jar:/usr/lib/hadoop/.//hadoop-fs2img-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-resourceestimator-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-aliyun.jar:/usr/lib/hadoop/.//hadoop-auth-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-resourceestimator.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-datajoin.jar:/usr/lib/hadoop/.//hadoop-openstack.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-nfs-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-openstack-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-distcp-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-streaming-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-azure-datalake-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-aliyun-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-extras.jar:/usr/lib/hadoop/.//hadoop-distcp.jar:/usr/lib/hadoop/.//hadoop-kafka.jar:/usr/lib/hadoop/.//hadoop-extras-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-rumen.jar:/usr/lib/hadoop/.//hadoop-streaming.jar:/usr/lib/hadoop/.//hadoop-rumen-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-archive-logs.jar:/usr/lib/hadoop/.//hadoop-azure-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-azure-datalake.jar:/usr/lib/hadoop/.//hadoop-annotations-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-sls.jar:/usr/lib/hadoop/.//hadoop-azure.jar:/usr/lib/hadoop/.//hadoop-kms-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-sls-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-archives-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-kafka-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-aws-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-gridmix-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/jersey-json-1.19.jar:/usr/lib/hadoop-hdfs/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/okhttp-2.7.5.jar:/usr/lib/hadoop-hdfs/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop-hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop-hdfs/lib/jsch-0.1.54.jar:/usr/lib/hadoop-hdfs/lib/token-provider-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-2.10.0.jar:/usr/lib/hadoop-hdfs/lib/httpclient-4.5.9.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-annotations-2.10.0.jar:/usr/lib/hadoop-hdfs/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.11.jar:/usr/lib/hadoop-hdfs/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/re2j-1.1.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/json-smart-2.3.jar:/usr/lib/hadoop-hdfs/lib/json-simple-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/paranamer-2.3.jar:/usr/lib/hadoop-hdfs/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop-hdfs/lib/gson-2.2.4.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.52.Final.jar:/usr/lib/hadoop-hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop-hdfs/lib/commons-lang3-3.7.jar:/usr/lib/hadoop-hdfs/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop-hdfs/lib/avro-1.7.7.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.5.jar:/usr/lib/hadoop-hdfs/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop-hdfs/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/asm-5.0.4.jar:/usr/lib/hadoop-hdfs/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop-hdfs/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/curator-client-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/commons-text-1.4.jar:/usr/lib/hadoop-hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.19.jar:/usr/lib/hadoop-hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop-hdfs/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/commons-compress-1.18.jar:/usr/lib/hadoop-hdfs/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop-hdfs/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-net-3.6.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop-hdfs/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-hdfs/lib/jettison-1.1.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop-hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.19.jar:/usr/lib/hadoop-hdfs/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/okio-1.6.0.jar:/usr/lib/hadoop-hdfs/lib/httpcore-4.4.11.jar:/usr/lib/hadoop-hdfs/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop-hdfs/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-databind-2.10.0.jar:/usr/lib/hadoop-hdfs/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/accessors-smart-1.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ecs-4.2.0.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-sts-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-sdk-oss-3.4.1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-core-3.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//wildfly-openssl-1.0.7.Final.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//jdom-1.1.jar:/usr/lib/hadoop-mapreduce/.//ojalgo-43.0.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-7.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//kafka-clients-2.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ram-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//aws-java-sdk-bundle-1.11.828.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//azure-keyvault-core-1.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//zstd-jni-1.4.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//lz4-java-1.6.0.jar:/usr/lib/hadoop-mapreduce/.//azure-data-lake-store-sdk-2.2.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.19.jar:/usr/lib/hadoop-yarn/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop-yarn/lib/objenesis-1.0.jar:/usr/lib/hadoop-yarn/lib/json-io-2.5.1.jar:/usr/lib/hadoop-yarn/lib/ehcache-3.3.1.jar:/usr/lib/hadoop-yarn/lib/HikariCP-java7-2.4.12.jar:/usr/lib/hadoop-yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-4.0.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-base-2.10.0.jar:/usr/lib/hadoop-yarn/lib/jackson-module-jaxb-annotations-2.10.0.jar:/usr/lib/hadoop-yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/usr/lib/hadoop-yarn/lib/fst-2.50.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-json-provider-2.10.0.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/guice-4.0.jar:/usr/lib/hadoop-yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.19.jar:/usr/lib/hadoop-yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/bcprov-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/java-util-1.9.0.jar:/usr/lib/hadoop-yarn/lib/jakarta.activation-api-1.2.1.jar:/usr/lib/hadoop-yarn/lib/snakeyaml-1.16.jar:/usr/lib/hadoop-yarn/lib/swagger-annotations-1.5.4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-\u001b[0m\n",
      "\u001b[34m3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = git@aws157git.com:/pkg/Aws157BigTop -r 520b97ed429ab8eb7a8d30068b0f34a8036c51a7; compiled by 'ec2-user' on 2020-07-30T08:02Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_272\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:51,657 INFO datanode.DataNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting DataNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.174.129\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = []\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.2.1-amzn-1\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/lib/hadoop/etc/hadoop:/usr/lib/hadoop/lib/jersey-json-1.19.jar:/usr/lib/hadoop/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop/lib/jsch-0.1.54.jar:/usr/lib/hadoop/lib/token-provider-1.0.1.jar:/usr/lib/hadoop/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop/lib/jackson-core-2.10.0.jar:/usr/lib/hadoop/lib/httpclient-4.5.9.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop/lib/jackson-annotations-2.10.0.jar:/usr/lib/hadoop/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-codec-1.11.jar:/usr/lib/hadoop/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop/lib/re2j-1.1.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.25.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.25.jar:/usr/lib/hadoop/lib/json-smart-2.3.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop/lib/commons-lang3-3.7.jar:/usr/lib/hadoop/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/avro-1.7.7.jar:/usr/lib/hadoop/lib/commons-io-2.5.jar:/usr/lib/hadoop/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop/lib/asm-5.0.4.jar:/usr/lib/hadoop/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop/lib/curator-client-2.13.0.jar:/usr/lib/hadoop/lib/commons-text-1.4.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/jersey-server-1.19.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/commons-compress-1.18.jar:/usr/lib/hadoop/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop/lib/commons-net-3.6.jar:/usr/lib/hadoop/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/jersey-core-1.19.jar:/usr/lib/hadoop/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop/lib/httpcore-4.4.11.jar:/usr/lib/hadoop/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop/lib/jackson-databind-2.10.0.jar:/usr/lib/hadoop/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop/lib/accessors-smart-1.2.jar:/usr/lib/hadoop/lib/jul-to-slf4j-1.7.25.jar:/usr/lib/hadoop/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//hadoop-archives.jar:/usr/lib/hadoop/.//hadoop-gridmix.jar:/usr/lib/hadoop/.//hadoop-archive-logs-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-datajoin-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-fs2img.jar:/usr/lib/hadoop/.//hadoop-kms.jar:/usr/lib/hadoop/.//hadoop-fs2img-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-resourceestimator-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-aliyun.jar:/usr/lib/hadoop/.//hadoop-auth-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-resourceestimator.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-datajoin.jar:/usr/lib/hadoop/.//hadoop-openstack.jar:/usr/lib/hadoop/.//hadoop-common-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-nfs-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-openstack-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-distcp-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-streaming-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-azure-datalake-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-aliyun-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//hadoop-extras.jar:/usr/lib/hadoop/.//hadoop-distcp.jar:/usr/lib/hadoop/.//hadoop-kafka.jar:/usr/lib/hadoop/.//hadoop-extras-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-rumen.jar:/usr/lib/hadoop/.//hadoop-streaming.jar:/usr/lib/hadoop/.//hadoop-rumen-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-archive-logs.jar:/usr/lib/hadoop/.//hadoop-azure-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-azure-datalake.jar:/usr/lib/hadoop/.//hadoop-annotations-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-sls.jar:/usr/lib/hadoop/.//hadoop-azure.jar:/usr/lib/hadoop/.//hadoop-kms-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-sls-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-archives-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-kafka-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-aws-3.2.1-amzn-1.jar:/usr/lib/hadoop/.//hadoop-gridmix-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/jersey-json-1.19.jar:/usr/lib/hadoop-hdfs/lib/jetty-io-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/kerb-client-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/okhttp-2.7.5.jar:/usr/lib/hadoop-hdfs/lib/snappy-java-1.1.7.3.jar:/usr/lib/hadoop-hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/lib/hadoop-hdfs/lib/jsch-0.1.54.jar:/usr/lib/hadoop-hdfs/lib/token-provider-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jersey-servlet-1.19.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-2.10.0.jar:/usr/lib/hadoop-hdfs/lib/httpclient-4.5.9.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/kerby-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-annotations-2.10.0.jar:/usr/lib/hadoop-hdfs/lib/jetty-security-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.11.jar:/usr/lib/hadoop-hdfs/lib/commons-configuration2-2.1.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-asn1-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/curator-recipes-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/kerby-pkix-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/re2j-1.1.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/json-smart-2.3.jar:/usr/lib/hadoop-hdfs/lib/json-simple-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/paranamer-2.3.jar:/usr/lib/hadoop-hdfs/lib/commons-beanutils-1.9.3.jar:/usr/lib/hadoop-hdfs/lib/gson-2.2.4.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.52.Final.jar:/usr/lib/hadoop-hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/lib/hadoop-hdfs/lib/commons-lang3-3.7.jar:/usr/lib/hadoop-hdfs/lib/jetty-server-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop-hdfs/lib/avro-1.7.7.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.5.jar:/usr/lib/hadoop-hdfs/lib/stax2-api-3.1.4.jar:/usr/lib/hadoop-hdfs/lib/curator-framework-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/asm-5.0.4.jar:/usr/lib/hadoop-hdfs/lib/jcip-annotations-1.0-1.jar:/usr/lib/hadoop-hdfs/lib/jsr311-api-1.1.1.jar:/usr/lib/hadoop-hdfs/lib/curator-client-2.13.0.jar:/usr/lib/hadoop-hdfs/lib/commons-text-1.4.jar:/usr/lib/hadoop-hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.19.jar:/usr/lib/hadoop-hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/dnsjava-2.1.7.jar:/usr/lib/hadoop-hdfs/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/commons-compress-1.18.jar:/usr/lib/hadoop-hdfs/lib/zookeeper-3.4.14.jar:/usr/lib/hadoop-hdfs/lib/kerb-core-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-net-3.6.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/kerb-admin-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/kerb-util-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/woodstox-core-5.0.3.jar:/usr/lib/hadoop-hdfs/lib/kerb-common-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-hdfs/lib/jettison-1.1.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/kerb-identity-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jaxb-api-2.2.11.jar:/usr/lib/hadoop-hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.19.jar:/usr/lib/hadoop-hdfs/lib/kerby-xdr-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/kerby-config-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jetty-http-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/lib/okio-1.6.0.jar:/usr/lib/hadoop-hdfs/lib/httpcore-4.4.11.jar:/usr/lib/hadoop-hdfs/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop-hdfs/lib/kerb-server-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/jackson-databind-2.10.0.jar:/usr/lib/hadoop-hdfs/lib/netty-3.10.5.Final.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/kerb-crypto-1.0.1.jar:/usr/lib/hadoop-hdfs/lib/accessors-smart-1.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-9.4.20.v20190813.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-rbf-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-client-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-httpfs-3.2.1-amzn-1.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-native-client.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ecs-4.2.0.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-sts-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img.jar:/usr/lib/hadoop-mapreduce/.//hadoop-fs2img-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-sdk-oss-3.4.1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-core-3.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun.jar:/usr/lib/hadoop-mapreduce/.//hadoop-resourceestimator.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-uploader.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//wildfly-openssl-1.0.7.Final.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//jdom-1.1.jar:/usr/lib/hadoop-mapreduce/.//ojalgo-43.0.jar:/usr/lib/hadoop-mapreduce/.//azure-storage-7.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-openstack-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aliyun-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//kafka-clients-2.4.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//aliyun-java-sdk-ram-3.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archive-logs.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-datalake.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//aws-java-sdk-bundle-1.11.828.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-1-tests.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//azure-keyvault-core-1.0.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//zstd-jni-1.4.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-kafka-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//lz4-java-1.6.0.jar:/usr/lib/hadoop-mapreduce/.//azure-data-lake-store-sdk-2.2.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-aws-3.2.1-amzn-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.19.jar:/usr/lib/hadoop-yarn/lib/metrics-core-3.2.4.jar:/usr/lib/hadoop-yarn/lib/objenesis-1.0.jar:/usr/lib/hadoop-yarn/lib/json-io-2.5.1.jar:/usr/lib/hadoop-yarn/lib/ehcache-3.3.1.jar:/usr/lib/hadoop-yarn/lib/HikariCP-java7-2.4.12.jar:/usr/lib/hadoop-yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-4.0.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-base-2.10.0.jar:/usr/lib/hadoop-yarn/lib/jackson-module-jaxb-annotations-2.10.0.jar:/usr/lib/hadoop-yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/usr/lib/hadoop-yarn/lib/fst-2.50.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-json-provider-2.10.0.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/guice-4.0.jar:/usr/lib/hadoop-yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.19.jar:/usr/lib/hadoop-yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/bcprov-jdk15on-1.60.jar:/usr/lib/hadoop-yarn/lib/java-util-1.9.0.jar:/usr/lib/hadoop-yarn/lib/jakarta.activation-api-1.2.1.jar:/usr/lib/hadoop-yarn/lib/snakeyaml-1.16.jar:/usr/lib/hadoop-yarn/lib/swagger-annotations-1.5.4.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-\u001b[0m\n",
      "\u001b[34m3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-submarine-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-core-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-router.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-services-api-3.2.1-amzn-1.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = git@aws157git.com:/pkg/Aws157BigTop -r 520b97ed429ab8eb7a8d30068b0f34a8036c51a7; compiled by 'ec2-user' on 2020-07-30T08:02Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_272\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:51,663 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:51,665 INFO datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:51,730 INFO namenode.NameNode: createNameNode []\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:51,863 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:51,947 INFO conf.Configuration: found resource core-site.xml at file:/etc/hadoop/conf.empty/core-site.xml\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:51,966 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:51,966 INFO impl.MetricsSystemImpl: NameNode metrics system started\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:51,987 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:51,988 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:51,989 INFO namenode.NameNodeUtils: fs.defaultFS is hdfs://10.0.174.129/\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,015 INFO checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/opt/amazon/hadoop/hdfs/datanode\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,017 INFO resourceplugin.ResourcePluginManager: No Resource plugins found from configuration!\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,017 INFO resourceplugin.ResourcePluginManager: Found Resource plugins from configuration: null\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,034 INFO conf.Configuration: found resource yarn-site.xml at file:/etc/hadoop/conf.empty/yarn-site.xml\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,047 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,080 INFO nodemanager.NodeManager: Node Manager health check script is not available or doesn't have execute permission, so not starting the node health script runner.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,080 INFO security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,085 INFO security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,089 INFO security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,104 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,116 INFO util.JvmPauseMonitor: Starting JVM pause monitor\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,129 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,130 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,131 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,131 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,131 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,132 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,132 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,133 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,135 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,135 INFO resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,135 INFO tracker.NMLogAggregationStatusTracker: the rolling interval seconds for the NodeManager Cached Log aggregation status is 600\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,141 INFO hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,152 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,152 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,153 INFO util.log: Logging initialized @975ms to org.eclipse.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,169 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,169 INFO impl.MetricsSystemImpl: DataNode metrics system started\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,170 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.event.EventDispatcher\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,171 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,172 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,173 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,199 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,227 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,255 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,268 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,268 INFO impl.MetricsSystemImpl: NodeManager metrics system started\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,268 INFO http.HttpRequestLog: Http request log for http.requests.namenode is not defined\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,274 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,277 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,277 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,277 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,289 INFO nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,301 INFO nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,302 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,302 INFO impl.MetricsSystemImpl: ResourceManager metrics system started\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,306 INFO http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,306 INFO http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,315 INFO http.HttpServer2: Jetty bound to port 9870\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,316 INFO server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_272-b10\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,316 INFO security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instantiated.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,319 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,327 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,328 INFO resourcemanager.RMNMInfo: Registered RMNMInfo MBean\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,329 INFO monitor.RMAppLifetimeMonitor: Application lifelime monitor interval set to 3000 ms.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,334 INFO placement.MultiNodeSortingManager: Initializing NodeSortingService=MultiNodeSortingManager\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,336 INFO util.HostsFileReader: Refreshing hosts (include/exclude) list\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,337 INFO nodemanager.NodeResourceMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@15043a2f\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,338 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,339 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,340 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,340 INFO containermanager.ContainerManagerImpl: AMRMProxyService is disabled\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,340 INFO localizer.ResourceLocalizationService: per directory file limit = 8192\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,341 INFO datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,342 INFO conf.Configuration: found resource capacity-scheduler.xml at file:/etc/hadoop/conf.empty/capacity-scheduler.xml\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,344 INFO server.session: DefaultSessionIdManager workerName=node0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,344 INFO server.session: No SessionScavenger set, using defaults\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,346 INFO server.session: node0 Scavenging every 600000ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,346 INFO datanode.DataNode: Configured hostname is algo-1\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,346 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,350 INFO datanode.DataNode: Starting DataNode with maxLockedMemory = 0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,356 INFO scheduler.AbstractYarnScheduler: Minimum allocation = <memory:1, vCores:1>\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,356 INFO scheduler.AbstractYarnScheduler: Maximum allocation = <memory:63569, vCores:16>\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,356 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@305ffe9e{logs,/logs,file:///usr/lib/hadoop/logs/,AVAILABLE}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,357 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@35841320{static,/static,file:///usr/lib/hadoop-hdfs/webapps/static/,AVAILABLE}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,358 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,363 INFO resources.ResourceHandlerModule: Using traffic control bandwidth handler\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,366 INFO monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@451001e5\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,366 INFO monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,367 INFO monitor.ContainersMonitorImpl: Physical memory check enabled: true\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,367 INFO datanode.DataNode: Opened streaming server at /0.0.0.0:9866\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,367 INFO monitor.ContainersMonitorImpl: Virtual memory check enabled: true\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,367 INFO monitor.ContainersMonitorImpl: Elastic memory control enabled: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,367 INFO monitor.ContainersMonitorImpl: Strict memory control enabled: true\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,367 INFO monitor.ContainersMonitorImpl: ContainersMonitor enabled: true\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,369 INFO datanode.DataNode: Balancing bandwidth is 10485760 bytes/s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,369 INFO datanode.DataNode: Number threads for balancing is 50\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,370 WARN monitor.ContainersMonitorImpl: NodeManager configured with 62.1 G physical memory allocated to containers, which is more than 80% of the total physical memory available (62.1 G). Thrashing might happen.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,370 INFO containermanager.ContainerManagerImpl: Not a recoverable state store. Nothing to recover.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,389 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,389 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,391 INFO capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,391 INFO capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,394 INFO conf.Configuration: node-resources.xml not found\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,395 INFO resource.ResourceUtils: Unable to find 'node-resources.xml'.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,396 INFO nodemanager.NodeStatusUpdaterImpl: Nodemanager resources is set to: <memory:63569, vCores:16>\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,401 INFO capacity.ParentQueue: root, capacity=1.0, absoluteCapacity=1.0, maxCapacity=1.0, absoluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,\u001b[0m\n",
      "\u001b[34m, reservationsContinueLooking=true, orderingPolicy=utilization, priority=0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,401 INFO capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,406 INFO util.TypeUtil: JVM Runtime does not support Modules\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,407 INFO util.log: Logging initialized @1222ms to org.eclipse.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,416 INFO capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,416 INFO capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,417 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@39d76cb5{hdfs,/,file:///usr/lib/hadoop-hdfs/webapps/hdfs/,AVAILABLE}{file:/usr/lib/hadoop-hdfs/webapps/hdfs}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,419 INFO capacity.LeafQueue: Initializing default\u001b[0m\n",
      "\u001b[34mcapacity = 1.0 [= (float) configuredCapacity / 100 ]\u001b[0m\n",
      "\u001b[34mabsoluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]\u001b[0m\n",
      "\u001b[34mmaxCapacity = 1.0 [= configuredMaxCapacity ]\u001b[0m\n",
      "\u001b[34mabsoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]\u001b[0m\n",
      "\u001b[34meffectiveMinResource=<memory:0, vCores:0>\n",
      " , effectiveMaxResource=<memory:0, vCores:0>\u001b[0m\n",
      "\u001b[34muserLimit = 100 [= configuredUserLimit ]\u001b[0m\n",
      "\u001b[34muserLimitFactor = 1.0 [= configuredUserLimitFactor ]\u001b[0m\n",
      "\u001b[34mmaxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]\u001b[0m\n",
      "\u001b[34mmaxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]\u001b[0m\n",
      "\u001b[34musedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]\u001b[0m\n",
      "\u001b[34mabsoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]\u001b[0m\n",
      "\u001b[34mmaxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]\u001b[0m\n",
      "\u001b[34mminimumAllocationFactor = 0.99998426 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]\u001b[0m\n",
      "\u001b[34mmaximumAllocation = <memory:63569, vCores:16> [= configuredMaxAllocation ]\u001b[0m\n",
      "\u001b[34mnumContainers = 0 [= currentNumContainers ]\u001b[0m\n",
      "\u001b[34mstate = RUNNING [= configuredState ]\u001b[0m\n",
      "\u001b[34macls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]\u001b[0m\n",
      "\u001b[34mnodeLocalityDelay = 40\u001b[0m\n",
      "\u001b[34mrackLocalityAdditionalDelay = -1\u001b[0m\n",
      "\u001b[34mlabels=*,\u001b[0m\n",
      "\u001b[34mreservationsContinueLooking = true\u001b[0m\n",
      "\u001b[34mpreemptionDisabled = true\u001b[0m\n",
      "\u001b[34mdefaultAppPriorityPerQueue = 0\u001b[0m\n",
      "\u001b[34mpriority = 0\u001b[0m\n",
      "\u001b[34mmaxLifetime = -1 seconds\u001b[0m\n",
      "\u001b[34mdefaultLifetime = -1 seconds\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,420 INFO capacity.CapacitySchedulerQueueManager: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0, effectiveMinResource=<memory:0, vCores:0> , effectiveMaxResource=<memory:0, vCores:0>\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,420 INFO capacity.CapacitySchedulerQueueManager: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,422 INFO capacity.CapacitySchedulerQueueManager: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,422 INFO placement.UserGroupMappingPlacementRule: Initialized queue mappings, override: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,423 INFO nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager with : physical-memory=63569 virtual-memory=317845 virtual-cores=16\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,423 INFO placement.MultiNodeSortingManager: MultiNode scheduling is 'false', and configured policies are \u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,423 INFO capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1, vCores:1>>, maximumAllocation=<<memory:63569, vCores:16>>, asynchronousScheduling=false, asyncScheduleInterval=5ms,multiNodePlacementEnabled=false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,426 INFO conf.Configuration: dynamic-resources.xml not found\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,426 INFO server.AbstractConnector: Started ServerConnector@5884a914{HTTP/1.1,[http/1.1]}{0.0.0.0:9870}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,427 INFO server.Server: Started @1249ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,428 INFO resourcemanager.AMSProcessingChain: Initializing AMS Processing chain. Root Processor=[org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor].\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,428 INFO resourcemanager.ApplicationMasterService: disabled placement handler will be used, all scheduling requests will be rejected.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,429 INFO resourcemanager.AMSProcessingChain: Adding [org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.processor.DisabledPlacementProcessor] tp top of AMS Processing chain. \u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,436 INFO resourcemanager.ResourceManager: TimelineServicePublisher is not configured\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,475 INFO util.log: Logging initialized @1285ms to org.eclipse.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,478 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,496 INFO ipc.Server: Starting Socket Reader #1 for port 0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,560 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,568 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,568 INFO http.HttpRequestLog: Http request log for http.requests.datanode is not defined\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,572 INFO http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,575 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,576 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,577 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,577 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,578 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,581 INFO http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,581 INFO http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,581 INFO http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,582 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,582 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,582 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,583 INFO http.HttpServer2: adding path spec: /cluster/*\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,583 INFO http.HttpServer2: adding path spec: /ws/*\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,583 INFO http.HttpServer2: adding path spec: /app/*\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,600 INFO http.HttpServer2: Jetty bound to port 35223\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,601 INFO server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_272-b10\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,622 INFO server.session: DefaultSessionIdManager workerName=node0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,622 INFO server.session: No SessionScavenger set, using defaults\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,624 INFO server.session: node0 Scavenging every 600000ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,634 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3fce8fd9{logs,/logs,file:///usr/lib/hadoop/logs/,AVAILABLE}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,635 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1df8b5b8{static,/static,file:///usr/lib/hadoop-hdfs/webapps/static/,AVAILABLE}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,649 WARN namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,650 WARN namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,687 INFO util.TypeUtil: JVM Runtime does not support Modules\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,694 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,697 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7d446ed1{datanode,/,file:///usr/lib/hadoop-hdfs/webapps/datanode/,AVAILABLE}{file:/usr/lib/hadoop-hdfs/webapps/datanode}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,704 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,706 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,706 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,707 INFO server.AbstractConnector: Started ServerConnector@27e47833{HTTP/1.1,[http/1.1]}{localhost:35223}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,708 INFO server.Server: Started @1523ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,711 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,711 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,711 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,711 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,722 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,722 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,722 INFO ipc.Server: IPC Server listener on 0: starting\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,738 INFO security.NMContainerTokenSecretManager: Updating node address : algo-1:43837\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,742 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,746 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,747 INFO ipc.Server: Starting Socket Reader #1 for port 8040\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,749 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,750 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,750 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,751 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,751 INFO ipc.Server: IPC Server listener on 8040: starting\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,753 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,753 INFO blockmanagement.BlockManager: The block deletion will start around 2021 Mar 12 03:19:52\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,754 INFO localizer.ResourceLocalizationService: Localizer started on port 8040\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,755 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,755 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,757 INFO util.GSet: 2.0% max memory 13.7 GB = 280.3 MB\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,757 INFO util.GSet: capacity      = 2^25 = 33554432 entries\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,759 INFO containermanager.ContainerManagerImpl: ContainerManager started at /10.0.174.129:43837\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,759 INFO containermanager.ContainerManagerImpl: ContainerManager bound to algo-1/10.0.174.129:0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,759 WARN tracker.NMLogAggregationStatusTracker: Log Aggregation is disabled.So is the LogAggregationStatusTracker.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,764 INFO webapp.WebServer: Instantiating NMWebApp at algo-1:8042\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,796 INFO util.log: Logging initialized @1616ms to org.eclipse.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,806 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,806 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,813 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,813 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,813 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,813 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,814 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,814 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,814 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,814 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,814 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,814 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,814 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,824 INFO web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,829 INFO util.JvmPauseMonitor: Starting JVM pause monitor\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,830 INFO datanode.DataNode: dnUserName = root\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,830 INFO datanode.DataNode: supergroup = supergroup\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,837 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,837 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,837 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,837 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,850 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,850 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,850 INFO util.GSet: 1.0% max memory 13.7 GB = 140.1 MB\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,850 INFO util.GSet: capacity      = 2^24 = 16777216 entries\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,865 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,879 INFO ipc.Server: Starting Socket Reader #1 for port 9867\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,882 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,885 INFO http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,886 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,886 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,886 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,886 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,890 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,891 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,891 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,891 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,891 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,892 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,892 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,892 INFO snapshot.SnapshotManager: SkipList is disabled\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,892 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,894 INFO http.HttpServer2: adding path spec: /node/*\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,894 INFO http.HttpServer2: adding path spec: /ws/*\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,898 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,898 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,898 INFO util.GSet: 0.25% max memory 13.7 GB = 35.0 MB\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:52,898 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,072 INFO webapp.WebApps: Registered webapp guice modules\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,080 INFO http.HttpServer2: Jetty bound to port 8088\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,081 INFO server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_272-b10\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,174 INFO server.session: DefaultSessionIdManager workerName=node0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,175 INFO server.session: No SessionScavenger set, using defaults\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,176 INFO server.session: node0 Scavenging every 660000ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,178 INFO datanode.DataNode: Opened IPC server at /0.0.0.0:9867\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,193 INFO datanode.DataNode: Refresh request received for nameservices: null\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,198 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,201 INFO datanode.DataNode: Starting BPOfferServices for nameservices: <default>\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,209 INFO delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,210 INFO datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to algo-1/10.0.174.129:8020 starting to offer service\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,211 INFO delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,211 INFO delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,218 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,218 INFO ipc.Server: IPC Server listener on 9867: starting\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,230 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d898981{logs,/logs,file:///var/log/yarn/,AVAILABLE}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,231 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@14f9390f{static,/static,jar:file:/usr/lib/hadoop-yarn/hadoop-yarn-common-3.2.1-amzn-1.jar!/webapps/static,AVAILABLE}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,241 WARN webapp.WebInfConfiguration: Can't generate resourceBase as part of webapp tmp dir name: java.lang.NullPointerException\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,294 INFO webapp.WebApps: Registered webapp guice modules\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,296 INFO http.HttpServer2: Jetty bound to port 8042\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,297 INFO server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_272-b10\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,309 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,309 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,309 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,313 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,313 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,315 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,315 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,315 INFO util.GSet: 0.029999999329447746% max memory 13.7 GB = 4.2 MB\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,315 INFO util.GSet: capacity      = 2^19 = 524288 entries\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,324 INFO server.session: DefaultSessionIdManager workerName=node0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,324 INFO server.session: No SessionScavenger set, using defaults\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,325 INFO server.session: node0 Scavenging every 660000ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,334 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,334 INFO common.Storage: Lock on /opt/amazon/hadoop/hdfs/namenode/in_use.lock acquired by nodename 138@algo-1\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,336 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@c2db68f{logs,/logs,file:///var/log/yarn/,AVAILABLE}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,337 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3668d4{static,/static,jar:file:/usr/lib/hadoop-yarn/hadoop-yarn-common-3.2.1-amzn-1.jar!/webapps/static,AVAILABLE}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,346 WARN webapp.WebInfConfiguration: Can't generate resourceBase as part of webapp tmp dir name: java.lang.NullPointerException\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,355 INFO namenode.FileJournalManager: Recovering unfinalized segments in /opt/amazon/hadoop/hdfs/namenode/current\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,356 INFO namenode.FSImage: No edit log streams selected.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,356 INFO namenode.FSImage: Planning to load image: FSImageFile(file=/opt/amazon/hadoop/hdfs/namenode/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,363 INFO util.TypeUtil: JVM Runtime does not support Modules\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,412 INFO namenode.FSImageFormatPBINode: Loading 1 INodes.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,432 INFO util.TypeUtil: JVM Runtime does not support Modules\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,435 INFO namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,436 INFO namenode.FSImage: Loaded image for txid 0 from /opt/amazon/hadoop/hdfs/namenode/current/fsimage_0000000000000000000\u001b[0m\n",
      "\u001b[34mMar 12, 2021 3:19:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\u001b[0m\n",
      "\u001b[34mINFO: Registering org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver as a provider class\u001b[0m\n",
      "\u001b[34mMar 12, 2021 3:19:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\u001b[0m\n",
      "\u001b[34mINFO: Registering org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices as a root resource class\u001b[0m\n",
      "\u001b[34mMar 12, 2021 3:19:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\u001b[0m\n",
      "\u001b[34mINFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,440 INFO namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,440 INFO namenode.FSEditLog: Starting log segment at 1\u001b[0m\n",
      "\u001b[34mMar 12, 2021 3:19:53 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate\u001b[0m\n",
      "\u001b[34mINFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'\u001b[0m\n",
      "\u001b[34mMar 12, 2021 3:19:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\u001b[0m\n",
      "\u001b[34mINFO: Binding org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope \"Singleton\"\u001b[0m\n",
      "\u001b[34mMar 12, 2021 3:19:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\u001b[0m\n",
      "\u001b[34mINFO: Registering org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices as a root resource class\u001b[0m\n",
      "\u001b[34mMar 12, 2021 3:19:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\u001b[0m\n",
      "\u001b[34mINFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class\u001b[0m\n",
      "\u001b[34mMar 12, 2021 3:19:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\u001b[0m\n",
      "\u001b[34mINFO: Registering org.apache.hadoop.yarn.server.nodemanager.webapp.JAXBContextResolver as a provider class\u001b[0m\n",
      "\u001b[34mMar 12, 2021 3:19:53 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate\u001b[0m\n",
      "\u001b[34mINFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,544 INFO namenode.NameCache: initialized with 0 entries 0 lookups\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,544 INFO namenode.FSNamesystem: Finished loading FSImage in 225 msecs\u001b[0m\n",
      "\u001b[34mMar 12, 2021 3:19:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\u001b[0m\n",
      "\u001b[34mINFO: Binding org.apache.hadoop.yarn.server.nodemanager.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope \"Singleton\"\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,691 INFO namenode.NameNode: RPC server is binding to algo-1:8020\u001b[0m\n",
      "\u001b[34mMar 12, 2021 3:19:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\u001b[0m\n",
      "\u001b[34mINFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope \"Singleton\"\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,719 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,732 INFO ipc.Server: Starting Socket Reader #1 for port 8020\u001b[0m\n",
      "\u001b[34mMar 12, 2021 3:19:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\u001b[0m\n",
      "\u001b[34mINFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope \"Singleton\"\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,930 INFO namenode.NameNode: Clients are to use algo-1:8020 to access this namenode/service.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,932 INFO namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:53,942 INFO namenode.LeaseManager: Number of blocks under construction: 0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,025 INFO blockmanagement.BlockManager: initializing replication queues\u001b[0m\n",
      "\u001b[34mMar 12, 2021 3:19:54 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\u001b[0m\n",
      "\u001b[34mINFO: Binding org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices to GuiceManagedComponentProvider with the scope \"Singleton\"\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,035 INFO hdfs.StateChange: STATE* Leaving safe mode after 0 secs\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,035 INFO hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,035 INFO hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,074 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@164a62bf{node,/,file:///tmp/jetty-algo-1-8042-_-any-8142521479521473720.dir/webapp/,AVAILABLE}{jar:file:/usr/lib/hadoop-yarn/hadoop-yarn-common-3.2.1-amzn-1.jar!/webapps/node}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,097 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,107 INFO ipc.Server: IPC Server listener on 8020: starting\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,123 INFO server.AbstractConnector: Started ServerConnector@2374d36a{HTTP/1.1,[http/1.1]}{algo-1:8042}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,124 INFO server.Server: Started @2944ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,124 INFO webapp.WebApps: Web app node started at 8042\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,126 INFO blockmanagement.BlockManager: Total number of blocks            = 0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,126 INFO blockmanagement.BlockManager: Number of invalid blocks          = 0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,126 INFO blockmanagement.BlockManager: Number of under-replicated blocks = 0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,126 INFO blockmanagement.BlockManager: Number of  over-replicated blocks = 0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,126 INFO blockmanagement.BlockManager: Number of blocks being written    = 0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,126 INFO hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 83 msec\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,152 INFO nodemanager.NodeStatusUpdaterImpl: Node ID assigned is : algo-1:43837\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,153 INFO util.JvmPauseMonitor: Starting JVM pause monitor\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,160 INFO client.RMProxy: Connecting to ResourceManager at /10.0.174.129:8031\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,173 INFO namenode.NameNode: NameNode RPC up at: algo-1/10.0.174.129:8020\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,186 INFO namenode.FSNamesystem: Starting services required for active state\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,187 INFO namenode.FSDirectory: Initializing quota with 4 thread(s)\u001b[0m\n",
      "\u001b[34mMar 12, 2021 3:19:54 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\u001b[0m\n",
      "\u001b[34mINFO: Binding org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices to GuiceManagedComponentProvider with the scope \"Singleton\"\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,210 INFO namenode.FSDirectory: Quota initialization completed in 24 milliseconds\u001b[0m\n",
      "\u001b[34mname space=1\u001b[0m\n",
      "\u001b[34mstorage space=0\u001b[0m\n",
      "\u001b[34mstorage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,221 INFO nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,234 INFO nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,238 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@396e6d9{cluster,/,file:///tmp/jetty-10_0_174_129-8088-_-any-6814011559134520389.dir/webapp/,AVAILABLE}{jar:file:/usr/lib/hadoop-yarn/hadoop-yarn-common-3.2.1-amzn-1.jar!/webapps/cluster}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,247 INFO blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,255 INFO server.AbstractConnector: Started ServerConnector@432038ec{HTTP/1.1,[http/1.1]}{10.0.174.129:8088}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,255 INFO server.Server: Started @3065ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,255 INFO webapp.WebApps: Web app cluster started at 8088\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,300 INFO ipc.Client: Retrying connect to server: algo-1/10.0.174.129:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,330 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,343 INFO ipc.Server: Starting Socket Reader #1 for port 8033\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     cluster is up\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     transitioning from status BOOTSTRAPPING to WAITING\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     starting executor logs watcher\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     start log event log publisher\u001b[0m\n",
      "\u001b[34mStarting executor logs watcher on log_dir: /var/log/yarn\u001b[0m\n",
      "\u001b[34m03-12 03:19 sagemaker-spark-event-logs-publisher INFO     Spark event log not enabled.\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     Waiting for hosts to bootstrap: ['algo-1']\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,497 INFO datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to algo-1/10.0.174.129:8020\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,498 INFO common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,499 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server\u001b[0m\n",
      "\u001b[34m03-12 03:19 smspark-submit INFO     Received host statuses: dict_items([('algo-1', StatusMessage(status='WAITING', timestamp='2021-03-12T03:19:54.497532'))])\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,499 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,499 INFO ipc.Server: IPC Server listener on 8033: starting\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,500 INFO resourcemanager.ResourceManager: Transitioning to active state\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,504 INFO common.Storage: Lock on /opt/amazon/hadoop/hdfs/datanode/in_use.lock acquired by nodename 139@algo-1\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,505 INFO common.Storage: Storage directory with location [DISK]file:/opt/amazon/hadoop/hdfs/datanode is not formatted for namespace 2061282482. Formatting...\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,506 INFO common.Storage: Generated new storageID DS-441d657e-dd8d-4593-a036-aefe2a4c159d for directory /opt/amazon/hadoop/hdfs/datanode \u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,514 INFO recovery.RMStateStore: Updating AMRMToken\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,515 INFO security.RMContainerTokenSecretManager: Rolling master-key for container-tokens\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,515 INFO security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,515 INFO delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,515 INFO security.RMDelegationTokenSecretManager: storing master key with keyID 1\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,515 INFO recovery.RMStateStore: Storing RMDTMasterKey.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,516 INFO delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,516 INFO delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,516 INFO security.RMDelegationTokenSecretManager: storing master key with keyID 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,516 INFO recovery.RMStateStore: Storing RMDTMasterKey.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,528 INFO common.Storage: Analyzing storage directories for bpid BP-2026770010-10.0.174.129-1615519190741\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,529 INFO common.Storage: Locking is disabled for /opt/amazon/hadoop/hdfs/datanode/current/BP-2026770010-10.0.174.129-1615519190741\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,529 INFO common.Storage: Block pool storage directory for location [DISK]file:/opt/amazon/hadoop/hdfs/datanode and block pool id BP-2026770010-10.0.174.129-1615519190741 is not formatted. Formatting ...\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,529 INFO common.Storage: Formatting block pool BP-2026770010-10.0.174.129-1615519190741 directory /opt/amazon/hadoop/hdfs/datanode/current/BP-2026770010-10.0.174.129-1615519190741/current\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,535 INFO datanode.DataNode: Setting up storage: nsid=2061282482;bpid=BP-2026770010-10.0.174.129-1615519190741;lv=-57;nsInfo=lv=-65;cid=CID-80619f6d-ab67-46b9-8fd5-f0e5a460883f;nsid=2061282482;c=1615519190741;bpid=BP-2026770010-10.0.174.129-1615519190741;dnuuid=null\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,537 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,538 INFO datanode.DataNode: Generated and persisted new Datanode UUID 28f270e1-3f95-4260-9b30-9b20fdc1051b\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,622 INFO impl.FsDatasetImpl: Added new volume: DS-441d657e-dd8d-4593-a036-aefe2a4c159d\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,622 INFO impl.FsDatasetImpl: Added volume - [DISK]file:/opt/amazon/hadoop/hdfs/datanode, StorageType: DISK\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,625 INFO impl.FsDatasetImpl: Registered FSDatasetState MBean\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,631 INFO checker.ThrottledAsyncChecker: Scheduling a check for /opt/amazon/hadoop/hdfs/datanode\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,638 INFO checker.DatasetVolumeChecker: Scheduled health check for volume /opt/amazon/hadoop/hdfs/datanode\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,639 INFO impl.FsDatasetImpl: Adding block pool BP-2026770010-10.0.174.129-1615519190741\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,640 INFO impl.FsDatasetImpl: Scanning block pool BP-2026770010-10.0.174.129-1615519190741 on volume /opt/amazon/hadoop/hdfs/datanode...\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,668 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-2026770010-10.0.174.129-1615519190741 on /opt/amazon/hadoop/hdfs/datanode: 29ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,668 INFO impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-2026770010-10.0.174.129-1615519190741: 29ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,670 INFO impl.FsDatasetImpl: Adding replicas to map for block pool BP-2026770010-10.0.174.129-1615519190741 on volume /opt/amazon/hadoop/hdfs/datanode...\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,670 INFO impl.BlockPoolSlice: Replica Cache file: /opt/amazon/hadoop/hdfs/datanode/current/BP-2026770010-10.0.174.129-1615519190741/current/replicas doesn't exist \u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,672 INFO impl.FsDatasetImpl: Time to add replicas to map for block pool BP-2026770010-10.0.174.129-1615519190741 on volume /opt/amazon/hadoop/hdfs/datanode: 1ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,672 INFO impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-2026770010-10.0.174.129-1615519190741: 2ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,673 INFO datanode.VolumeScanner: Now scanning bpid BP-2026770010-10.0.174.129-1615519190741 on volume /opt/amazon/hadoop/hdfs/datanode\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,675 INFO datanode.VolumeScanner: VolumeScanner(/opt/amazon/hadoop/hdfs/datanode, DS-441d657e-dd8d-4593-a036-aefe2a4c159d): finished scanning block pool BP-2026770010-10.0.174.129-1615519190741\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,676 INFO store.AbstractFSNodeStore: Created store directory :file:/tmp/hadoop-yarn-root/node-attribute\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,686 INFO datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 3/12/21 5:41 AM with interval of 21600000ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,688 INFO datanode.VolumeScanner: VolumeScanner(/opt/amazon/hadoop/hdfs/datanode, DS-441d657e-dd8d-4593-a036-aefe2a4c159d): no suitable block pools found to scan.  Waiting 1814399985 ms.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,688 INFO store.AbstractFSNodeStore: Finished write mirror at:file:/tmp/hadoop-yarn-root/node-attribute/nodeattribute.mirror\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,688 INFO store.AbstractFSNodeStore: Finished create editlog file at:file:/tmp/hadoop-yarn-root/node-attribute/nodeattribute.editlog\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,691 INFO datanode.DataNode: Block pool BP-2026770010-10.0.174.129-1615519190741 (Datanode Uuid 28f270e1-3f95-4260-9b30-9b20fdc1051b) service to algo-1/10.0.174.129:8020 beginning handshake with NN\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,700 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesManagerImpl$ForwardingEventHandler\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,703 INFO placement.MultiNodeSortingManager: Starting NodeSortingService=MultiNodeSortingManager\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,715 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,717 INFO ipc.Server: Starting Socket Reader #1 for port 8031\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,719 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,723 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,727 INFO ipc.Server: IPC Server listener on 8031: starting\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,729 INFO hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.174.129:9866, datanodeUuid=28f270e1-3f95-4260-9b30-9b20fdc1051b, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-80619f6d-ab67-46b9-8fd5-f0e5a460883f;nsid=2061282482;c=1615519190741) storage 28f270e1-3f95-4260-9b30-9b20fdc1051b\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,730 INFO net.NetworkTopology: Adding a new node: /default-rack/10.0.174.129:9866\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,730 INFO blockmanagement.BlockReportLeaseManager: Registered DN 28f270e1-3f95-4260-9b30-9b20fdc1051b (10.0.174.129:9866).\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,743 INFO datanode.DataNode: Block pool Block pool BP-2026770010-10.0.174.129-1615519190741 (Datanode Uuid 28f270e1-3f95-4260-9b30-9b20fdc1051b) service to algo-1/10.0.174.129:8020 successfully registered with NN\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,743 INFO datanode.DataNode: For namenode algo-1/10.0.174.129:8020 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,753 INFO util.JvmPauseMonitor: Starting JVM pause monitor\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,763 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,769 INFO ipc.Server: Starting Socket Reader #1 for port 8030\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,775 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,779 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,779 INFO ipc.Server: IPC Server listener on 8030: starting\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,804 INFO blockmanagement.DatanodeDescriptor: Adding new storage ID DS-441d657e-dd8d-4593-a036-aefe2a4c159d for DN 10.0.174.129:9866\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,879 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,881 INFO ipc.Server: Starting Socket Reader #1 for port 8032\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,886 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,892 INFO ipc.Server: IPC Server Responder: starting\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,892 INFO ipc.Server: IPC Server listener on 8032: starting\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,895 INFO BlockStateChange: BLOCK* processReport 0x4d7c90fd8d81a0a2: Processing first storage report for DS-441d657e-dd8d-4593-a036-aefe2a4c159d from datanode 28f270e1-3f95-4260-9b30-9b20fdc1051b\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,897 INFO BlockStateChange: BLOCK* processReport 0x4d7c90fd8d81a0a2: from storage DS-441d657e-dd8d-4593-a036-aefe2a4c159d node DatanodeRegistration(10.0.174.129:9866, datanodeUuid=28f270e1-3f95-4260-9b30-9b20fdc1051b, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-80619f6d-ab67-46b9-8fd5-f0e5a460883f;nsid=2061282482;c=1615519190741), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,926 INFO datanode.DataNode: Successfully sent block report 0x4d7c90fd8d81a0a2,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 95 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,926 INFO datanode.DataNode: Got finalize command for block pool BP-2026770010-10.0.174.129-1615519190741\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:54,939 INFO resourcemanager.ResourceManager: Transitioned to active state\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:55,305 INFO ipc.Client: Retrying connect to server: algo-1/10.0.174.129:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:55,459 INFO resourcemanager.ResourceTrackerService: NodeManager from node algo-1(cmPort: 43837 httpPort: 8042) registered with capability: <memory:63569, vCores:16>, assigned nodeId algo-1:43837\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:55,463 INFO rmnode.RMNodeImpl: algo-1:43837 Node Transitioned from NEW to RUNNING\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:55,474 INFO security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id -179751341\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:55,475 INFO security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -1957827328\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:55,475 INFO nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as algo-1:43837 with total resource of <memory:63569, vCores:16>\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:55,480 INFO capacity.CapacityScheduler: Added node algo-1:43837 clusterResource: <memory:63569, vCores:16>\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:57,896 INFO spark.SparkContext: Running Spark version 3.0.0-amzn-0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:57,943 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:57,945 INFO resource.ResourceUtils: Resources for spark.driver:\n",
      "\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:57,945 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:57,945 INFO spark.SparkContext: Submitted application: processing_entrypoint.py\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,012 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,012 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,012 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,012 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,012 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,255 INFO util.Utils: Successfully started service 'sparkDriver' on port 35737.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,286 INFO spark.SparkEnv: Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,323 INFO spark.SparkEnv: Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,352 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,352 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,389 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,405 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-4b1f915b-4f54-4d07-9b54-89846cf374c6\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,429 INFO memory.MemoryStore: MemoryStore started with capacity 1007.8 MiB\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,475 INFO spark.SparkEnv: Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,591 INFO util.log: Logging initialized @3743ms to org.sparkproject.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,687 INFO server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_272-b10\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,710 INFO server.Server: Started @3862ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,745 INFO server.AbstractConnector: Started ServerConnector@516afbcd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,745 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,770 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@43e98f67{/jobs,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,773 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@131b154f{/jobs/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,774 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@42906db9{/jobs/job,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,775 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@191a887e{/jobs/job/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,776 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@420bfbd4{/stages,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,776 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@833f972{/stages/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,777 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7ba91dbd{/stages/stage,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,778 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4e1fbfca{/stages/stage/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,779 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2593f208{/stages/pool,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,779 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2b1d6340{/stages/pool/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,780 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@fb423a6{/storage,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,780 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2cac798c{/storage/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,781 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5b5a9c56{/storage/rdd,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,781 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20ab89ea{/storage/rdd/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,782 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@339f79a0{/environment,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,782 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a7200d{/environment/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,783 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@34bcec69{/executors,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,784 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@98be4da{/executors/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,784 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@102a990e{/executors/threadDump,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,785 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@618f0813{/executors/threadDump/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,795 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@51aeac81{/static,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,796 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@15e0c31e{/,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,797 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@64a23f1{/api,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,798 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3b9eeba{/jobs/job/kill,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,798 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a572c14{/stages/stage/kill,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:58,800 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.0.174.129:4040\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:59,098 INFO client.RMProxy: Connecting to ResourceManager at /10.0.174.129:8032\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:59,382 INFO yarn.Client: Requesting a new application from cluster with 1 NodeManagers\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:59,402 INFO resourcemanager.ClientRMService: Allocated new applicationId: 1\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:59,533 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:59,534 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:59,553 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (63569 MB per container)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:59,553 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:59,554 INFO yarn.Client: Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:59,555 INFO yarn.Client: Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:59,562 INFO yarn.Client: Preparing resources for our AM container\u001b[0m\n",
      "\u001b[34m2021-03-12 03:19:59,587 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:02,959 INFO yarn.Client: Uploading resource file:/tmp/spark-99741e4a-173a-475b-bd1a-6b33b541f744/__spark_libs__5404052653850104229.zip -> file:/root/.sparkStaging/application_1615519194501_0001/__spark_libs__5404052653850104229.zip\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:04,891 INFO yarn.Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> file:/root/.sparkStaging/application_1615519194501_0001/pyspark.zip\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:04,895 INFO yarn.Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.10.9-src.zip -> file:/root/.sparkStaging/application_1615519194501_0001/py4j-0.10.9-src.zip\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,001 INFO yarn.Client: Uploading resource file:/tmp/spark-99741e4a-173a-475b-bd1a-6b33b541f744/__spark_conf__1822777453333004080.zip -> file:/root/.sparkStaging/application_1615519194501_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,020 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,021 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,021 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,021 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,021 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,047 INFO yarn.Client: Submitting application application_1615519194501_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,127 INFO capacity.CapacityScheduler: Application 'application_1615519194501_0001' is submitted without priority hence considering default queue/cluster priority: 0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,127 INFO capacity.CapacityScheduler: Priority '0' is acceptable in queue : default for application: application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,144 WARN rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 1]. Use the global max attempts instead.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,145 INFO resourcemanager.ClientRMService: Application with id 1 submitted by user root\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,146 INFO rmapp.RMAppImpl: Storing application with id application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,147 INFO resourcemanager.RMAuditLogger: USER=root#011IP=10.0.174.129#011OPERATION=Submit Application Request#011TARGET=ClientRMService#011RESULT=SUCCESS#011APPID=application_1615519194501_0001#011QUEUENAME=default\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,153 INFO rmapp.RMAppImpl: application_1615519194501_0001 State change from NEW to NEW_SAVING on event = START\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,153 INFO recovery.RMStateStore: Storing info for app: application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,154 INFO rmapp.RMAppImpl: application_1615519194501_0001 State change from NEW_SAVING to SUBMITTED on event = APP_NEW_SAVED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,155 INFO capacity.ParentQueue: Application added - appId: application_1615519194501_0001 user: root leaf-queue of parent: root #applications: 1\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,156 INFO capacity.CapacityScheduler: Accepted application application_1615519194501_0001 from user: root, in queue: default\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,167 INFO rmapp.RMAppImpl: application_1615519194501_0001 State change from SUBMITTED to ACCEPTED on event = APP_ACCEPTED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,191 INFO resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1615519194501_0001_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,192 INFO attempt.RMAppAttemptImpl: appattempt_1615519194501_0001_000001 State change from NEW to SUBMITTED on event = START\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,240 INFO impl.YarnClientImpl: Submitted application application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,255 INFO capacity.LeafQueue: Application application_1615519194501_0001 from user: root activated in queue: default\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,255 INFO capacity.LeafQueue: Application added - appId: application_1615519194501_0001 user: root, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,255 INFO capacity.CapacityScheduler: Added Application Attempt appattempt_1615519194501_0001_000001 to scheduler from user root in queue default\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,262 INFO attempt.RMAppAttemptImpl: appattempt_1615519194501_0001_000001 State change from SUBMITTED to SCHEDULED on event = ATTEMPT_ADDED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,566 INFO allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1615519194501_0001_000001 container=null queue=default clusterResource=<memory:63569, vCores:16> type=OFF_SWITCH requestedPartition=\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,570 INFO rmcontainer.RMContainerImpl: container_1615519194501_0001_01_000001 Container Transitioned from NEW to ALLOCATED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,571 INFO fica.FiCaSchedulerNode: Assigned container container_1615519194501_0001_01_000001 of capacity <memory:896, vCores:1> on host algo-1:43837, which has 1 containers, <memory:896, vCores:1> used and <memory:62673, vCores:15> available after allocation\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,571 INFO resourcemanager.RMAuditLogger: USER=root#011OPERATION=AM Allocated Container#011TARGET=SchedulerApp#011RESULT=SUCCESS#011APPID=application_1615519194501_0001#011CONTAINERID=container_1615519194501_0001_01_000001#011RESOURCE=<memory:896, vCores:1>#011QUEUENAME=default\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,587 INFO security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : algo-1:43837 for container : container_1615519194501_0001_01_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,594 INFO rmcontainer.RMContainerImpl: container_1615519194501_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,595 INFO security.NMTokenSecretManagerInRM: Clear node set for appattempt_1615519194501_0001_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,595 INFO capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.014094921 absoluteUsedCapacity=0.014094921 used=<memory:896, vCores:1> cluster=<memory:63569, vCores:16>\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,595 INFO attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1615519194501_0001 AttemptId: appattempt_1615519194501_0001_000001 MasterContainer: Container: [ContainerId: container_1615519194501_0001_01_000001, AllocationRequestId: -1, Version: 0, NodeId: algo-1:43837, NodeHttpAddress: algo-1:8042, Resource: <memory:896, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.0.174.129:43837 }, ExecutionType: GUARANTEED, ]\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,595 INFO capacity.CapacityScheduler: Allocation proposal accepted\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,605 INFO attempt.RMAppAttemptImpl: appattempt_1615519194501_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING on event = CONTAINER_ALLOCATED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,609 INFO attempt.RMAppAttemptImpl: appattempt_1615519194501_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED on event = ATTEMPT_NEW_SAVED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,620 INFO amlauncher.AMLauncher: Launching masterappattempt_1615519194501_0001_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,669 INFO amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1615519194501_0001_01_000001, AllocationRequestId: -1, Version: 0, NodeId: algo-1:43837, NodeHttpAddress: algo-1:8042, Resource: <memory:896, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.0.174.129:43837 }, ExecutionType: GUARANTEED, ] for AM appattempt_1615519194501_0001_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,670 INFO security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1615519194501_0001_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,673 INFO security.AMRMTokenSecretManager: Creating password for appattempt_1615519194501_0001_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,781 INFO ipc.Server: Auth successful for appattempt_1615519194501_0001_000001 (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,869 INFO containermanager.ContainerManagerImpl: Start request for container_1615519194501_0001_01_000001 by user root\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,916 INFO containermanager.ContainerManagerImpl: Creating a new application reference for app application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,924 INFO application.ApplicationImpl: Application application_1615519194501_0001 transitioned from NEW to INITING\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,924 INFO application.ApplicationImpl: Adding container_1615519194501_0001_01_000001 to application application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,925 INFO nodemanager.NMAuditLogger: USER=root#011IP=10.0.174.129#011OPERATION=Start Container Request#011TARGET=ContainerManageImpl#011RESULT=SUCCESS#011APPID=application_1615519194501_0001#011CONTAINERID=container_1615519194501_0001_01_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,929 INFO application.ApplicationImpl: Application application_1615519194501_0001 transitioned from INITING to RUNNING\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,933 INFO container.ContainerImpl: Container container_1615519194501_0001_01_000001 transitioned from NEW to LOCALIZING\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,933 INFO containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,940 INFO amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1615519194501_0001_01_000001, AllocationRequestId: -1, Version: 0, NodeId: algo-1:43837, NodeHttpAddress: algo-1:8042, Resource: <memory:896, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.0.174.129:43837 }, ExecutionType: GUARANTEED, ] for AM appattempt_1615519194501_0001_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,940 INFO attempt.RMAppAttemptImpl: appattempt_1615519194501_0001_000001 State change from ALLOCATED to LAUNCHED on event = LAUNCHED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,940 INFO rmapp.RMAppImpl: update the launch time for applicationId: application_1615519194501_0001, attemptId: appattempt_1615519194501_0001_000001launchTime: 1615519205940\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,941 INFO recovery.RMStateStore: Updating info for app: application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:05,943 INFO localizer.ResourceLocalizationService: Created localizer for container_1615519194501_0001_01_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:06,006 INFO localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /tmp/hadoop-root/nm-local-dir/nmPrivate/container_1615519194501_0001_01_000001.tokens\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:06,017 INFO nodemanager.DefaultContainerExecutor: Initializing user root\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:06,022 INFO nodemanager.DefaultContainerExecutor: Copying from /tmp/hadoop-root/nm-local-dir/nmPrivate/container_1615519194501_0001_01_000001.tokens to /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001/container_1615519194501_0001_01_000001.tokens\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:06,023 INFO nodemanager.DefaultContainerExecutor: Localizer CWD set to /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001 = file:/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:06,244 INFO yarn.Client: Application report for application_1615519194501_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:06,246 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: AM container is launched, waiting for AM container to Register with RM\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1615519205144\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1615519194501_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:06,567 INFO rmcontainer.RMContainerImpl: container_1615519194501_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:07,249 INFO yarn.Client: Application report for application_1615519194501_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:08,252 INFO yarn.Client: Application report for application_1615519194501_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:08,452 INFO container.ContainerImpl: Container container_1615519194501_0001_01_000001 transitioned from LOCALIZING to SCHEDULED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:08,453 INFO scheduler.ContainerScheduler: Starting container [container_1615519194501_0001_01_000001]\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:08,481 INFO container.ContainerImpl: Container container_1615519194501_0001_01_000001 transitioned from SCHEDULED to RUNNING\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:08,481 INFO monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1615519194501_0001_01_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:08,485 INFO nodemanager.DefaultContainerExecutor: launchContainer: [bash, /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001/container_1615519194501_0001_01_000001/default_container_executor.sh]\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/prelaunch.out\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/prelaunch.err\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/launch_container.sh\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/directory.info\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stdout\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:09,254 INFO yarn.Client: Application report for application_1615519194501_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:10,258 INFO yarn.Client: Application report for application_1615519194501_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:10,711 INFO ipc.Server: Auth successful for appattempt_1615519194501_0001_000001 (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:10,732 INFO resourcemanager.DefaultAMSProcessor: AM registration appattempt_1615519194501_0001_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:10,733 INFO resourcemanager.RMAuditLogger: USER=root#011IP=10.0.174.129#011OPERATION=Register App Master#011TARGET=ApplicationMasterService#011RESULT=SUCCESS#011APPID=application_1615519194501_0001#011APPATTEMPTID=appattempt_1615519194501_0001_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:10,733 INFO attempt.RMAppAttemptImpl: appattempt_1615519194501_0001_000001 State change from LAUNCHED to RUNNING on event = REGISTERED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:10,733 INFO rmapp.RMAppImpl: application_1615519194501_0001 State change from ACCEPTED to RUNNING on event = ATTEMPT_REGISTERED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:10,764 INFO monitor.ContainersMonitorImpl: container_1615519194501_0001_01_000001's ip = 10.0.174.129, and hostname = algo-1\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:10,770 INFO monitor.ContainersMonitorImpl: Skipping monitoring container container_1615519194501_0001_01_000001 since CPU usage is not yet available.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,016 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1615519194501_0001), /proxy/application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,261 INFO yarn.Client: Application report for application_1615519194501_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,261 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.0.174.129\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1615519205144\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1615519194501_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,262 INFO cluster.YarnClientSchedulerBackend: Application application_1615519194501_0001 has started running.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,272 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39501.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,273 INFO netty.NettyBlockTransferService: Server created on 10.0.174.129:39501\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,274 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,286 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.174.129, 39501, None)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,290 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.174.129:39501 with 1007.8 MiB RAM, BlockManagerId(driver, 10.0.174.129, 39501, None)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,293 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.174.129, 39501, None)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,293 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.174.129, 39501, None)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,358 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:09,522 INFO util.SignalUtils: Registered signal handler for TERM\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:09,524 INFO util.SignalUtils: Registered signal handler for HUP\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:09,524 INFO util.SignalUtils: Registered signal handler for INT\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:09,968 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:09,969 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:09,970 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:09,970 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:09,971 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:10,089 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:10,284 INFO yarn.ApplicationMaster: ApplicationAttemptId: appattempt_1615519194501_0001_000001\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:10,546 INFO client.RMProxy: Connecting to ResourceManager at /10.0.174.129:8030\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:10,606 INFO yarn.YarnRMClient: Registering the ApplicationMaster\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:10,863 INFO client.TransportClientFactory: Successfully created connection to /10.0.174.129:35737 after 72 ms (0 ms spent in bootstraps)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:11,028 INFO yarn.ApplicationMaster: Preparing Local resources\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:11,229 INFO yarn.ApplicationMaster: \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] ===============================================================================\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] Default YARN executor launch context:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]   env:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]     CLASSPATH -> /usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar<CPS>{{PWD}}<CPS>{{PWD}}/__spark_conf__<CPS>{{PWD}}/__spark_libs__/*<CPS>$HADOOP_CONF_DIR<CPS>$HADOOP_COMMON_HOME/share/hadoop/common/*<CPS>$HADOOP_COMMON_HOME/share/hadoop/common/lib/*<CPS>$HADOOP_HDFS_HOME/share/hadoop/hdfs/*<CPS>$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*<CPS>$HADOOP_YARN_HOME/share/hadoop/yarn/*<CPS>$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*<CPS>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*<CPS>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*<CPS>{{PWD}}/__spark_conf__/__hadoop_conf__\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]     SPARK_YARN_STAGING_DIR -> file:/root/.sparkStaging/application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]     SPARK_USER -> root\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]     PYTHONPATH -> {{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9-src.zip\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]   command:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]     LD_LIBRARY_PATH=\\\"/usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native:$LD_LIBRARY_PATH\\\" \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       {{JAVA_HOME}}/bin/java \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       -server \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       -Xmx55742m \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       '-verbose:gc' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       '-XX:OnOutOfMemoryError=kill -9 %p' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       '-XX:+PrintGCDetails' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       '-XX:+PrintGCDateStamps' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       '-XX:+UseParallelGC' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       '-XX:InitiatingHeapOccupancyPercent=70' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       '-XX:ConcGCThreads=4' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       '-XX:ParallelGCThreads=12' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       -Djava.io.tmpdir={{PWD}}/tmp \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       '-Dspark.driver.port=35737' \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       -Dspark.yarn.app.container.log.dir=<LOG_DIR> \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       org.apache.spark.executor.YarnCoarseGrainedExecutorBackend \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       --driver-url \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       spark://CoarseGrainedScheduler@10.0.174.129:35737 \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       --executor-id \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       <executorId> \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       --hostname \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       <hostname> \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       --cores \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       16 \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       --app-id \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       application_1615519194501_0001 \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       --resourceProfileId \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       0 \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       --user-class-path \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       file:$PWD/__app__.jar \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       1><LOG_DIR>/stdout \\ \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]       2><LOG_DIR>/stderr\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]   resources:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]     pyspark.zip -> resource { scheme: \"file\" port: -1 file: \"/root/.sparkStaging/application_1615519194501_0001/pyspark.zip\" } size: 732492 timestamp: 1615519204000 type: FILE visibility: PRIVATE\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]     __spark_libs__ -> resource { scheme: \"file\" port: -1 file: \"/root/.sparkStaging/application_1615519194501_0001/__spark_libs__5404052653850104229.zip\" } size: 398449508 timestamp: 1615519203000 type: ARCHIVE visibility: PRIVATE\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]     py4j-0.10.9-src.zip -> resource { scheme: \"file\" port: -1 file: \"/root/.sparkStaging/application_1615519194501_0001/py4j-0.10.9-src.zip\" } size: 41587 timestamp: 1615519204000 type: FILE visibility: PRIVATE\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr]     __spark_conf__ -> resource { scheme: \"file\" port: -1 file: \"/root/.sparkStaging/application_1615519194501_0001/__spark_conf__.zip\" } size: 262561 timestamp: 1615519205000 type: ARCHIVE visibility: PRIVATE\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] ===============================================================================\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:11,308 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:11,309 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:11,335 INFO yarn.YarnAllocator: Will request 1 executor container(s), each with 16 core(s) and 61316 MB memory (including 5574 MB of overhead)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,523 INFO ui.ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,526 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2f989812{/metrics/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,560 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,581 INFO allocator.AbstractContainerAllocator: assignedContainer application attempt=appattempt_1615519194501_0001_000001 container=null queue=default clusterResource=<memory:63569, vCores:16> type=OFF_SWITCH requestedPartition=\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,581 INFO rmcontainer.RMContainerImpl: container_1615519194501_0001_01_000002 Container Transitioned from NEW to ALLOCATED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,581 INFO fica.FiCaSchedulerNode: Assigned container container_1615519194501_0001_01_000002 of capacity <memory:61316, vCores:1> on host algo-1:43837, which has 2 containers, <memory:62212, vCores:2> used and <memory:1357, vCores:14> available after allocation\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,581 INFO resourcemanager.RMAuditLogger: USER=root#011OPERATION=AM Allocated Container#011TARGET=SchedulerApp#011RESULT=SUCCESS#011APPID=application_1615519194501_0001#011CONTAINERID=container_1615519194501_0001_01_000002#011RESOURCE=<memory:61316, vCores:1>#011QUEUENAME=default\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,581 INFO capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.97865313 absoluteUsedCapacity=0.97865313 used=<memory:62212, vCores:2> cluster=<memory:63569, vCores:16>\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,581 INFO capacity.CapacityScheduler: Allocation proposal accepted\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,686 INFO security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : algo-1:43837 for container : container_1615519194501_0001_01_000002\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,687 INFO rmcontainer.RMContainerImpl: container_1615519194501_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000001/stderr] 2021-03-12 03:20:11,359 INFO yarn.YarnAllocator: Submitted 1 unloINFO:root:Running with these Spark Configs:\u001b[0m\n",
      "\u001b[34mINFO:root:[('spark.driver.extraLibraryPath',\n",
      "  '/usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native'),\n",
      " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES',\n",
      "  'http://algo-1:8088/proxy/application_1615519194501_0001'),\n",
      " ('spark.ui.proxyBase', '/proxy/application_1615519194501_0001'),\n",
      " ('spark.executor.memoryOverhead', '5574m'),\n",
      " ('spark.executor.memory', '55742m'),\n",
      " ('spark.app.id', 'application_1615519194501_0001'),\n",
      " ('spark.serializer.objectStreamReset', '100'),\n",
      " ('spark.default.parallelism', '32'),\n",
      " ('spark.executor.cores', '16'),\n",
      " ('spark.submit.deployMode', 'client'),\n",
      " ('spark.ui.filters',\n",
      "  'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'),\n",
      " ('spark.driver.extraClassPath',\n",
      "  '/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar'),\n",
      " ('spark.driver.memoryOverhead', '204m'),\n",
      " ('spark.executor.id', 'driver'),\n",
      " ('spark.executor.extraClassPath',\n",
      "  '/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar'),\n",
      " ('spark.driver.port', '35737'),\n",
      " ('spark.executorEnv.PYTHONPATH',\n",
      "  '{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9-src.zip'),\n",
      " ('spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version', '2'),\n",
      " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS',\n",
      "  'algo-1'),\n",
      " ('spark.driver.host', '10.0.174.129'),\n",
      " ('spark.driver.defaultJavaOptions',\n",
      "  \"-XX:OnOutOfMemoryError='kill -9 %p' -XX:+UseConcMarkSweepGC \"\n",
      "  '-XX:CMSInitiatingOccupancyFraction=70 -XX:MaxHeapFreeRatio=70 '\n",
      "  '-XX:+CMSClassUnloadingEnabled'),\n",
      " ('spark.master', 'yarn'),\n",
      " ('spark.driver.memory', '2048m'),\n",
      " ('spark.rdd.compress', 'True'),\n",
      " ('spark.executor.extraLibraryPath',\n",
      "  '/usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native'),\n",
      " ('spark.executor.instances', '1'),\n",
      " ('spark.submit.pyFiles', ''),\n",
      " ('spark.yarn.isPython', 'true'),\n",
      " ('spark.executor.defaultJavaOptions',\n",
      "  \"-verbose:gc -XX:OnOutOfMemoryError='kill -9 %p' -XX:+PrintGCDetails \"\n",
      "  '-XX:+PrintGCDateStamps -XX:+UseParallelGC '\n",
      "  '-XX:InitiatingHeapOccupancyPercent=70 -XX:ConcGCThreads=4 '\n",
      "  '-XX:ParallelGCThreads=12'),\n",
      " ('spark.driver.appUIAddress', 'http://10.0.174.129:4040'),\n",
      " ('spark.app.name', 'processing_entrypoint.py')]\u001b[0m\n",
      "\u001b[34mINFO:root:Output Config: {\n",
      "    \"e4adff78-b977-4b75-b975-ef25e26f348f.default\": {\n",
      "        \"content_type\": \"CSV\"\n",
      "    }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mINFO:root:No `default` configuration provided. Content type will default to CSV for all outputs not specified in the output config.\u001b[0m\n",
      "\u001b[34mINFO:entrypoint:Processing Job Config: {\n",
      "    \"ProcessingJobArn\": \"arn:aws:sagemaker:ap-northeast-1:024103970757:processing-job/credit-flow-2021-03-12-03-14-57\",\n",
      "    \"ProcessingJobName\": \"credit-flow-2021-03-12-03-14-57\",\n",
      "    \"AppSpecification\": {\n",
      "        \"ImageUri\": \"649008135260.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-data-wrangler-container:1.3.0\",\n",
      "        \"ContainerEntrypoint\": null,\n",
      "        \"ContainerArguments\": [\n",
      "            \"--output-config '{\\\"e4adff78-b977-4b75-b975-ef25e26f348f.default\\\": {\\\"content_type\\\": \\\"CSV\\\"}}'\"\n",
      "        ]\n",
      "    },\n",
      "    \"ProcessingInputs\": [\n",
      "        {\n",
      "            \"InputName\": \"flow\",\n",
      "            \"AppManaged\": false,\n",
      "            \"S3Input\": {\n",
      "                \"LocalPath\": \"/opt/ml/processing/flow\",\n",
      "                \"S3Uri\": \"s3://creditmodel-mlsandbox-024103970757-ap-northeast-1/data-wrangler/credit-flow-2021-03-12-03-14-57/flow/credit-data.flow\",\n",
      "                \"S3DataDistributionType\": \"FullyReplicated\",\n",
      "                \"S3DataType\": \"S3Prefix\",\n",
      "                \"S3InputMode\": \"File\",\n",
      "                \"S3CompressionType\": \"None\",\n",
      "                \"S3DownloadMode\": \"StartOfJob\"\n",
      "            },\n",
      "            \"DatasetDefinition\": null\n",
      "        },\n",
      "        {\n",
      "            \"InputName\": \"german.csv\",\n",
      "            \"AppManaged\": false,\n",
      "            \"S3Input\": {\n",
      "                \"LocalPath\": \"/opt/ml/processing/german.csv\",\n",
      "                \"S3Uri\": \"s3://creditmodel-mlrawdata-024103970757-ap-northeast-1/german.csv\",\n",
      "                \"S3DataDistributionType\": \"FullyReplicated\",\n",
      "                \"S3DataType\": \"S3Prefix\",\n",
      "                \"S3InputMode\": \"File\",\n",
      "                \"S3CompressionType\": \"None\",\n",
      "                \"S3DownloadMode\": \"StartOfJob\"\n",
      "            },\n",
      "            \"DatasetDefinition\": null\n",
      "        }\n",
      "    ],\n",
      "    \"ProcessingOutputConfig\": {\n",
      "        \"Outputs\": [\n",
      "            {\n",
      "                \"OutputName\": \"e4adff78-b977-4b75-b975-ef25e26f348f.default\",\n",
      "                \"AppManaged\": false,\n",
      "                \"S3Output\": {\n",
      "                    \"LocalPath\": \"/opt/ml/processing/output\",\n",
      "                    \"S3Uri\": \"s3://creditmodel-mlsandbox-024103970757-ap-northeast-1/data-wrangler\",\n",
      "                    \"S3UploadMode\": \"EndOfJob\"\n",
      "                },\n",
      "                \"FeatureStoreOutput\": null\n",
      "            }\n",
      "        ],\n",
      "        \"KmsKeyId\": null\n",
      "    },\n",
      "    \"ProcessingResources\": {\n",
      "        \"ClusterConfig\": {\n",
      "            \"InstanceCount\": 1,\n",
      "            \"InstanceType\": \"ml.m5.4xlarge\",\n",
      "            \"VolumeSizeInGB\": 30,\n",
      "            \"VolumeKmsKeyId\": null\n",
      "        }\n",
      "    },\n",
      "    \"RoleArn\": \"arn:aws:iam::024103970757:role/mlopsintro-SageMakerExecutionRole-TK3Y6YQI58VH\",\n",
      "    \"StoppingCondition\": {\n",
      "        \"MaxRuntimeInSeconds\": 86400\n",
      "    }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mWARNING:root:Skipping reading sagemaker.read_csv as it's part of whitelist\u001b[0m\n",
      "\u001b[34mWARNING:root:Skipping reading sagemaker.spark.join_tables as it's part of whitelist\u001b[0m\n",
      "\u001b[34mWARNING:root:Skipping reading sagemaker.spark.concatenate_datasets as it's part of whitelist\u001b[0m\n",
      "\u001b[34mWARNING:root:Skipping reading sagemaker.spark.cast_type as it's part of whitelist\u001b[0m\n",
      "\u001b[34mWARNING:root:Skipping reading sagemaker.spark.infer_and_cast_type as it's part of whitelist\u001b[0m\n",
      "\u001b[34mINFO:root:Resolving logical graph\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,825 INFO ipc.Server: Auth successful for appattempt_1615519194501_0001_000001 (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,828 INFO containermanager.ContainerManagerImpl: Start request for container_1615519194501_0001_01_000002 by user root\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,830 INFO application.ApplicationImpl: Adding container_1615519194501_0001_01_000002 to application application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,830 INFO nodemanager.NMAuditLogger: USER=root#011IP=10.0.174.129#011OPERATION=Start Container Request#011TARGET=ContainerManageImpl#011RESULT=SUCCESS#011APPID=application_1615519194501_0001#011CONTAINERID=container_1615519194501_0001_01_000002\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,831 INFO container.ContainerImpl: Container container_1615519194501_0001_01_000002 transitioned from NEW to LOCALIZING\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,831 INFO containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,831 INFO container.ContainerImpl: Container container_1615519194501_0001_01_000002 transitioned from LOCALIZING to SCHEDULED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,831 INFO scheduler.ContainerScheduler: Starting container [container_1615519194501_0001_01_000002]\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,846 INFO container.ContainerImpl: Container container_1615519194501_0001_01_000002 transitioned from SCHEDULED to RUNNING\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,846 INFO monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1615519194501_0001_01_000002\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,849 INFO nodemanager.DefaultContainerExecutor: launchContainer: [bash, /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001/container_1615519194501_0001_01_000002/default_container_executor.sh]\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/prelaunch.out\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/prelaunch.err\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/launch_container.sh\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:11,868 INFO util.TypeUtil: JVM Runtime does not support Modules\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stdout\u001b[0m\n",
      "\u001b[34mHandling create event for file: /var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:12,583 INFO rmcontainer.RMContainerImpl: container_1615519194501_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 144989 1372 -r-x------   1 root     root      1400944 Mar 12 03:20 ./__spark_libs__/jackson-databind-2.10.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 144990  196 -r-x------   1 root     root       197176 Mar 12 03:20 ./__spark_libs__/commons-text-1.6.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 144991 1024 -r-x------   1 root     root      1045744 Mar 12 03:20 ./__spark_libs__/leveldbjni-all-1.8.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 144992   64 -r-x------   1 root     root        65261 Mar 12 03:20 ./__spark_libs__/oro-2.0.8.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 144993 10424 -r-x------   1 root     root     10672015 Mar 12 03:20 ./__spark_libs__/scala-compiler-2.12.10.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 144994   36 -r-x------   1 root     root        33031 Mar 12 03:20 ./__spark_libs__/jsr305-3.0.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 144995   28 -r-x------   1 root     root        26514 Mar 12 03:20 ./__spark_libs__/stax-api-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 144996  116 -r-x------   1 root     root       116120 Mar 12 03:20 ./__spark_libs__/kerb-crypto-1.0.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145230  356 -r-x------   1 root     root       360692 Mar 12 03:20 ./__spark_libs__/aws-java-sdk-comprehendmedical-1.11.828.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 144997  636 -r-x------   1 root     root       649950 Mar 12 03:20 ./__spark_libs__/lz4-java-1.7.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 144998   32 -r-x------   1 root     root        30035 Mar 12 03:20 ./__spark_libs__/accessors-smart-1.2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145231  804 -r-x------   1 root     root       822890 Mar 12 03:20 ./__spark_libs__/aws-java-sdk-kinesisanalyticsv2-1.11.828.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 144999   88 -r-x------   1 root     root        87051 Mar 12 03:20 ./__spark_libs__/spark-network-shuffle_2.12-3.0.0-amzn-0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145232  252 -r-x------   1 root     root       254246 Mar 12 03:20 ./__spark_libs__/aws-java-sdk-acm-1.11.828.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145000  268 -r-x------   1 root     root       273370 Mar 12 03:20 ./__spark_libs__/commons-net-3.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145001  472 -r-x------   1 root     root       482486 Mar 12 03:20 ./__spark_libs__/json4s-core_2.12-3.6.6.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145002  244 -r-x------   1 root     root       246445 Mar 12 03:20 ./__spark_libs__/libthrift-0.12.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145003 4112 -r-x------   1 root     root      4210625 Mar 12 03:20 ./__spark_libs__/zstd-jni-1.4.4-3.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145233 1068 -r-x------   1 root     root      1091650 Mar 12 03:20 ./__spark_libs__/aws-java-sdk-opsworks-1.11.828.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145234  184 -r-x------   1 root     root       186523 Mar 12 03:20 ./__spark_libs__/aws-java-sdk-textract-1.11.828.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145240  492 -r-x------   1 root     root       501702 Mar 12 03:20 ./__spark_libs__/hadoop-aws-3.2.1-amzn-1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145004 1024 -r-x------   1 root     root      1048530 Mar 12 03:20 ./__spark_libs__/parquet-jackson-1.10.1-spark-amzn-2.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145005 1456 -r-x------   1 root     root      1489507 Mar 12 03:20 ./__spark_libs__/netlib-native_ref-linux-i686-1.1-natives.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145235  896 -r-x------   1 root     root       913853 Mar 12 03:20 ./__spark_libs__/aws-java-sdk-simpleworkflow-1.11.828.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145006  200 -r-x------   1 root     root       203358 Mar 12 03:20 ./__spark_libs__/hk2-locator-2.6.1.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145236    4 -r-x------   1 root     root         4031 Mar 12 03:20 ./__spark_libs__/aws-java-sdk-1.11.828.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145007  416 -r-x------   1 root     root       423175 Mar 12 03:20 ./__spark_libs__/okhttp-3.12.6.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145237  136 -r-x------   1 root     root       137101 Mar 12 03:20 ./__spark_libs__/aws-java-sdk-lex-1.11.828.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145008   20 -r-x------   1 root     root        18497 Mar 12 03:20 ./__spark_libs__/flatbuffers-java-1.9.0.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145238 1008 -r-x------   1 root     root      1029561 Mar 12 03:20 ./__spark_libs__/aws-java-sdk-dms-1.11.828.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145239  492 -r-x------   1 root     root       501832 Mar 12 03:20 ./__spark_libs__/aws-java-sdk-amplify-1.11.828.jar\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145314    4 -rwx------   1 root     root          668 Mar 12 03:20 ./default_container_executor_session.sh\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145243    4 drwx------   3 root     root         4096 Mar 12 03:20 ./__spark_conf__\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145244   16 -r-x------   1 root     root        14890 Mar 12 03:20 ./__spark_conf__/log4j.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145270    4 -r-x------   1 root     root          686 Mar 12 03:20 ./__spark_conf__/__spark_dist_cache__.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145269    4 -r-x------   1 root     root         2525 Mar 12 03:20 ./__spark_conf__/__spark_conf__.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145268  128 -r-x------   1 root     root       129009 Mar 12 03:20 ./__spark_conf__/__spark_hadoop_conf__.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145245    4 drwx------   2 root     root         4096 Mar 12 03:20 ./__spark_conf__/__hadoop_conf__\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145246   16 -r-x------   1 root     root        14890 Mar 12 03:20 ./__spark_conf__/__hadoop_conf__/log4j.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145247   16 -r-x------   1 root     root        16380 Mar 12 03:20 ./__spark_conf__/__hadoop_conf__/hadoop-env.sh\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145251   12 -r-x------   1 root     root         8260 Mar 12 03:20 ./__spark_conf__/__hadoop_conf__/capacity-scheduler.xml.default\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145254   12 -r-x------   1 root     root         8260 Mar 12 03:20 ./__spark_conf__/__hadoop_conf__/capacity-scheduler.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145248    4 -r-x------   1 root     root          758 Mar 12 03:20 ./__spark_conf__/__hadoop_conf__/mapred-site.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145259    4 -r-x------   1 root     root         1940 Mar 12 03:20 ./__spark_conf__/__hadoop_conf__/container-executor.cfg\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145265    4 -r-x------   1 root     root         2697 Mar 12 03:20 ./__spark_conf__/__hadoop_conf__/ssl-server.xml.example\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145264    4 -r-x------   1 root     root         3593 Mar 12 03:20 ./__spark_conf__/__hadoop_conf__/container-log4j.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145263   12 -r-x------   1 root     root        11392 Mar 12 03:20 ./__spark_conf__/__hadoop_conf__/hadoop-policy.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145249    4 -r-x------   1 root     root         3321 Mar 12 03:20 ./__spark_conf__/__hadoop_conf__/hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145267    4 -r-x------   1 root     root         1764 Mar 12 03:20 ./__spark_conf__/__hadoop_conf__/mapred-env.sh.default\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145252    4 -r-x------   1 root     root          986 Mar 12 03:20 ./__spark_conf__/__hadoop_conf__/core-site.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145253    4 -r-x------   1 root     root           10 Mar 12 03:20 ./__spark_conf__/__hadoop_conf__/workers\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145266    8 -r-x------   1 root     root         4113 Mar 12 03:20 ./__spark_conf__/__hadoop_conf__/mapred-queues.xml.template\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145261    4 -r-x------   1 root     root         2316 Mar 12 03:20 ./__spark_conf__/__hadoop_conf__/ssl-client.xml.example\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145258    4 -r-x------   1 root     root          764 Mar 12 03:20 ./__spark_conf__/__hadoop_conf__/hdfs-site.xml\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/directory.info] 145262   16 -r-x------   1 root     root        14890 Mar 12 03:20 ./__spark_conf__/__hadoop_conf__/lINFO:root:Adding head\u001b[0m\n",
      "\u001b[34mINFO:root:Adding column limit\u001b[0m\n",
      "\u001b[34mINFO:root:Adding caching\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:13,397 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/sagemaker-user/spark-warehouse').\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:13,397 INFO internal.SharedState: Warehouse path is 'file:/home/sagemaker-user/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:13,412 INFO ui.ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:13,413 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@277d51d9{/SQL,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:13,414 INFO ui.ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:13,415 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2c0c9d6b{/SQL/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:13,415 INFO ui.ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:13,416 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@928d051{/SQL/execution,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:13,416 INFO ui.ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:13,417 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@64027957{/SQL/execution/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:13,418 INFO ui.ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:13,419 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2373b059{/static/sql,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:13,797 INFO monitor.ContainersMonitorImpl: container_1615519194501_0001_01_000002's ip = 10.0.174.129, and hostname = algo-1\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:13,801 INFO monitor.ContainersMonitorImpl: Skipping monitoring container container_1615519194501_0001_01_000002 since CPU usage is not yet available.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:14,114 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(memoryOverhead -> name: memoryOverhead, amount: 5574, script: , vendor: , cores -> name: cores, amount: 16, script: , vendor: , memory -> name: memory, amount: 55742, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:14,154 INFO datasources.InMemoryFileIndex: It took 29 ms to list leaf files for 1 paths.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:14,213 INFO datasources.InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:14,709 INFO scheduler.AppSchedulingInfo: checking for deactivate of application :application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:12,970 INFO executor.CoarseGrainedExecutorBackend: Started daemon with process name: 1282@algo-1\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:12,980 INFO util.SignalUtils: Registered signal handler for TERM\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:12,981 INFO util.SignalUtils: Registered signal handler for HUP\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:12,981 INFO util.SignalUtils: Registered signal handler for INT\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:13,637 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:13,637 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:13,638 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:13,638 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:13,638 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:14,055 INFO client.TransportClientFactory: Successfully created connection to /10.0.174.129:35737 after 80 ms (0 ms spent in bootstraps)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:14,197 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:14,197 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:14,197 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:14,197 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:14,197 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:14,262 INFO client.TransportClientFactory: Successfully created connection to /10.0.174.129:35737 after 1 ms (0 ms spent in bootstraps)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:14,336 INFO storage.DiskBlockManager: Created local directory at /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001/blockmgr-15251f3c-3141-430b-9efc-399c784844ff\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:14,383 INFO memory.MemoryStore: MemoryStore started with capacity 28.9 GiB\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:14,930 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.174.129:47554) with ID 1\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:15,074 INFO storage.BlockManagerMasterEndpoint: Registering block manager algo-1:38713 with 28.9 GiB RAM, BlockManagerId(1, algo-1, 38713, None)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:14,780 INFO executor.YarnCoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@10.0.174.129:35737\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:14,791 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:14,793 INFO resource.ResourceUtils: Resources for spark.executor:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:14,793 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:14,937 INFO executor.YarnCoarseGrainedExecutorBackend: Successfully registered with driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:14,942 INFO executor.Executor: Starting executor ID 1 on host algo-1\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:14,973 WARN executor.YarnCoarseGrainedExecutorBackend: eagerFSInit: Unable to eagerly init filesystem s3://does/not/exist\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"s3\"\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3336)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3356)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:123)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3407)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3375)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:486)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at org.apache.spark.executor.CoarseGrainedExecutorBackend.$anonfun$eagerFSInit$1(CoarseGrainedExecutorBackend.scala:274)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at scala.collection.parallel.mutable.ParArray$ParArrayIterator.flatmap2combiner(ParArray.scala:419)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at scala.collection.parallel.ParIterableLike$FlatMap.leaf(ParIterableLike.scala:1074)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at scala.collection.parallel.Task.$anonfun$tryLeaf$1(Tasks.scala:53)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at scala.util.control.Breaks$$anon$1.catchBreak(Breaks.scala:67)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:16,399 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:16,403 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:16,403 INFO datasources.FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:16,407 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:16,896 INFO codegen.CodeGenerator: Code generated in 248.573857 ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:16,957 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 313.9 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,007 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,010 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.174.129:39501 (size: 29.9 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,012 INFO spark.SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,057 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 1, prefetch: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,062 INFO execution.FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,1))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,146 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,160 INFO scheduler.DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,161 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,161 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,162 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,166 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,225 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.8 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,227 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,228 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.174.129:39501 (size: 5.4 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,228 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,243 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,244 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,279 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7755 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:17,564 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on algo-1:38713 (size: 5.4 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at scala.collection.parallel.Task.tryLeaf(Tasks.scala:56)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at scala.collection.parallel.Task.tryLeaf$(Tasks.scala:50)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at scala.collection.parallel.ParIterableLike$FlatMap.tryLeaf(ParIterableLike.scala:1070)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at scala.collection.parallel.FutureTasks.$anonfun$exec$5(Tasks.scala:499)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at scala.util.Success.$anonfun$map$1(Try.scala:255)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at scala.util.Success.map(Try.scala:213)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] #011at java.lang.Thread.run(Thread.java:748)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:15,050 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38713.\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:15,050 INFO netty.NettyBlockTransferService: Server created on algo-1:38713\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:15,052 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:15,067 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(1, algo-1, 38713, None)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:15,077 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(1, algo-1, 38713, None)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:15,078 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(1, algo-1, 38713, None)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:17,303 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 0\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:17,312 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,613 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on algo-1:38713 (size: 29.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,789 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1519 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,791 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,797 INFO scheduler.DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.618 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,800 INFO scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,800 INFO cluster.YarnScheduler: Killing all running tasks in stage 0: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,802 INFO scheduler.DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.655629 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,836 INFO codegen.CodeGenerator: Code generated in 12.906567 ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,839 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.174.129:39501 in memory (size: 5.4 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,853 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on algo-1:38713 in memory (size: 5.4 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,895 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,895 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,895 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,896 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,901 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 313.9 KiB, free 1007.2 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,910 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 1007.2 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,911 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.174.129:39501 (size: 29.9 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,912 INFO spark.SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,912 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 1, prefetch: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:18,912 INFO execution.FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,1))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,051 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 10.0.174.129:39501 in memory (size: 29.9 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,054 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on algo-1:38713 in memory (size: 29.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,060 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on 10.0.174.129:39501 in memory (size: 29.9 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,270 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,271 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,271 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,271 INFO datasources.FileSourceStrategy: Output Data Schema: struct<marital_status_and_gender: string>\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,309 INFO codegen.CodeGenerator: Code generated in 20.548109 ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,312 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 313.9 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,322 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,323 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.174.129:39501 (size: 29.9 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,323 INFO spark.SparkContext: Created broadcast 3 from rdd at CountVectorizer.scala:191\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,327 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 1, prefetch: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,328 INFO execution.FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,1))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,360 INFO spark.SparkContext: Starting job: count at CountVectorizer.scala:197\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,361 INFO scheduler.DAGScheduler: Got job 1 (count at CountVectorizer.scala:197) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,362 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (count at CountVectorizer.scala:197)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,362 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,364 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,364 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[16] at map at CountVectorizer.scala:191), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,409 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 30.1 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,411 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.2 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,411 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.174.129:39501 (size: 14.2 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,412 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,412 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[16] at map at CountVectorizer.scala:191) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,412 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,414 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7755 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:20,429 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on algo-1:38713 (size: 14.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:17,439 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:17,501 INFO client.TransportClientFactory: Successfully created connection to /10.0.174.129:39501 after 1 ms (0 ms spent in bootstraps)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:17,559 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:17,570 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 130 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:17,667 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.8 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:18,496 INFO codegen.CodeGenerator: Code generated in 281.45351 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:18,531 INFO datasources.FileScanRDD: TID: 0 - Reading current file: path: file:///opt/ml/processing/german.csv/german.csv, range: 0-137181, partition values: [empty row], isDataPresent: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:18,602 INFO codegen.CodeGenerator: Code generated in 11.993628 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:18,604 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:18,611 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:18,614 INFO broadcast.TorrentBroadcast: Reading broadcast variable 0 took 9 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:18,671 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 561.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:18,777 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 1888 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:20,416 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 1\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:20,416 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 1)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:20,421 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:20,427 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.2 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:20,430 INFO broadcast.TorrentBroadcast: Reading broadcast variable 4 took 9 ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:21,998 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on algo-1:38713 (size: 29.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,192 INFO storage.BlockManagerInfo: Added rdd_16_0 in memory on algo-1:38713 (size: 202.0 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,209 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1796 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,209 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,210 INFO scheduler.DAGScheduler: ResultStage 1 (count at CountVectorizer.scala:197) finished in 1.845 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,210 INFO scheduler.DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,210 INFO cluster.YarnScheduler: Killing all running tasks in stage 1: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,211 INFO scheduler.DAGScheduler: Job 1 finished: count at CountVectorizer.scala:197, took 1.850246 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,250 INFO spark.SparkContext: Starting job: count at CountVectorizer.scala:233\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,258 INFO scheduler.DAGScheduler: Registering RDD 17 (flatMap at CountVectorizer.scala:212) as input to shuffle 0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,261 INFO scheduler.DAGScheduler: Got job 2 (count at CountVectorizer.scala:233) with 32 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,261 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (count at CountVectorizer.scala:233)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,261 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,262 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 2)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,264 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at flatMap at CountVectorizer.scala:212), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,279 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 32.2 KiB, free 1007.4 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,280 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.4 KiB, free 1007.4 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,281 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.174.129:39501 (size: 15.4 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,281 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,284 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at flatMap at CountVectorizer.scala:212) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,284 INFO cluster.YarnScheduler: Adding task set 2.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,289 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7744 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,304 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on algo-1:38713 (size: 15.4 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,446 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 159 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,447 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,448 INFO scheduler.DAGScheduler: ShuffleMapStage 2 (flatMap at CountVectorizer.scala:212) finished in 0.181 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,448 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,449 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,449 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 3)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,449 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,452 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at map at CountVectorizer.scala:230), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,463 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 5.4 KiB, free 1007.4 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,464 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1007.4 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,465 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.174.129:39501 (size: 3.0 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,465 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,466 INFO scheduler.DAGScheduler: Submitting 32 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at map at CountVectorizer.scala:230) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,466 INFO cluster.YarnScheduler: Adding task set 3.0 with 32 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,469 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 3, algo-1, executor 1, partition 1, NODE_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,469 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 3.0 (TID 4, algo-1, executor 1, partition 8, NODE_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,469 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 3.0 (TID 5, algo-1, executor 1, partition 14, NODE_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,469 INFO scheduler.TaskSetManager: Starting task 20.0 in stage 3.0 (TID 6, algo-1, executor 1, partition 20, NODE_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,470 INFO scheduler.TaskSetManager: Starting task 25.0 in stage 3.0 (TID 7, algo-1, executor 1, partition 25, NODE_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,470 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 8, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,470 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 3.0 (TID 9, algo-1, executor 1, partition 2, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,470 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 3.0 (TID 10, algo-1, executor 1, partition 3, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,470 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 3.0 (TID 11, algo-1, executor 1, partition 4, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,471 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 3.0 (TID 12, algo-1, executor 1, partition 5, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,471 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 3.0 (TID 13, algo-1, executor 1, partition 6, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,471 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 3.0 (TID 14, algo-1, executor 1, partition 7, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,472 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 3.0 (TID 15, algo-1, executor 1, partition 9, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,472 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 3.0 (TID 16, algo-1, executor 1, partition 10, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,472 INFO scheduler.TaskSetManager: Starting task 11.0 in stage 3.0 (TID 17, algo-1, executor 1, partition 11, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,472 INFO scheduler.TaskSetManager: Starting task 12.0 in stage 3.0 (TID 18, algo-1, executor 1, partition 12, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,497 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on algo-1:38713 (size: 3.0 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,531 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.174.129:47554\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,625 INFO storage.BlockManagerInfo: Added rdd_20_10 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,626 INFO storage.BlockManagerInfo: Added rdd_20_6 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,629 INFO storage.BlockManagerInfo: Added rdd_20_0 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,629 INFO storage.BlockManagerInfo: Added rdd_20_11 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,630 INFO storage.BlockManagerInfo: Added rdd_20_4 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,630 INFO storage.BlockManagerInfo: Added rdd_20_7 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,630 INFO storage.BlockManagerInfo: Added rdd_20_2 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,631 INFO storage.BlockManagerInfo: Added rdd_20_12 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,631 INFO storage.BlockManagerInfo: Added rdd_20_3 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,632 INFO storage.BlockManagerInfo: Added rdd_20_5 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,633 INFO storage.BlockManagerInfo: Added rdd_20_9 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,635 INFO storage.BlockManagerInfo: Added rdd_20_25 in memory on algo-1:38713 (size: 160.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,636 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 3.0 (TID 19, algo-1, executor 1, partition 13, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,637 INFO storage.BlockManagerInfo: Added rdd_20_8 in memory on algo-1:38713 (size: 160.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,638 INFO scheduler.TaskSetManager: Finished task 10.0 in stage 3.0 (TID 16) in 166 ms on algo-1 (executor 1) (1/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,641 INFO storage.BlockManagerInfo: Added rdd_20_20 in memory on algo-1:38713 (size: 160.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,643 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 3.0 (TID 20, algo-1, executor 1, partition 15, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,643 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 8) in 173 ms on algo-1 (executor 1) (2/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,644 INFO scheduler.TaskSetManager: Starting task 16.0 in stage 3.0 (TID 21, algo-1, executor 1, partition 16, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,647 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 3.0 (TID 13) in 173 ms on algo-1 (executor 1) (3/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,647 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 3.0 (TID 22, algo-1, executor 1, partition 17, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,648 INFO scheduler.TaskSetManager: Starting task 18.0 in stage 3.0 (TID 23, algo-1, executor 1, partition 18, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,649 INFO scheduler.TaskSetManager: Starting task 19.0 in stage 3.0 (TID 24, algo-1, executor 1, partition 19, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,650 INFO scheduler.TaskSetManager: Starting task 21.0 in stage 3.0 (TID 25, algo-1, executor 1, partition 21, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,650 INFO scheduler.TaskSetManager: Starting task 22.0 in stage 3.0 (TID 26, algo-1, executor 1, partition 22, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,651 INFO scheduler.TaskSetManager: Starting task 23.0 in stage 3.0 (TID 27, algo-1, executor 1, partition 23, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,652 INFO scheduler.TaskSetManager: Finished task 11.0 in stage 3.0 (TID 17) in 180 ms on algo-1 (executor 1) (4/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,652 INFO scheduler.TaskSetManager: Starting task 24.0 in stage 3.0 (TID 28, algo-1, executor 1, partition 24, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,652 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 3.0 (TID 11) in 182 ms on algo-1 (executor 1) (5/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,653 INFO scheduler.TaskSetManager: Finished task 12.0 in stage 3.0 (TID 18) in 180 ms on algo-1 (executor 1) (6/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,653 INFO scheduler.TaskSetManager: Finished task 9.0 in stage 3.0 (TID 15) in 182 ms on algo-1 (executor 1) (7/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,653 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 3.0 (TID 12) in 183 ms on algo-1 (executor 1) (8/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,653 INFO scheduler.TaskSetManager: Starting task 26.0 in stage 3.0 (TID 29, algo-1, executor 1, partition 26, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,653 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 3.0 (TID 14) in 182 ms on algo-1 (executor 1) (9/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,653 INFO scheduler.TaskSetManager: Finished task 25.0 in stage 3.0 (TID 7) in 184 ms on algo-1 (executor 1) (10/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,654 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 3.0 (TID 10) in 184 ms on algo-1 (executor 1) (11/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,654 INFO scheduler.TaskSetManager: Starting task 27.0 in stage 3.0 (TID 30, algo-1, executor 1, partition 27, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,655 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 3.0 (TID 4) in 186 ms on algo-1 (executor 1) (12/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,655 INFO scheduler.TaskSetManager: Starting task 28.0 in stage 3.0 (TID 31, algo-1, executor 1, partition 28, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,655 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 3.0 (TID 9) in 185 ms on algo-1 (executor 1) (13/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,656 INFO scheduler.TaskSetManager: Starting task 29.0 in stage 3.0 (TID 32, algo-1, executor 1, partition 29, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,656 INFO scheduler.TaskSetManager: Finished task 20.0 in stage 3.0 (TID 6) in 187 ms on algo-1 (executor 1) (14/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,660 INFO storage.BlockManagerInfo: Added rdd_20_14 in memory on algo-1:38713 (size: 160.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,660 INFO storage.BlockManagerInfo: Added rdd_20_1 in memory on algo-1:38713 (size: 168.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,662 INFO storage.BlockManagerInfo: Added rdd_20_13 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,667 INFO storage.BlockManagerInfo: Added rdd_20_15 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,683 INFO scheduler.TaskSetManager: Starting task 30.0 in stage 3.0 (TID 33, algo-1, executor 1, partition 30, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,684 INFO scheduler.TaskSetManager: Finished task 14.0 in stage 3.0 (TID 5) in 215 ms on algo-1 (executor 1) (15/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,684 INFO storage.BlockManagerInfo: Added rdd_20_16 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,684 INFO scheduler.TaskSetManager: Starting task 31.0 in stage 3.0 (TID 34, algo-1, executor 1, partition 31, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,686 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 3.0 (TID 3) in 217 ms on algo-1 (executor 1) (16/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,686 INFO scheduler.TaskSetManager: Finished task 13.0 in stage 3.0 (TID 19) in 50 ms on algo-1 (executor 1) (17/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,687 INFO storage.BlockManagerInfo: Added rdd_20_17 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,687 INFO storage.BlockManagerInfo: Added rdd_20_19 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,687 INFO storage.BlockManagerInfo: Added rdd_20_22 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,688 INFO storage.BlockManagerInfo: Added rdd_20_18 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,688 INFO storage.BlockManagerInfo: Added rdd_20_21 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,689 INFO scheduler.TaskSetManager: Finished task 15.0 in stage 3.0 (TID 20) in 46 ms on algo-1 (executor 1) (18/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,693 INFO storage.BlockManagerInfo: Added rdd_20_24 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,694 INFO storage.BlockManagerInfo: Added rdd_20_27 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,694 INFO storage.BlockManagerInfo: Added rdd_20_26 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,695 INFO storage.BlockManagerInfo: Added rdd_20_28 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,695 INFO storage.BlockManagerInfo: Added rdd_20_23 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,703 INFO storage.BlockManagerInfo: Added rdd_20_29 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,703 INFO scheduler.TaskSetManager: Finished task 16.0 in stage 3.0 (TID 21) in 60 ms on algo-1 (executor 1) (19/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,704 INFO scheduler.TaskSetManager: Finished task 17.0 in stage 3.0 (TID 22) in 57 ms on algo-1 (executor 1) (20/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,706 INFO scheduler.TaskSetManager: Finished task 19.0 in stage 3.0 (TID 24) in 57 ms on algo-1 (executor 1) (21/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,706 INFO scheduler.TaskSetManager: Finished task 18.0 in stage 3.0 (TID 23) in 58 ms on algo-1 (executor 1) (22/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,708 INFO scheduler.TaskSetManager: Finished task 22.0 in stage 3.0 (TID 26) in 58 ms on algo-1 (executor 1) (23/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,708 INFO scheduler.TaskSetManager: Finished task 21.0 in stage 3.0 (TID 25) in 59 ms on algo-1 (executor 1) (24/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,724 INFO scheduler.TaskSetManager: Finished task 24.0 in stage 3.0 (TID 28) in 72 ms on algo-1 (executor 1) (25/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,725 INFO scheduler.TaskSetManager: Finished task 28.0 in stage 3.0 (TID 31) in 70 ms on algo-1 (executor 1) (26/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,726 INFO scheduler.TaskSetManager: Finished task 26.0 in stage 3.0 (TID 29) in 73 ms on algo-1 (executor 1) (27/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,726 INFO storage.BlockManagerInfo: Added rdd_20_31 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,727 INFO storage.BlockManagerInfo: Added rdd_20_30 in memory on algo-1:38713 (size: 24.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,727 INFO scheduler.TaskSetManager: Finished task 23.0 in stage 3.0 (TID 27) in 76 ms on algo-1 (executor 1) (28/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,729 INFO scheduler.TaskSetManager: Finished task 27.0 in stage 3.0 (TID 30) in 75 ms on algo-1 (executor 1) (29/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,729 INFO scheduler.TaskSetManager: Finished task 29.0 in stage 3.0 (TID 32) in 73 ms on algo-1 (executor 1) (30/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,731 INFO scheduler.TaskSetManager: Finished task 31.0 in stage 3.0 (TID 34) in 47 ms on algo-1 (executor 1) (31/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,733 INFO scheduler.TaskSetManager: Finished task 30.0 in stage 3.0 (TID 33) in 50 ms on algo-1 (executor 1) (32/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,733 INFO cluster.YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,734 INFO scheduler.DAGScheduler: ResultStage 3 (count at CountVectorizer.scala:233) finished in 0.274 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,734 INFO scheduler.DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,734 INFO cluster.YarnScheduler: Killing all running tasks in stage 3: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,734 INFO scheduler.DAGScheduler: Job 2 finished: count at CountVectorizer.scala:233, took 0.483863 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,763 INFO spark.SparkContext: Starting job: top at CountVectorizer.scala:236\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,764 INFO scheduler.DAGScheduler: Got job 3 (top at CountVectorizer.scala:236) with 32 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,764 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (top at CountVectorizer.scala:236)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,764 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,765 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,766 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[21] at top at CountVectorizer.scala:236), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,772 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 6.5 KiB, free 1007.4 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,774 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.4 KiB, free 1007.4 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,774 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.174.129:39501 (size: 3.4 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,775 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,776 INFO scheduler.DAGScheduler: Submitting 32 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at top at CountVectorizer.scala:236) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,776 INFO cluster.YarnScheduler: Adding task set 5.0 with 32 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,778 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 35, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,778 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 5.0 (TID 36, algo-1, executor 1, partition 1, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,778 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 5.0 (TID 37, algo-1, executor 1, partition 2, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,778 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 5.0 (TID 38, algo-1, executor 1, partition 3, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,778 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 5.0 (TID 39, algo-1, executor 1, partition 4, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,779 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 5.0 (TID 40, algo-1, executor 1, partition 5, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,779 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 5.0 (TID 41, algo-1, executor 1, partition 6, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,779 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 5.0 (TID 42, algo-1, executor 1, partition 7, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,779 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 5.0 (TID 43, algo-1, executor 1, partition 8, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,779 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 5.0 (TID 44, algo-1, executor 1, partition 9, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,780 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 5.0 (TID 45, algo-1, executor 1, partition 10, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,780 INFO scheduler.TaskSetManager: Starting task 11.0 in stage 5.0 (TID 46, algo-1, executor 1, partition 11, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,780 INFO scheduler.TaskSetManager: Starting task 12.0 in stage 5.0 (TID 47, algo-1, executor 1, partition 12, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,780 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 5.0 (TID 48, algo-1, executor 1, partition 13, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,781 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 5.0 (TID 49, algo-1, executor 1, partition 14, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,781 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 5.0 (TID 50, algo-1, executor 1, partition 15, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,807 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on algo-1:38713 (size: 3.4 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,852 INFO scheduler.TaskSetManager: Starting task 16.0 in stage 5.0 (TID 51, algo-1, executor 1, partition 16, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,853 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 5.0 (TID 52, algo-1, executor 1, partition 17, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,854 INFO scheduler.TaskSetManager: Starting task 18.0 in stage 5.0 (TID 53, algo-1, executor 1, partition 18, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,878 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 5.0 (TID 36) in 100 ms on algo-1 (executor 1) (1/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,880 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 5.0 (TID 43) in 101 ms on algo-1 (executor 1) (2/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,882 INFO scheduler.TaskSetManager: Finished task 14.0 in stage 5.0 (TID 49) in 102 ms on algo-1 (executor 1) (3/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,883 INFO scheduler.TaskSetManager: Starting task 19.0 in stage 5.0 (TID 54, algo-1, executor 1, partition 19, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,884 INFO scheduler.TaskSetManager: Starting task 20.0 in stage 5.0 (TID 55, algo-1, executor 1, partition 20, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,885 INFO scheduler.TaskSetManager: Starting task 21.0 in stage 5.0 (TID 56, algo-1, executor 1, partition 21, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,886 INFO scheduler.TaskSetManager: Starting task 22.0 in stage 5.0 (TID 57, algo-1, executor 1, partition 22, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,886 INFO scheduler.TaskSetManager: Starting task 23.0 in stage 5.0 (TID 58, algo-1, executor 1, partition 23, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,887 INFO scheduler.TaskSetManager: Starting task 24.0 in stage 5.0 (TID 59, algo-1, executor 1, partition 24, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:20,432 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 30.2 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:21,891 INFO codegen.CodeGenerator: Code generated in 25.257006 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:21,980 INFO codegen.CodeGenerator: Code generated in 22.874891 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:21,986 INFO datasources.FileScanRDD: TID: 1 - Reading current file: path: file:///opt/ml/processing/german.csv/german.csv, range: 0-137181, partition values: [empty row], isDataPresent: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:21,989 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:21,996 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:21,999 INFO broadcast.TorrentBroadcast: Reading broadcast variable 3 took 9 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,008 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 561.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,190 INFO memory.MemoryStore: Block rdd_16_0 stored as values in memory (estimated size 202.0 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,205 INFO executor.Executor: Finished task 0.0 in stage 1.0 (TID 1). 1665 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,291 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,292 INFO executor.Executor: Running task 0.0 in stage 2.0 (TID 2)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,297 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,302 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.4 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,305 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 8 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,306 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 32.2 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,370 INFO storage.BlockManager: Found block rdd_16_0 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,440 INFO executor.Executor: Finished task 0.0 in stage 2.0 (TID 2). 1929 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,474 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 3\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,474 INFO executor.Executor: Running task 1.0 in stage 3.0 (TID 3)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,474 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 4\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,475 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 5\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,475 INFO executor.Executor: Running task 8.0 in stage 3.0 (TID 4)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,475 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 6\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,476 INFO executor.Executor: Running task 14.0 in stage 3.0 (TID 5)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,476 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 7\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,476 INFO executor.Executor: Running task 20.0 in stage 3.0 (TID 6)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,476 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 8\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,477 INFO executor.Executor: Running task 25.0 in stage 3.0 (TID 7)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,477 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 9\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,477 INFO executor.Executor: Running task 0.0 in stage 3.0 (TID 8)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,477 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 10\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,478 INFO executor.Executor: Running task 2.0 in stage 3.0 (TID 9)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,478 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 11\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,478 INFO executor.Executor: Running task 3.0 in stage 3.0 (TID 10)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,479 INFO spark.MapOutputTrackerWorker: Updating epoch to 1 and clearing cache\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,481 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,483 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 12\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,483 INFO executor.Executor: Running task 4.0 in stage 3.0 (TID 11)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,487 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 13\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,487 INFO executor.Executor: Running task 5.0 in stage 3.0 (TID 12)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,491 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 14\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,491 INFO executor.Executor: Running task 6.0 in stage 3.0 (TID 13)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,492 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 15\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,492 INFO executor.Executor: Running task 7.0 in stage 3.0 (TID 14)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,492 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 16\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,492 INFO executor.Executor: Running task 9.0 in stage 3.0 (TID 15)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,494 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 17\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,494 INFO executor.Executor: Running task 10.0 in stage 3.0 (TID 16)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,494 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 18\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,495 INFO executor.Executor: Running task 11.0 in stage 3.0 (TID 17)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,495 INFO executor.Executor: Running task 12.0 in stage 3.0 (TID 18)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,495 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,499 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 17 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,500 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 5.4 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,520 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,521 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,520 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,521 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,521 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,521 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,522 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,522 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,523 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,523 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,523 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.0.174.129:35737)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,523 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,523 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,523 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,524 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,524 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,524 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,575 INFO spark.MapOutputTrackerWorker: Got the output locations\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,606 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,606 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,606 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,606 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,606 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,607 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,607 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,606 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,607 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,607 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,606 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,607 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,608 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,607 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,606 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,608 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,607 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,608 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,607 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,606 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,607 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,609 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,610 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,610 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,610 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,611 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,610 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,611 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,611 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,611 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 17 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,612 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,612 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,623 INFO memory.MemoryStore: Block rdd_20_10 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,623 INFO memory.MemoryStore: Block rdd_20_6 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,623 INFO memory.MemoryStore: Block rdd_20_12 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,623 INFO memory.MemoryStore: Block rdd_20_2 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,624 INFO memory.MemoryStore: Block rdd_20_0 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,624 INFO memory.MemoryStore: Block rdd_20_11 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,624 INFO memory.MemoryStore: Block rdd_20_4 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,624 INFO memory.MemoryStore: Block rdd_20_5 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,625 INFO memory.MemoryStore: Block rdd_20_7 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,625 INFO memory.MemoryStore: Block rdd_20_3 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,629 INFO memory.MemoryStore: Block rdd_20_9 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,631 INFO executor.Executor: Finished task 10.0 in stage 3.0 (TID 16). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,632 INFO executor.Executor: Finished task 0.0 in stage 3.0 (TID 8). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,632 INFO executor.Executor: Finished task 6.0 in stage 3.0 (TID 13). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,633 INFO memory.MemoryStore: Block rdd_20_25 stored as values in memory (estimated size 160.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,634 INFO executor.Executor: Finished task 11.0 in stage 3.0 (TID 17). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,634 INFO executor.Executor: Finished task 4.0 in stage 3.0 (TID 11). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,635 INFO memory.MemoryStore: Block rdd_20_8 stored as values in memory (estimated size 160.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,636 INFO executor.Executor: Finished task 12.0 in stage 3.0 (TID 18). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,636 INFO executor.Executor: Finished task 5.0 in stage 3.0 (TID 12). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,637 INFO executor.Executor: Finished task 9.0 in stage 3.0 (TID 15). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,637 INFO executor.Executor: Finished task 3.0 in stage 3.0 (TID 10). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,637 INFO memory.MemoryStore: Block rdd_20_20 stored as values in memory (estimated size 160.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,637 INFO executor.Executor: Finished task 7.0 in stage 3.0 (TID 14). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,638 INFO executor.Executor: Finished task 25.0 in stage 3.0 (TID 7). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,639 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 19\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,639 INFO executor.Executor: Running task 13.0 in stage 3.0 (TID 19)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,640 INFO executor.Executor: Finished task 8.0 in stage 3.0 (TID 4). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,644 INFO executor.Executor: Finished task 2.0 in stage 3.0 (TID 9). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,645 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 20\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,645 INFO executor.Executor: Running task 15.0 in stage 3.0 (TID 20)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,645 INFO executor.Executor: Finished task 20.0 in stage 3.0 (TID 6). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,647 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 21\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,648 INFO executor.Executor: Running task 16.0 in stage 3.0 (TID 21)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,648 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,648 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,650 INFO memory.MemoryStore: Block rdd_20_14 stored as values in memory (estimated size 160.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,650 INFO memory.MemoryStore: Block rdd_20_1 stored as values in memory (estimated size 168.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,650 INFO memory.MemoryStore: Block rdd_20_13 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,652 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 22\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,652 INFO executor.Executor: Running task 17.0 in stage 3.0 (TID 22)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,652 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 23\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,652 INFO executor.Executor: Running task 18.0 in stage 3.0 (TID 23)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,652 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 24\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,653 INFO executor.Executor: Running task 19.0 in stage 3.0 (TID 24)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,658 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 25\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,658 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 26\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,658 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,658 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,658 INFO executor.Executor: Running task 22.0 in stage 3.0 (TID 26)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,658 INFO executor.Executor: Running task 21.0 in stage 3.0 (TID 25)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,659 INFO memory.MemoryStore: Block rdd_20_15 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,665 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 27\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,665 INFO executor.Executor: Running task 23.0 in stage 3.0 (TID 27)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,665 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 28\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,665 INFO executor.Executor: Running task 24.0 in stage 3.0 (TID 28)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,667 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 29\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,667 INFO executor.Executor: Running task 26.0 in stage 3.0 (TID 29)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,667 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 30\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,667 INFO executor.Executor: Running task 27.0 in stage 3.0 (TID 30)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,670 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 31\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,670 INFO executor.Executor: Running task 28.0 in stage 3.0 (TID 31)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,675 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 32\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,675 INFO executor.Executor: Running task 29.0 in stage 3.0 (TID 32)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,677 INFO executor.Executor: Finished task 14.0 in stage 3.0 (TID 5). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,677 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,677 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,677 INFO executor.Executor: Finished task 13.0 in stage 3.0 (TID 19). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,678 INFO memory.MemoryStore: Block rdd_20_16 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,679 INFO executor.Executor: Finished task 1.0 in stage 3.0 (TID 3). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,682 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,682 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,682 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,682 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,682 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,682 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,682 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,683 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,683 INFO memory.MemoryStore: Block rdd_20_17 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,683 INFO memory.MemoryStore: Block rdd_20_19 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,683 INFO memory.MemoryStore: Block rdd_20_22 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,684 INFO memory.MemoryStore: Block rdd_20_18 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,684 INFO executor.Executor: Finished task 15.0 in stage 3.0 (TID 20). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,684 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,684 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,685 INFO memory.MemoryStore: Block rdd_20_21 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,688 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,688 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,688 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,688 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,688 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,689 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,689 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,689 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,689 INFO memory.MemoryStore: Block rdd_20_24 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,689 INFO memory.MemoryStore: Block rdd_20_27 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,689 INFO memory.MemoryStore: Block rdd_20_26 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,689 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,689 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,690 INFO memory.MemoryStore: Block rdd_20_28 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,690 INFO memory.MemoryStore: Block rdd_20_23 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,691 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 33\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,691 INFO executor.Executor: Running task 30.0 in stage 3.0 (TID 33)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,691 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,691 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 34\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,691 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,691 INFO executor.Executor: Running task 31.0 in stage 3.0 (TID 34)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,692 INFO executor.Executor: Finished task 16.0 in stage 3.0 (TID 21). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,696 INFO memory.MemoryStore: Block rdd_20_29 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,696 INFO executor.Executor: Finished task 17.0 in stage 3.0 (TID 22). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,701 INFO executor.Executor: Finished task 19.0 in stage 3.0 (TID 24). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,701 INFO executor.Executor: Finished task 22.0 in stage 3.0 (TID 26). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,701 INFO executor.Executor: Finished task 18.0 in stage 3.0 (TID 23). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,702 INFO executor.Executor: Finished task 21.0 in stage 3.0 (TID 25). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,704 INFO executor.Executor: Finished task 24.0 in stage 3.0 (TID 28). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,707 INFO executor.Executor: Finished task 28.0 in stage 3.0 (TID 31). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,708 INFO executor.Executor: Finished task 26.0 in stage 3.0 (TID 29). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,710 INFO executor.Executor: Finished task 23.0 in stage 3.0 (TID 27). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,710 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,710 INFO executor.Executor: Finished task 27.0 in stage 3.0 (TID 30). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,710 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,710 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,711 INFO executor.Executor: Finished task 29.0 in stage 3.0 (TID 32). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,711 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,711 INFO memory.MemoryStore: Block rdd_20_31 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,712 INFO memory.MemoryStore: Block rdd_20_30 stored as values in memory (estimated size 24.0 B, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,729 INFO executor.Executor: Finished task 31.0 in stage 3.0 (TID 34). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,731 INFO executor.Executor: Finished task 30.0 in stage 3.0 (TID 33). 1305 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,782 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 35\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,782 INFO executor.Executor: Running task 0.0 in stage 5.0 (TID 35)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,783 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 36\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,783 INFO executor.Executor: Running task 1.0 in stage 5.0 (TID 36)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,783 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 37\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,783 INFO executor.Executor: Running task 2.0 in stage 5.0 (TID 37)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,784 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 38\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,784 INFO executor.Executor: Running task 3.0 in stage 5.0 (TID 38)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,784 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 39\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,784 INFO executor.Executor: Running task 4.0 in stage 5.0 (TID 39)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,784 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 40\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,784 INFO executor.Executor: Running task 5.0 in stage 5.0 (TID 40)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,784 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 7 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,785 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 41\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,785 INFO executor.Executor: Running task 6.0 in stage 5.0 (TID 41)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,785 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 42\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,785 INFO executor.Executor: Running task 7.0 in stage 5.0 (TID 42)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,786 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 43\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,786 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 44\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,786 INFO executor.Executor: Running task 9.0 in stage 5.0 (TID 44)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,786 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 45\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,786 INFO executor.Executor: Running task 10.0 in stage 5.0 (TID 45)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,786 INFO executor.Executor: Running task 8.0 in stage 5.0 (TID 43)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,786 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 46\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,787 INFO executor.Executor: Running task 11.0 in stage 5.0 (TID 46)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,789 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 47\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,789 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 48\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,789 INFO executor.Executor: Running task 12.0 in stage 5.0 (TID 47)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,789 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 49\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,789 INFO executor.Executor: Running task 13.0 in stage 5.0 (TID 48)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,789 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 50\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,888 INFO scheduler.TaskSetManager: Starting task 25.0 in stage 5.0 (TID 60, algo-1, executor 1, partition 25, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,888 INFO scheduler.TaskSetManager: Starting task 26.0 in stage 5.0 (TID 61, algo-1, executor 1, partition 26, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,789 INFO executor.Executor: Running task 14.0 in stage 5.0 (TID 49)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,789 INFO executor.Executor: Running task 15.0 in stage 5.0 (TID 50)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,805 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.4 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,808 INFO broadcast.TorrentBroadcast: Reading broadcast variable 7 took 23 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,809 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 6.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,829 INFO storage.BlockManager: Found block rdd_20_4 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,829 INFO storage.BlockManager: Found block rdd_20_12 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,829 INFO storage.BlockManager: Found block rdd_20_15 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,829 INFO storage.BlockManager: Found block rdd_20_8 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,830 INFO storage.BlockManager: Found block rdd_20_9 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,831 INFO storage.BlockManager: Found block rdd_20_7 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,831 INFO storage.BlockManager: Found block rdd_20_6 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,829 INFO storage.BlockManager: Found block rdd_20_11 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,831 INFO storage.BlockManager: Found block rdd_20_14 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,831 INFO storage.BlockManager: Found block rdd_20_1 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,831 INFO storage.BlockManager: Found block rdd_20_3 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,829 INFO storage.BlockManager: Found block rdd_20_13 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,829 INFO storage.BlockManager: Found block rdd_20_5 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,835 INFO storage.BlockManager: Found block rdd_20_10 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,835 INFO storage.BlockManager: Found block rdd_20_2 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,835 INFO storage.BlockManager: Found block rdd_20_0 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,849 INFO executor.Executor: Finished task 8.0 in stage 5.0 (TID 43). 2648 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,849 INFO executor.Executor: Finished task 1.0 in stage 5.0 (TID 36). 2651 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,850 INFO executor.Executor: Finished task 14.0 in stage 5.0 (TID 49). 2650 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,853 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 51\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,853 INFO executor.Executor: Running task 16.0 in stage 5.0 (TID 51)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,855 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 52\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,855 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 53\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,855 INFO executor.Executor: Running task 17.0 in stage 5.0 (TID 52)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,856 INFO executor.Executor: Running task 18.0 in stage 5.0 (TID 53)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,858 INFO storage.BlockManager: Found block rdd_20_16 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,858 INFO storage.BlockManager: Found block rdd_20_17 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,859 INFO storage.BlockManager: Found block rdd_20_18 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,869 INFO executor.Executor: Finished task 13.0 in stage 5.0 (TID 48). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,869 INFO executor.Executor: Finished task 6.0 in stage 5.0 (TID 41). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,869 INFO executor.Executor: Finished task 11.0 in stage 5.0 (TID 46). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,869 INFO executor.Executor: Finished task 7.0 in stage 5.0 (TID 42). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,869 INFO executor.Executor: Finished task 0.0 in stage 5.0 (TID 35). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,874 INFO executor.Executor: Finished task 10.0 in stage 5.0 (TID 45). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,874 INFO executor.Executor: Finished task 12.0 in stage 5.0 (TID 47). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,874 INFO executor.Executor: Finished task 5.0 in stage 5.0 (TID 40). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,889 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 5.0 (TID 41) in 110 ms on algo-1 (executor 1) (4/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,889 INFO scheduler.TaskSetManager: Finished task 11.0 in stage 5.0 (TID 46) in 109 ms on algo-1 (executor 1) (5/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,890 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 35) in 113 ms on algo-1 (executor 1) (6/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,890 INFO scheduler.TaskSetManager: Finished task 10.0 in stage 5.0 (TID 45) in 111 ms on algo-1 (executor 1) (7/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,891 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 5.0 (TID 40) in 113 ms on algo-1 (executor 1) (8/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,891 INFO scheduler.TaskSetManager: Finished task 15.0 in stage 5.0 (TID 50) in 110 ms on algo-1 (executor 1) (9/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,893 INFO scheduler.TaskSetManager: Finished task 13.0 in stage 5.0 (TID 48) in 113 ms on algo-1 (executor 1) (10/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,893 INFO scheduler.TaskSetManager: Starting task 27.0 in stage 5.0 (TID 62, algo-1, executor 1, partition 27, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,894 INFO scheduler.TaskSetManager: Starting task 28.0 in stage 5.0 (TID 63, algo-1, executor 1, partition 28, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,895 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 5.0 (TID 42) in 116 ms on algo-1 (executor 1) (11/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,912 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 5.0 (TID 38) in 117 ms on algo-1 (executor 1) (12/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,913 INFO scheduler.TaskSetManager: Starting task 29.0 in stage 5.0 (TID 64, algo-1, executor 1, partition 29, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,913 INFO scheduler.TaskSetManager: Starting task 30.0 in stage 5.0 (TID 65, algo-1, executor 1, partition 30, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,914 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 5.0 (TID 39) in 136 ms on algo-1 (executor 1) (13/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,914 INFO scheduler.TaskSetManager: Finished task 18.0 in stage 5.0 (TID 53) in 60 ms on algo-1 (executor 1) (14/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,914 INFO scheduler.TaskSetManager: Finished task 9.0 in stage 5.0 (TID 44) in 135 ms on algo-1 (executor 1) (15/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,915 INFO scheduler.TaskSetManager: Starting task 31.0 in stage 5.0 (TID 66, algo-1, executor 1, partition 31, PROCESS_LOCAL, 7154 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,916 INFO scheduler.TaskSetManager: Finished task 16.0 in stage 5.0 (TID 51) in 64 ms on algo-1 (executor 1) (16/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,920 INFO scheduler.TaskSetManager: Finished task 12.0 in stage 5.0 (TID 47) in 140 ms on algo-1 (executor 1) (17/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,921 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 5.0 (TID 37) in 143 ms on algo-1 (executor 1) (18/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,921 INFO scheduler.TaskSetManager: Finished task 23.0 in stage 5.0 (TID 58) in 35 ms on algo-1 (executor 1) (19/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,921 INFO scheduler.TaskSetManager: Finished task 22.0 in stage 5.0 (TID 57) in 36 ms on algo-1 (executor 1) (20/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,921 INFO scheduler.TaskSetManager: Finished task 19.0 in stage 5.0 (TID 54) in 38 ms on algo-1 (executor 1) (21/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,921 INFO scheduler.TaskSetManager: Finished task 17.0 in stage 5.0 (TID 52) in 68 ms on algo-1 (executor 1) (22/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,921 INFO scheduler.TaskSetManager: Finished task 20.0 in stage 5.0 (TID 55) in 37 ms on algo-1 (executor 1) (23/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,923 INFO scheduler.TaskSetManager: Finished task 21.0 in stage 5.0 (TID 56) in 38 ms on algo-1 (executor 1) (24/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,924 INFO scheduler.TaskSetManager: Finished task 27.0 in stage 5.0 (TID 62) in 31 ms on algo-1 (executor 1) (25/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,925 INFO scheduler.TaskSetManager: Finished task 26.0 in stage 5.0 (TID 61) in 37 ms on algo-1 (executor 1) (26/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,925 INFO scheduler.TaskSetManager: Finished task 24.0 in stage 5.0 (TID 59) in 38 ms on algo-1 (executor 1) (27/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,926 INFO scheduler.TaskSetManager: Finished task 30.0 in stage 5.0 (TID 65) in 13 ms on algo-1 (executor 1) (28/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,927 INFO scheduler.TaskSetManager: Finished task 28.0 in stage 5.0 (TID 63) in 33 ms on algo-1 (executor 1) (29/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,928 INFO scheduler.TaskSetManager: Finished task 29.0 in stage 5.0 (TID 64) in 16 ms on algo-1 (executor 1) (30/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,931 INFO scheduler.TaskSetManager: Finished task 25.0 in stage 5.0 (TID 60) in 44 ms on algo-1 (executor 1) (31/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,934 INFO scheduler.TaskSetManager: Finished task 31.0 in stage 5.0 (TID 66) in 19 ms on algo-1 (executor 1) (32/32)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,934 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,938 INFO scheduler.DAGScheduler: ResultStage 5 (top at CountVectorizer.scala:236) finished in 0.170 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,939 INFO scheduler.DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,939 INFO cluster.YarnScheduler: Killing all running tasks in stage 5: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,939 INFO scheduler.DAGScheduler: Job 3 finished: top at CountVectorizer.scala:236, took 0.176382 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,941 INFO rdd.MapPartitionsRDD: Removing RDD 16 from persistence list\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,956 INFO storage.BlockManager: Removing RDD 16\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,964 INFO rdd.MapPartitionsRDD: Removing RDD 20 from persistence list\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:22,973 INFO storage.BlockManager: Removing RDD 20\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,044 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,049 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,050 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,050 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,050 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,075 INFO spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,076 INFO scheduler.DAGScheduler: Got job 4 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,076 INFO scheduler.DAGScheduler: Final stage: ResultStage 6 (runJob at SparkHadoopWriter.scala:78)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,076 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,076 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,077 INFO scheduler.DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[23] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,088 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 85.6 KiB, free 1007.3 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,089 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 1007.3 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,090 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.174.129:39501 (size: 30.5 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,090 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,091 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,091 INFO cluster.YarnScheduler: Adding task set 6.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,093 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 67, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7807 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,106 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on algo-1:38713 (size: 30.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,199 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 67) in 107 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,199 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,200 INFO scheduler.DAGScheduler: ResultStage 6 (runJob at SparkHadoopWriter.scala:78) finished in 0.121 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,200 INFO scheduler.DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,200 INFO cluster.YarnScheduler: Killing all running tasks in stage 6: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,200 INFO scheduler.DAGScheduler: Job 4 finished: runJob at SparkHadoopWriter.scala:78, took 0.125193 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,203 INFO io.SparkHadoopWriter: Job job_20210312032023_0023 committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,344 INFO parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,359 WARN hadoop.ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,363 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,363 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,364 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,364 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,364 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,364 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,413 INFO codegen.CodeGenerator: Code generated in 10.453446 ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,423 INFO scheduler.DAGScheduler: Registering RDD 26 (parquet at CountVectorizer.scala:371) as input to shuffle 1\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,423 INFO scheduler.DAGScheduler: Got map stage job 5 (parquet at CountVectorizer.scala:371) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,423 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 7 (parquet at CountVectorizer.scala:371)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,424 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,424 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,425 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[26] at parquet at CountVectorizer.scala:371), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,433 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.8 KiB, free 1007.3 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,434 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 1007.3 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,434 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.174.129:39501 (size: 4.3 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,435 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,435 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[26] at parquet at CountVectorizer.scala:371) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,435 INFO cluster.YarnScheduler: Adding task set 7.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,437 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 68, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7629 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,447 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on algo-1:38713 (size: 4.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,512 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 68) in 76 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,512 INFO cluster.YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,513 INFO scheduler.DAGScheduler: ShuffleMapStage 7 (parquet at CountVectorizer.scala:371) finished in 0.087 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,513 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,513 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,513 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,513 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,558 INFO spark.SparkContext: Starting job: parquet at CountVectorizer.scala:371\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,559 INFO scheduler.DAGScheduler: Got job 6 (parquet at CountVectorizer.scala:371) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,559 INFO scheduler.DAGScheduler: Final stage: ResultStage 9 (parquet at CountVectorizer.scala:371)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,559 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,559 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,560 INFO scheduler.DAGScheduler: Submitting ResultStage 9 (ShuffledRowRDD[27] at parquet at CountVectorizer.scala:371), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,580 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 179.0 KiB, free 1007.1 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,582 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 1007.0 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,583 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.174.129:39501 (size: 64.2 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,583 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,584 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (ShuffledRowRDD[27] at parquet at CountVectorizer.scala:371) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,584 INFO cluster.YarnScheduler: Adding task set 9.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,586 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 69, algo-1, executor 1, partition 0, NODE_LOCAL, 7336 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,599 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on algo-1:38713 (size: 64.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:23,653 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.0.174.129:47554\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,874 INFO executor.Executor: Finished task 4.0 in stage 5.0 (TID 39). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,873 INFO executor.Executor: Finished task 15.0 in stage 5.0 (TID 50). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,873 INFO executor.Executor: Finished task 3.0 in stage 5.0 (TID 38). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,872 INFO executor.Executor: Finished task 18.0 in stage 5.0 (TID 53). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,871 INFO executor.Executor: Finished task 2.0 in stage 5.0 (TID 37). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,871 INFO executor.Executor: Finished task 9.0 in stage 5.0 (TID 44). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,875 INFO executor.Executor: Finished task 16.0 in stage 5.0 (TID 51). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,879 INFO executor.Executor: Finished task 17.0 in stage 5.0 (TID 52). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,890 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 54\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,894 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 55\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,894 INFO executor.Executor: Running task 20.0 in stage 5.0 (TID 55)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,896 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 56\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,896 INFO executor.Executor: Running task 21.0 in stage 5.0 (TID 56)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,896 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 57\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,896 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 58\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,897 INFO executor.Executor: Running task 23.0 in stage 5.0 (TID 58)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,897 INFO storage.BlockManager: Found block rdd_20_20 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,898 INFO executor.Executor: Finished task 20.0 in stage 5.0 (TID 55). 2563 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,898 INFO executor.Executor: Running task 19.0 in stage 5.0 (TID 54)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,898 INFO executor.Executor: Running task 22.0 in stage 5.0 (TID 57)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,899 INFO storage.BlockManager: Found block rdd_20_23 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,899 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 59\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,899 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 60\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,899 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 61\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,899 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 62\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,899 INFO executor.Executor: Running task 25.0 in stage 5.0 (TID 60)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,899 INFO executor.Executor: Running task 26.0 in stage 5.0 (TID 61)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,901 INFO storage.BlockManager: Found block rdd_20_22 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,901 INFO executor.Executor: Finished task 23.0 in stage 5.0 (TID 58). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,902 INFO executor.Executor: Running task 27.0 in stage 5.0 (TID 62)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,902 INFO executor.Executor: Finished task 22.0 in stage 5.0 (TID 57). 2383 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,902 INFO storage.BlockManager: Found block rdd_20_25 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,902 INFO storage.BlockManager: Found block rdd_20_19 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,902 INFO executor.Executor: Running task 24.0 in stage 5.0 (TID 59)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,903 INFO executor.Executor: Finished task 25.0 in stage 5.0 (TID 60). 2563 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,903 INFO executor.Executor: Finished task 19.0 in stage 5.0 (TID 54). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,905 INFO storage.BlockManager: Found block rdd_20_26 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,906 INFO storage.BlockManager: Found block rdd_20_24 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,907 INFO storage.BlockManager: Found block rdd_20_21 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,908 INFO executor.Executor: Finished task 21.0 in stage 5.0 (TID 56). 2383 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,909 INFO storage.BlockManager: Found block rdd_20_27 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,910 INFO executor.Executor: Finished task 27.0 in stage 5.0 (TID 62). 2383 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,911 INFO executor.Executor: Finished task 24.0 in stage 5.0 (TID 59). 2383 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,912 INFO executor.Executor: Finished task 26.0 in stage 5.0 (TID 61). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,915 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 63\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,915 INFO executor.Executor: Running task 28.0 in stage 5.0 (TID 63)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,915 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 64\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,916 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 65\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,916 INFO executor.Executor: Running task 30.0 in stage 5.0 (TID 65)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,919 INFO storage.BlockManager: Found block rdd_20_30 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,919 INFO storage.BlockManager: Found block rdd_20_28 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,920 INFO executor.Executor: Finished task 30.0 in stage 5.0 (TID 65). 2383 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,919 INFO executor.Executor: Running task 29.0 in stage 5.0 (TID 64)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,920 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 66\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,923 INFO executor.Executor: Finished task 28.0 in stage 5.0 (TID 63). 2426 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,925 INFO storage.BlockManager: Found block rdd_20_29 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,926 INFO executor.Executor: Finished task 29.0 in stage 5.0 (TID 64). 2383 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,927 INFO executor.Executor: Running task 31.0 in stage 5.0 (TID 66)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,930 INFO storage.BlockManager: Found block rdd_20_31 locally\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,931 INFO executor.Executor: Finished task 31.0 in stage 5.0 (TID 66). 2383 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,952 INFO storage.BlockManager: Removing RDD 16\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:22,973 INFO storage.BlockManager: Removing RDD 20\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,095 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 67\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,095 INFO executor.Executor: Running task 0.0 in stage 6.0 (TID 67)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,099 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 8 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,105 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,107 INFO broadcast.TorrentBroadcast: Reading broadcast variable 8 took 7 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,108 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 85.6 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,140 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,141 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,141 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,142 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,193 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032023_0023_m_000000_0' to file:/tmp/tmpxgxshx26/model/metadata\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,194 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032023_0023_m_000000_0: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,196 INFO executor.Executor: Finished task 0.0 in stage 6.0 (TID 67). 1158 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,439 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 68\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,439 INFO executor.Executor: Running task 0.0 in stage 7.0 (TID 68)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,441 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 9 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,446 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,448 INFO broadcast.TorrentBroadcast: Reading broadcast variable 9 took 6 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,449 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.8 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,510 INFO executor.Executor: Finished task 0.0 in stage 7.0 (TID 68). 1608 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,588 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 69\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,588 INFO executor.Executor: Running task 0.0 in stage 9.0 (TID 69)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,592 INFO spark.MapOutputTrackerWorker: Updating epoch to 2 and clearing cache\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,593 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 10 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,598 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,600 INFO broadcast.TorrentBroadcast: Reading broadcast variable 10 took 6 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,601 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 179.0 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,652 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 1, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,652 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.0.174.129:35737)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,655 INFO spark.MapOutputTrackerWorker: Got the output locations\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,655 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,656 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,663 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,663 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,664 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,664 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,664 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,665 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,681 INFO codec.CodecConfig: Compression: SNAPPY\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,684 INFO codec.CodecConfig: Compression: SNAPPY\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,725 INFO hadoop.ParquetOutputFormat: Parquet block size to 134217728\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,725 INFO hadoop.ParquetOutputFormat: Parquet page size to 1048576\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,725 INFO hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,725 INFO hadoop.ParquetOutputFormat: Dictionary is on\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,725 INFO hadoop.ParquetOutputFormat: Validation is off\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,725 INFO hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,725 INFO hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,725 INFO hadoop.ParquetOutputFormat: Page size checking is: estimated\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,725 INFO hadoop.ParquetOutputFormat: Min row count for page size check is: 100\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,725 INFO hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,864 INFO parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   \"type\" : \"struct\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   \"fields\" : [ {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"name\" : \"vocabulary\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"type\" : {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"type\" : \"array\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"elementType\" : \"string\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"containsNull\" : true\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     },\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,455 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 69) in 870 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,455 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,456 INFO scheduler.DAGScheduler: ResultStage 9 (parquet at CountVectorizer.scala:371) finished in 0.894 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,456 INFO scheduler.DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,456 INFO cluster.YarnScheduler: Killing all running tasks in stage 9: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,457 INFO scheduler.DAGScheduler: Job 6 finished: parquet at CountVectorizer.scala:371, took 0.898979 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,458 WARN hadoop.ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,459 INFO datasources.FileFormatWriter: Write Job 7783cabd-e7b9-418a-914d-d3220d4b6ecf committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,463 INFO datasources.FileFormatWriter: Finished processing stats for write job 7783cabd-e7b9-418a-914d-d3220d4b6ecf.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,579 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 656.0 B, free 1007.0 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,581 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 266.0 B, free 1007.0 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,581 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.174.129:39501 (size: 266.0 B, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,582 INFO spark.SparkContext: Created broadcast 11 from broadcast at CountVectorizer.scala:306\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,651 INFO storage.BlockManager: Removing RDD 20\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,659 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.174.129:39501 in memory (size: 29.9 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,661 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on algo-1:38713 in memory (size: 29.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,668 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.174.129:39501 in memory (size: 14.2 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,670 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on algo-1:38713 in memory (size: 14.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,679 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on 10.0.174.129:39501 in memory (size: 30.5 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,680 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on algo-1:38713 in memory (size: 30.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,686 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on 10.0.174.129:39501 in memory (size: 3.4 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,689 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on algo-1:38713 in memory (size: 3.4 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,692 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on 10.0.174.129:39501 in memory (size: 3.0 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,693 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on algo-1:38713 in memory (size: 3.0 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,698 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on algo-1:38713 in memory (size: 64.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,699 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on 10.0.174.129:39501 in memory (size: 64.2 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,702 INFO storage.BlockManager: Removing RDD 16\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,707 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 10.0.174.129:39501 in memory (size: 4.3 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,708 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on algo-1:38713 in memory (size: 4.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,713 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.174.129:39501 in memory (size: 15.4 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,714 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on algo-1:38713 in memory (size: 15.4 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:24,935 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,032 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,032 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,032 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,032 INFO datasources.FileSourceStrategy: Output Data Schema: struct<purpose: string>\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,068 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 313.9 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,076 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,076 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.174.129:39501 (size: 29.9 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,077 INFO spark.SparkContext: Created broadcast 12 from collect at StringIndexer.scala:204\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,078 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 1, prefetch: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,078 INFO execution.FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,1))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,083 INFO scheduler.DAGScheduler: Registering RDD 33 (collect at StringIndexer.scala:204) as input to shuffle 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,083 INFO scheduler.DAGScheduler: Got map stage job 7 (collect at StringIndexer.scala:204) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,083 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 10 (collect at StringIndexer.scala:204)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,083 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,084 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,085 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[33] at collect at StringIndexer.scala:204), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,100 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 19.0 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,101 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,102 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.174.129:39501 (size: 9.5 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,102 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,102 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[33] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,102 INFO cluster.YarnScheduler: Adding task set 10.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,104 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 70, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7744 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,112 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on algo-1:38713 (size: 9.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,150 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on algo-1:38713 (size: 29.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,595 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 70) in 492 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,595 INFO cluster.YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,596 INFO scheduler.DAGScheduler: ShuffleMapStage 10 (collect at StringIndexer.scala:204) finished in 0.511 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,596 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,596 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,596 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,596 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,603 INFO adaptive.ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 47.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,635 INFO spark.SparkContext: Starting job: collect at StringIndexer.scala:204\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,635 INFO scheduler.DAGScheduler: Got job 8 (collect at StringIndexer.scala:204) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,635 INFO scheduler.DAGScheduler: Final stage: ResultStage 12 (collect at StringIndexer.scala:204)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,635 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,636 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,636 INFO scheduler.DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[36] at collect at StringIndexer.scala:204), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,639 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 21.7 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,640 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,640 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.174.129:39501 (size: 10.9 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,640 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,641 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[36] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,641 INFO cluster.YarnScheduler: Adding task set 12.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,642 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 12.0 (TID 71, algo-1, executor 1, partition 0, NODE_LOCAL, 7336 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,649 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on algo-1:38713 (size: 10.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,666 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.0.174.129:47554\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,746 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 12.0 (TID 71) in 104 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,747 INFO cluster.YarnScheduler: Removed TaskSet 12.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,747 INFO scheduler.DAGScheduler: ResultStage 12 (collect at StringIndexer.scala:204) finished in 0.110 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,747 INFO scheduler.DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,747 INFO cluster.YarnScheduler: Killing all running tasks in stage 12: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,747 INFO scheduler.DAGScheduler: Job 8 finished: collect at StringIndexer.scala:204, took 0.112684 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:25,778 INFO codegen.CodeGenerator: Code generated in 25.972491 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"nullable\" : true,\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"metadata\" : { }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   } ]\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] and corresponding Parquet message type:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] message spark_schema {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   optional group vocabulary (LIST) {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     repeated group list {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       optional binary element (UTF8);\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]        \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:23,901 INFO compress.CodecPool: Got brand-new compressor [.snappy]\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:24,140 INFO hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 77\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:24,446 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032023_0009_m_000000_69' to file:/tmp/tmpxgxshx26/model/data\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:24,446 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032023_0009_m_000000_69: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:24,450 INFO executor.Executor: Finished task 0.0 in stage 9.0 (TID 69). 3281 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:24,652 INFO storage.BlockManager: Removing RDD 20\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:24,703 INFO storage.BlockManager: Removing RDD 16\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,106 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 70\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,106 INFO executor.Executor: Running task 0.0 in stage 10.0 (TID 70)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,107 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 13 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,111 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,112 INFO broadcast.TorrentBroadcast: Reading broadcast variable 13 took 5 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,113 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 19.0 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,142 INFO datasources.FileScanRDD: TID: 70 - Reading current file: path: file:///opt/ml/processing/german.csv/german.csv, range: 0-137181, partition values: [empty row], isDataPresent: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,144 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 12 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,148 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,150 INFO broadcast.TorrentBroadcast: Reading broadcast variable 12 took 5 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,155 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 561.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,188 INFO codegen.CodeGenerator: Code generated in 10.733517 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,208 INFO codegen.CodeGenerator: Code generated in 9.702839 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,225 INFO codegen.CodeGenerator: Code generated in 10.875904 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,247 INFO codegen.CodeGenerator: Code generated in 8.131785 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,306 INFO codegen.CodeGenerator: Code generated in 19.691305 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,593 INFO executor.Executor: Finished task 0.0 in stage 10.0 (TID 70). 2166 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,643 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 71\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,644 INFO executor.Executor: Running task 0.0 in stage 12.0 (TID 71)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,644 INFO spark.MapOutputTrackerWorker: Updating epoch to 3 and clearing cache\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,645 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 14 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,648 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,650 INFO broadcast.TorrentBroadcast: Reading broadcast variable 14 took 4 ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,051 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,051 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,051 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,051 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,059 INFO spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,060 INFO scheduler.DAGScheduler: Got job 9 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,060 INFO scheduler.DAGScheduler: Final stage: ResultStage 13 (runJob at SparkHadoopWriter.scala:78)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,060 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,060 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,061 INFO scheduler.DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[38] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,069 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 85.6 KiB, free 1007.4 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,070 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 1007.3 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,070 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.0.174.129:39501 (size: 30.5 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,071 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,071 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[38] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,071 INFO cluster.YarnScheduler: Adding task set 13.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,072 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 72, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7719 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,079 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on algo-1:38713 (size: 30.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,093 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 72) in 21 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,093 INFO cluster.YarnScheduler: Removed TaskSet 13.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,093 INFO scheduler.DAGScheduler: ResultStage 13 (runJob at SparkHadoopWriter.scala:78) finished in 0.032 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,093 INFO scheduler.DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,093 INFO cluster.YarnScheduler: Killing all running tasks in stage 13: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,094 INFO scheduler.DAGScheduler: Job 9 finished: runJob at SparkHadoopWriter.scala:78, took 0.034737 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,095 INFO io.SparkHadoopWriter: Job job_20210312032026_0038 committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,125 INFO parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,125 WARN hadoop.ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,126 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,126 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,126 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,126 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,126 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,126 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,145 INFO codegen.CodeGenerator: Code generated in 14.488745 ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,151 INFO scheduler.DAGScheduler: Registering RDD 41 (parquet at StringIndexer.scala:498) as input to shuffle 3\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,151 INFO scheduler.DAGScheduler: Got map stage job 10 (parquet at StringIndexer.scala:498) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,151 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 14 (parquet at StringIndexer.scala:498)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,151 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,151 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,152 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[41] at parquet at StringIndexer.scala:498), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,154 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 7.8 KiB, free 1007.3 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,155 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 1007.3 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,156 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.174.129:39501 (size: 4.3 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,156 INFO spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,156 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[41] at parquet at StringIndexer.scala:498) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,156 INFO cluster.YarnScheduler: Adding task set 14.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,157 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 14.0 (TID 73, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7784 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,165 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on algo-1:38713 (size: 4.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,171 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 14.0 (TID 73) in 14 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,171 INFO cluster.YarnScheduler: Removed TaskSet 14.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,171 INFO scheduler.DAGScheduler: ShuffleMapStage 14 (parquet at StringIndexer.scala:498) finished in 0.019 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,171 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,171 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,171 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,171 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,190 INFO spark.SparkContext: Starting job: parquet at StringIndexer.scala:498\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,191 INFO scheduler.DAGScheduler: Got job 11 (parquet at StringIndexer.scala:498) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,191 INFO scheduler.DAGScheduler: Final stage: ResultStage 16 (parquet at StringIndexer.scala:498)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,191 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,191 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,192 INFO scheduler.DAGScheduler: Submitting ResultStage 16 (ShuffledRowRDD[42] at parquet at StringIndexer.scala:498), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,222 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 10.0.174.129:39501 in memory (size: 30.5 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,223 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on algo-1:38713 in memory (size: 30.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,223 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 179.1 KiB, free 1007.3 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,225 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 1007.2 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,225 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.174.129:39501 (size: 64.2 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,226 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,226 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (ShuffledRowRDD[42] at parquet at StringIndexer.scala:498) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,226 INFO cluster.YarnScheduler: Adding task set 16.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,227 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on 10.0.174.129:39501 in memory (size: 29.9 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,228 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 16.0 (TID 74, algo-1, executor 1, partition 0, NODE_LOCAL, 7336 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,228 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on algo-1:38713 in memory (size: 29.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,234 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on 10.0.174.129:39501 in memory (size: 9.5 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,235 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on algo-1:38713 in memory (size: 9.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,236 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on algo-1:38713 (size: 64.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,238 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on 10.0.174.129:39501 in memory (size: 10.9 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,240 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on algo-1:38713 in memory (size: 10.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,246 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 10.0.174.129:47554\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,247 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on 10.0.174.129:39501 in memory (size: 4.3 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,249 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on algo-1:38713 in memory (size: 4.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,261 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 16.0 (TID 74) in 34 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,261 INFO cluster.YarnScheduler: Removed TaskSet 16.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,262 INFO scheduler.DAGScheduler: ResultStage 16 (parquet at StringIndexer.scala:498) finished in 0.070 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,262 INFO scheduler.DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,262 INFO cluster.YarnScheduler: Killing all running tasks in stage 16: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,262 INFO scheduler.DAGScheduler: Job 11 finished: parquet at StringIndexer.scala:498, took 0.072171 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,263 WARN hadoop.ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,263 INFO datasources.FileFormatWriter: Write Job 8b369406-73b6-4935-b650-a7aa2977014c committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,263 INFO datasources.FileFormatWriter: Finished processing stats for write job 8b369406-73b6-4935-b650-a7aa2977014c.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,347 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,347 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,347 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,347 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,355 INFO spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,356 INFO scheduler.DAGScheduler: Got job 12 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,356 INFO scheduler.DAGScheduler: Final stage: ResultStage 17 (runJob at SparkHadoopWriter.scala:78)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,356 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,356 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,357 INFO scheduler.DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[46] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,365 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 85.6 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,366 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,366 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.174.129:39501 (size: 30.5 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,367 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,367 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[46] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,367 INFO cluster.YarnScheduler: Adding task set 17.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,368 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 17.0 (TID 75, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7723 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,375 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on algo-1:38713 (size: 30.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,386 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 17.0 (TID 75) in 18 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,386 INFO cluster.YarnScheduler: Removed TaskSet 17.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,386 INFO scheduler.DAGScheduler: ResultStage 17 (runJob at SparkHadoopWriter.scala:78) finished in 0.029 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,387 INFO scheduler.DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,387 INFO cluster.YarnScheduler: Killing all running tasks in stage 17: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,387 INFO scheduler.DAGScheduler: Job 12 finished: runJob at SparkHadoopWriter.scala:78, took 0.031307 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,388 INFO io.SparkHadoopWriter: Job job_20210312032026_0046 committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,420 INFO parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,420 WARN hadoop.ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,421 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,421 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,421 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,421 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,421 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,421 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,434 INFO codegen.CodeGenerator: Code generated in 9.221239 ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,439 INFO scheduler.DAGScheduler: Registering RDD 49 (parquet at OneHotEncoder.scala:408) as input to shuffle 4\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,439 INFO scheduler.DAGScheduler: Got map stage job 13 (parquet at OneHotEncoder.scala:408) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,439 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 18 (parquet at OneHotEncoder.scala:408)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,439 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,439 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,440 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[49] at parquet at OneHotEncoder.scala:408), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,442 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 7.8 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,443 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,444 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.174.129:39501 (size: 4.3 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,444 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,444 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[49] at parquet at OneHotEncoder.scala:408) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,444 INFO cluster.YarnScheduler: Adding task set 18.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,445 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 76, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7549 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,452 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on algo-1:38713 (size: 4.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,457 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 76) in 12 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,457 INFO cluster.YarnScheduler: Removed TaskSet 18.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,458 INFO scheduler.DAGScheduler: ShuffleMapStage 18 (parquet at OneHotEncoder.scala:408) finished in 0.018 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,458 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,458 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,458 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,458 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,475 INFO spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:408\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,477 INFO scheduler.DAGScheduler: Got job 14 (parquet at OneHotEncoder.scala:408) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,477 INFO scheduler.DAGScheduler: Final stage: ResultStage 20 (parquet at OneHotEncoder.scala:408)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,477 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,477 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,477 INFO scheduler.DAGScheduler: Submitting ResultStage 20 (ShuffledRowRDD[50] at parquet at OneHotEncoder.scala:408), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,492 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 179.0 KiB, free 1007.3 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,494 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 1007.2 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,495 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.174.129:39501 (size: 64.2 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,495 INFO spark.SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,496 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (ShuffledRowRDD[50] at parquet at OneHotEncoder.scala:408) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,496 INFO cluster.YarnScheduler: Adding task set 20.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,497 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 20.0 (TID 77, algo-1, executor 1, partition 0, NODE_LOCAL, 7336 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,504 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on algo-1:38713 (size: 64.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,514 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 10.0.174.129:47554\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,540 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 20.0 (TID 77) in 43 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,540 INFO cluster.YarnScheduler: Removed TaskSet 20.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,540 INFO scheduler.DAGScheduler: ResultStage 20 (parquet at OneHotEncoder.scala:408) finished in 0.062 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,540 INFO scheduler.DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,540 INFO cluster.YarnScheduler: Killing all running tasks in stage 20: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,540 INFO scheduler.DAGScheduler: Job 14 finished: parquet at OneHotEncoder.scala:408, took 0.065301 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,541 WARN hadoop.ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,542 INFO datasources.FileFormatWriter: Write Job f235a70c-1f7d-48d5-8ab9-da1257d4e081 committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,542 INFO datasources.FileFormatWriter: Finished processing stats for write job f235a70c-1f7d-48d5-8ab9-da1257d4e081.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,758 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,758 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,758 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,759 INFO datasources.FileSourceStrategy: Output Data Schema: struct<other_parties: string>\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,780 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 313.9 KiB, free 1006.9 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,788 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 1006.9 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,789 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.174.129:39501 (size: 29.9 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,789 INFO spark.SparkContext: Created broadcast 21 from collect at StringIndexer.scala:204\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,790 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 1, prefetch: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,790 INFO execution.FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,1))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,793 INFO scheduler.DAGScheduler: Registering RDD 56 (collect at StringIndexer.scala:204) as input to shuffle 5\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,793 INFO scheduler.DAGScheduler: Got map stage job 15 (collect at StringIndexer.scala:204) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,793 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 21 (collect at StringIndexer.scala:204)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,793 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,793 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,795 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[56] at collect at StringIndexer.scala:204), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,801 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 19.0 KiB, free 1006.9 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,802 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 1006.9 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,802 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.174.129:39501 (size: 9.6 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,802 INFO spark.SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,803 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[56] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,803 INFO cluster.YarnScheduler: Adding task set 21.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,804 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 21.0 (TID 78, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7744 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,811 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on algo-1:38713 (size: 9.6 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,820 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on algo-1:38713 (size: 29.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,849 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 21.0 (TID 78) in 46 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,849 INFO cluster.YarnScheduler: Removed TaskSet 21.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,849 INFO scheduler.DAGScheduler: ShuffleMapStage 21 (collect at StringIndexer.scala:204) finished in 0.053 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,849 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,849 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,849 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,849 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,851 INFO adaptive.ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 43.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,873 INFO spark.SparkContext: Starting job: collect at StringIndexer.scala:204\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,874 INFO scheduler.DAGScheduler: Got job 16 (collect at StringIndexer.scala:204) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,874 INFO scheduler.DAGScheduler: Final stage: ResultStage 23 (collect at StringIndexer.scala:204)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,874 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,874 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,874 INFO scheduler.DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[59] at collect at StringIndexer.scala:204), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,876 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 21.7 KiB, free 1006.9 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,877 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 1006.9 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,878 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.0.174.129:39501 (size: 10.9 KiB, free: 1007.6 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,878 INFO spark.SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,878 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[59] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,878 INFO cluster.YarnScheduler: Adding task set 23.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,879 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 23.0 (TID 79, algo-1, executor 1, partition 0, NODE_LOCAL, 7336 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,887 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on algo-1:38713 (size: 10.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,650 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 21.7 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,665 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 2, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,665 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.0.174.129:35737)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,667 INFO spark.MapOutputTrackerWorker: Got the output locations\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,668 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (717.0 B) non-empty blocks including 1 (717.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,668 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,695 INFO codegen.CodeGenerator: Code generated in 16.346367 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:25,744 INFO executor.Executor: Finished task 0.0 in stage 12.0 (TID 71). 3675 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,073 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 72\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,074 INFO executor.Executor: Running task 0.0 in stage 13.0 (TID 72)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,075 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 15 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,078 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,079 INFO broadcast.TorrentBroadcast: Reading broadcast variable 15 took 4 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,080 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 85.6 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,085 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,085 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,085 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,085 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,090 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032026_0038_m_000000_0' to file:/tmp/tmpx9l02a2u/model/metadata\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,090 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032026_0038_m_000000_0: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,091 INFO executor.Executor: Finished task 0.0 in stage 13.0 (TID 72). 1158 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,159 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 73\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,159 INFO executor.Executor: Running task 0.0 in stage 14.0 (TID 73)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,160 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 16 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,164 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,166 INFO broadcast.TorrentBroadcast: Reading broadcast variable 16 took 5 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,166 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 7.8 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,169 INFO executor.Executor: Finished task 0.0 in stage 14.0 (TID 73). 1607 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,229 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 74\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,229 INFO executor.Executor: Running task 0.0 in stage 16.0 (TID 74)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,230 INFO spark.MapOutputTrackerWorker: Updating epoch to 4 and clearing cache\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,230 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 17 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,235 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,237 INFO broadcast.TorrentBroadcast: Reading broadcast variable 17 took 7 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,238 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 179.1 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,246 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 3, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,246 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.0.174.129:35737)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,249 INFO spark.MapOutputTrackerWorker: Got the output locations\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,249 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,249 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,251 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,251 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,251 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,251 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,251 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,251 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,251 INFO codec.CodecConfig: Compression: SNAPPY\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,251 INFO codec.CodecConfig: Compression: SNAPPY\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,252 INFO hadoop.ParquetOutputFormat: Parquet block size to 134217728\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,252 INFO hadoop.ParquetOutputFormat: Parquet page size to 1048576\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,252 INFO hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,252 INFO hadoop.ParquetOutputFormat: Dictionary is on\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,252 INFO hadoop.ParquetOutputFormat: Validation is off\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,252 INFO hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,252 INFO hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,252 INFO hadoop.ParquetOutputFormat: Page size checking is: estimated\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,252 INFO hadoop.ParquetOutputFormat: Min row count for page size check is: 100\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,252 INFO hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,253 INFO parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   \"type\" : \"struct\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   \"fields\" : [ {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"name\" : \"labelsArray\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"type\" : {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"type\" : \"array\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"elementType\" : {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         \"type\" : \"array\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         \"elementType\" : \"string\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         \"containsNull\" : true\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       },\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"containsNull\" : true\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     },\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"nullable\" : true,\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"metadata\" : { }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   } ]\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] and corresponding Parquet message type:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] message spark_schema {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   optional group labelsArray (LIST) {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     repeated group list {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       optional group element (LIST) {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         repeated group list {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]           optional binary element (UTF8);\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]        \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,255 INFO hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 253\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,259 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032026_0016_m_000000_74' to file:/tmp/tmpx9l02a2u/model/data\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,259 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032026_0016_m_000000_74: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,259 INFO executor.Executor: Finished task 0.0 in stage 16.0 (TID 74). 3195 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,369 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 75\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,370 INFO executor.Executor: Running task 0.0 in stage 17.0 (TID 75)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,371 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 18 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,374 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,375 INFO broadcast.TorrentBroadcast: Reading broadcast variable 18 took 4 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,376 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 85.6 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,380 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,380 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,380 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,380 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,384 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032026_0046_m_000000_0' to file:/tmp/tmpu5dby5p2/model/metadata\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,384 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032026_0046_m_000000_0: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,384 INFO executor.Executor: Finished task 0.0 in stage 17.0 (TID 75). 1158 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,447 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 76\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,447 INFO executor.Executor: Running task 0.0 in stage 18.0 (TID 76)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,448 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 19 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,451 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,452 INFO broadcast.TorrentBroadcast: Reading broadcast variable 19 took 4 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,453 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 7.8 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,456 INFO executor.Executor: Finished task 0.0 in stage 18.0 (TID 76). 1608 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,498 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 77\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,498 INFO executor.Executor: Running task 0.0 in stage 20.0 (TID 77)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,499 INFO spark.MapOutputTrackerWorker: Updating epoch to 5 and clearing cache\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,500 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 20 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,503 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,504 INFO broadcast.TorrentBroadcast: Reading broadcast variable 20 took 4 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,505 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 179.0 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,513 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 4, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,513 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.0.174.129:35737)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,515 INFO spark.MapOutputTrackerWorker: Got the output locations\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,516 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,516 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,517 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,517 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,517 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,518 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,518 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,518 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,518 INFO codec.CodecConfig: Compression: SNAPPY\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,518 INFO codec.CodecConfig: Compression: SNAPPY\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,519 INFO hadoop.ParquetOutputFormat: Parquet block size to 134217728\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,519 INFO hadoop.ParquetOutputFormat: Parquet page size to 1048576\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,519 INFO hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,519 INFO hadoop.ParquetOutputFormat: Dictionary is on\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,519 INFO hadoop.ParquetOutputFormat: Validation is off\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,519 INFO hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,519 INFO hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,519 INFO hadoop.ParquetOutputFormat: Page size checking is: estimated\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,519 INFO hadoop.ParquetOutputFormat: Min row count for page size check is: 100\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,519 INFO hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,520 INFO parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   \"type\" : \"struct\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   \"fields\" : [ {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"name\" : \"categorySizes\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"type\" : {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"type\" : \"array\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"elementType\" : \"integer\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"containsNull\" : false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     },\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"nullable\" : true,\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"metadata\" : { }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   } ]\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] and corresponding Parquet message type:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] message spark_schema {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   optional group categorySizes (LIST) {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     repeated group list {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       required int32 element;\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]        \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,530 INFO hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 8\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,537 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032026_0020_m_000000_77' to file:/tmp/tmpu5dby5p2/model/data\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,537 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032026_0020_m_000000_77: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,538 INFO executor.Executor: Finished task 0.0 in stage 20.0 (TID 77). 3195 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,805 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 78\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,805 INFO executor.Executor: Running task 0.0 in stage 21.0 (TID 78)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,807 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 22 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,891 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 10.0.174.129:47554\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,919 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 23.0 (TID 79) in 40 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,919 INFO cluster.YarnScheduler: Removed TaskSet 23.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,920 INFO scheduler.DAGScheduler: ResultStage 23 (collect at StringIndexer.scala:204) finished in 0.045 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,920 INFO scheduler.DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,920 INFO cluster.YarnScheduler: Killing all running tasks in stage 23: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,920 INFO scheduler.DAGScheduler: Job 16 finished: collect at StringIndexer.scala:204, took 0.046766 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,950 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,950 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,950 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,950 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,958 INFO spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,958 INFO scheduler.DAGScheduler: Got job 17 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,958 INFO scheduler.DAGScheduler: Final stage: ResultStage 24 (runJob at SparkHadoopWriter.scala:78)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,958 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,958 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,959 INFO scheduler.DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[61] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,966 INFO memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 85.6 KiB, free 1006.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,967 INFO memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 1006.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,968 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.0.174.129:39501 (size: 30.5 KiB, free: 1007.6 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,968 INFO spark.SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,968 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[61] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,968 INFO cluster.YarnScheduler: Adding task set 24.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,969 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 24.0 (TID 80, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7725 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,976 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on algo-1:38713 (size: 30.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,986 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 24.0 (TID 80) in 17 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,986 INFO cluster.YarnScheduler: Removed TaskSet 24.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,986 INFO scheduler.DAGScheduler: ResultStage 24 (runJob at SparkHadoopWriter.scala:78) finished in 0.027 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,986 INFO scheduler.DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,986 INFO cluster.YarnScheduler: Killing all running tasks in stage 24: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,987 INFO scheduler.DAGScheduler: Job 17 finished: runJob at SparkHadoopWriter.scala:78, took 0.028889 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:26,988 INFO io.SparkHadoopWriter: Job job_20210312032026_0061 committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,009 INFO parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,009 WARN hadoop.ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,010 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,010 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,010 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,010 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,010 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,010 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,017 INFO scheduler.DAGScheduler: Registering RDD 64 (parquet at StringIndexer.scala:498) as input to shuffle 6\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,017 INFO scheduler.DAGScheduler: Got map stage job 18 (parquet at StringIndexer.scala:498) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,017 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 25 (parquet at StringIndexer.scala:498)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,017 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,017 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,017 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[64] at parquet at StringIndexer.scala:498), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,019 INFO memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 7.8 KiB, free 1006.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,020 INFO memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 1006.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,021 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.0.174.129:39501 (size: 4.3 KiB, free: 1007.6 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,021 INFO spark.SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,023 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[64] at parquet at StringIndexer.scala:498) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,023 INFO cluster.YarnScheduler: Adding task set 25.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,024 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 25.0 (TID 81, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7629 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,031 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on algo-1:38713 (size: 4.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,036 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 25.0 (TID 81) in 12 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,036 INFO cluster.YarnScheduler: Removed TaskSet 25.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,036 INFO scheduler.DAGScheduler: ShuffleMapStage 25 (parquet at StringIndexer.scala:498) finished in 0.018 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,036 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,036 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,036 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,036 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,055 INFO spark.SparkContext: Starting job: parquet at StringIndexer.scala:498\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,056 INFO scheduler.DAGScheduler: Got job 19 (parquet at StringIndexer.scala:498) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,056 INFO scheduler.DAGScheduler: Final stage: ResultStage 27 (parquet at StringIndexer.scala:498)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,056 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,056 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,056 INFO scheduler.DAGScheduler: Submitting ResultStage 27 (ShuffledRowRDD[65] at parquet at StringIndexer.scala:498), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,070 INFO memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 179.1 KiB, free 1006.6 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,071 INFO memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 1006.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,072 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.0.174.129:39501 (size: 64.2 KiB, free: 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,072 INFO spark.SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,072 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (ShuffledRowRDD[65] at parquet at StringIndexer.scala:498) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,072 INFO cluster.YarnScheduler: Adding task set 27.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,074 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 27.0 (TID 82, algo-1, executor 1, partition 0, NODE_LOCAL, 7336 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,080 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on algo-1:38713 (size: 64.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,087 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 10.0.174.129:47554\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,100 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 27.0 (TID 82) in 27 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,100 INFO cluster.YarnScheduler: Removed TaskSet 27.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,101 INFO scheduler.DAGScheduler: ResultStage 27 (parquet at StringIndexer.scala:498) finished in 0.044 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,101 INFO scheduler.DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,101 INFO cluster.YarnScheduler: Killing all running tasks in stage 27: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,101 INFO scheduler.DAGScheduler: Job 19 finished: parquet at StringIndexer.scala:498, took 0.045690 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,102 WARN hadoop.ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,102 INFO datasources.FileFormatWriter: Write Job 3f8137b6-2a30-453a-8d77-c5ceaeb3f6f1 committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,103 INFO datasources.FileFormatWriter: Finished processing stats for write job 3f8137b6-2a30-453a-8d77-c5ceaeb3f6f1.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,166 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,166 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,166 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,166 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,174 INFO spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,175 INFO scheduler.DAGScheduler: Got job 20 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,175 INFO scheduler.DAGScheduler: Final stage: ResultStage 28 (runJob at SparkHadoopWriter.scala:78)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,175 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,175 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,175 INFO scheduler.DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[69] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,182 INFO memory.MemoryStore: Block broadcast_27 stored as values in memory (estimated size 85.6 KiB, free 1006.4 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,183 INFO memory.MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 1006.4 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,183 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.0.174.129:39501 (size: 30.5 KiB, free: 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,184 INFO spark.SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,184 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[69] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,184 INFO cluster.YarnScheduler: Adding task set 28.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,185 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 28.0 (TID 83, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7723 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,191 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on algo-1:38713 (size: 30.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,200 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 28.0 (TID 83) in 15 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,200 INFO cluster.YarnScheduler: Removed TaskSet 28.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,200 INFO scheduler.DAGScheduler: ResultStage 28 (runJob at SparkHadoopWriter.scala:78) finished in 0.025 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,200 INFO scheduler.DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,200 INFO cluster.YarnScheduler: Killing all running tasks in stage 28: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,201 INFO scheduler.DAGScheduler: Job 20 finished: runJob at SparkHadoopWriter.scala:78, took 0.026520 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,202 INFO io.SparkHadoopWriter: Job job_20210312032027_0069 committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,223 INFO parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,223 WARN hadoop.ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,223 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,223 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,223 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,223 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,223 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,224 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,250 INFO scheduler.DAGScheduler: Registering RDD 72 (parquet at OneHotEncoder.scala:408) as input to shuffle 7\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,250 INFO scheduler.DAGScheduler: Got map stage job 21 (parquet at OneHotEncoder.scala:408) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,250 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 29 (parquet at OneHotEncoder.scala:408)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,250 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,250 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,250 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[72] at parquet at OneHotEncoder.scala:408), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,253 INFO memory.MemoryStore: Block broadcast_28 stored as values in memory (estimated size 7.8 KiB, free 1006.4 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,257 INFO memory.MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 1006.4 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,259 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.0.174.129:39501 (size: 4.3 KiB, free: 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,259 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on 10.0.174.129:39501 in memory (size: 4.3 KiB, free: 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,259 INFO spark.SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,260 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[72] at parquet at OneHotEncoder.scala:408) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,260 INFO cluster.YarnScheduler: Adding task set 29.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,260 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on algo-1:38713 in memory (size: 4.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,261 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 29.0 (TID 84, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7549 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,266 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on 10.0.174.129:39501 in memory (size: 64.2 KiB, free: 1007.6 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,266 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on algo-1:38713 in memory (size: 64.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,268 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on algo-1:38713 (size: 4.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,270 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on 10.0.174.129:39501 in memory (size: 64.2 KiB, free: 1007.6 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,271 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on algo-1:38713 in memory (size: 64.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,274 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 29.0 (TID 84) in 14 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,274 INFO cluster.YarnScheduler: Removed TaskSet 29.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,274 INFO scheduler.DAGScheduler: ShuffleMapStage 29 (parquet at OneHotEncoder.scala:408) finished in 0.023 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,274 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,274 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,274 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,274 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,279 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on 10.0.174.129:39501 in memory (size: 10.9 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,279 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on algo-1:38713 in memory (size: 10.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,284 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on 10.0.174.129:39501 in memory (size: 30.5 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,286 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on algo-1:38713 in memory (size: 30.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,292 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on 10.0.174.129:39501 in memory (size: 64.2 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,294 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on algo-1:38713 in memory (size: 64.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,294 INFO spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:408\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,295 INFO scheduler.DAGScheduler: Got job 22 (parquet at OneHotEncoder.scala:408) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,295 INFO scheduler.DAGScheduler: Final stage: ResultStage 31 (parquet at OneHotEncoder.scala:408)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,295 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,295 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,295 INFO scheduler.DAGScheduler: Submitting ResultStage 31 (ShuffledRowRDD[73] at parquet at OneHotEncoder.scala:408), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,296 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on 10.0.174.129:39501 in memory (size: 30.5 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,297 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on algo-1:38713 in memory (size: 30.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,299 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on 10.0.174.129:39501 in memory (size: 4.3 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,300 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on algo-1:38713 in memory (size: 4.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,306 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on algo-1:38713 in memory (size: 29.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,308 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on 10.0.174.129:39501 in memory (size: 29.9 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,309 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on 10.0.174.129:39501 in memory (size: 9.6 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,309 INFO memory.MemoryStore: Block broadcast_29 stored as values in memory (estimated size 179.0 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,310 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on algo-1:38713 in memory (size: 9.6 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,311 INFO memory.MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,311 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.0.174.129:39501 (size: 64.2 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,311 INFO spark.SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,312 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (ShuffledRowRDD[73] at parquet at OneHotEncoder.scala:408) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,312 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on 10.0.174.129:39501 in memory (size: 30.5 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,312 INFO cluster.YarnScheduler: Adding task set 31.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,312 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on algo-1:38713 in memory (size: 30.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,313 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 31.0 (TID 85, algo-1, executor 1, partition 0, NODE_LOCAL, 7336 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,318 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on algo-1:38713 (size: 64.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,326 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.0.174.129:47554\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,337 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 31.0 (TID 85) in 25 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,337 INFO cluster.YarnScheduler: Removed TaskSet 31.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,338 INFO scheduler.DAGScheduler: ResultStage 31 (parquet at OneHotEncoder.scala:408) finished in 0.042 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,338 INFO scheduler.DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,338 INFO cluster.YarnScheduler: Killing all running tasks in stage 31: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,339 INFO scheduler.DAGScheduler: Job 22 finished: parquet at OneHotEncoder.scala:408, took 0.044044 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,340 WARN hadoop.ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,340 INFO datasources.FileFormatWriter: Write Job 03f6a3c3-6c28-4d7c-ae90-ebfd9ad6d834 committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,340 INFO datasources.FileFormatWriter: Finished processing stats for write job 03f6a3c3-6c28-4d7c-ae90-ebfd9ad6d834.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,556 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,557 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,557 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,557 INFO datasources.FileSourceStrategy: Output Data Schema: struct<other_installment_plans: string>\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,575 INFO memory.MemoryStore: Block broadcast_30 stored as values in memory (estimated size 313.9 KiB, free 1007.3 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,582 INFO memory.MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 1007.3 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,583 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.0.174.129:39501 (size: 29.9 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,583 INFO spark.SparkContext: Created broadcast 30 from collect at StringIndexer.scala:204\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,584 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 1, prefetch: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,584 INFO execution.FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,1))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,586 INFO scheduler.DAGScheduler: Registering RDD 79 (collect at StringIndexer.scala:204) as input to shuffle 8\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,587 INFO scheduler.DAGScheduler: Got map stage job 23 (collect at StringIndexer.scala:204) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,587 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 32 (collect at StringIndexer.scala:204)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,587 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,587 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,587 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[79] at collect at StringIndexer.scala:204), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,593 INFO memory.MemoryStore: Block broadcast_31 stored as values in memory (estimated size 19.0 KiB, free 1007.2 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,594 INFO memory.MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 1007.2 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,595 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.0.174.129:39501 (size: 9.5 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,595 INFO spark.SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,595 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[79] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,595 INFO cluster.YarnScheduler: Adding task set 32.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,596 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 32.0 (TID 86, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7744 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,603 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on algo-1:38713 (size: 9.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,610 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on algo-1:38713 (size: 29.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,636 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 32.0 (TID 86) in 40 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,636 INFO cluster.YarnScheduler: Removed TaskSet 32.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,637 INFO scheduler.DAGScheduler: ShuffleMapStage 32 (collect at StringIndexer.scala:204) finished in 0.050 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,637 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,637 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,637 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,637 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,639 INFO adaptive.ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 43.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,660 INFO spark.SparkContext: Starting job: collect at StringIndexer.scala:204\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,661 INFO scheduler.DAGScheduler: Got job 24 (collect at StringIndexer.scala:204) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,661 INFO scheduler.DAGScheduler: Final stage: ResultStage 34 (collect at StringIndexer.scala:204)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,661 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,661 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,661 INFO scheduler.DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[82] at collect at StringIndexer.scala:204), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,663 INFO memory.MemoryStore: Block broadcast_32 stored as values in memory (estimated size 21.8 KiB, free 1007.2 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,664 INFO memory.MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 1007.2 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,664 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.0.174.129:39501 (size: 10.9 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,664 INFO spark.SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,665 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[82] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,665 INFO cluster.YarnScheduler: Adding task set 34.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,665 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 34.0 (TID 87, algo-1, executor 1, partition 0, NODE_LOCAL, 7336 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,671 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on algo-1:38713 (size: 10.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,675 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 10.0.174.129:47554\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,699 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 34.0 (TID 87) in 34 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,699 INFO cluster.YarnScheduler: Removed TaskSet 34.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,699 INFO scheduler.DAGScheduler: ResultStage 34 (collect at StringIndexer.scala:204) finished in 0.037 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,699 INFO scheduler.DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,699 INFO cluster.YarnScheduler: Killing all running tasks in stage 34: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,700 INFO scheduler.DAGScheduler: Job 24 finished: collect at StringIndexer.scala:204, took 0.039447 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,727 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,727 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,727 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,727 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,735 INFO spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,736 INFO scheduler.DAGScheduler: Got job 25 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,736 INFO scheduler.DAGScheduler: Final stage: ResultStage 35 (runJob at SparkHadoopWriter.scala:78)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,736 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,736 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,736 INFO scheduler.DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[84] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,743 INFO memory.MemoryStore: Block broadcast_33 stored as values in memory (estimated size 85.6 KiB, free 1007.1 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,744 INFO memory.MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 1007.1 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,745 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.0.174.129:39501 (size: 30.5 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,745 INFO spark.SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,745 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[84] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,745 INFO cluster.YarnScheduler: Adding task set 35.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,746 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 35.0 (TID 88, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7735 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,752 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on algo-1:38713 (size: 30.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,763 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 35.0 (TID 88) in 17 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,763 INFO cluster.YarnScheduler: Removed TaskSet 35.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,763 INFO scheduler.DAGScheduler: ResultStage 35 (runJob at SparkHadoopWriter.scala:78) finished in 0.027 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,763 INFO scheduler.DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,763 INFO cluster.YarnScheduler: Killing all running tasks in stage 35: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,763 INFO scheduler.DAGScheduler: Job 25 finished: runJob at SparkHadoopWriter.scala:78, took 0.028128 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,765 INFO io.SparkHadoopWriter: Job job_20210312032027_0084 committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,792 INFO parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,793 WARN hadoop.ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,793 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,793 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,793 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,794 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,794 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,794 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,802 INFO scheduler.DAGScheduler: Registering RDD 87 (parquet at StringIndexer.scala:498) as input to shuffle 9\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,803 INFO scheduler.DAGScheduler: Got map stage job 26 (parquet at StringIndexer.scala:498) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,803 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 36 (parquet at StringIndexer.scala:498)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,803 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,803 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,803 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[87] at parquet at StringIndexer.scala:498), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,805 INFO memory.MemoryStore: Block broadcast_34 stored as values in memory (estimated size 7.8 KiB, free 1007.1 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,806 INFO memory.MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 1007.1 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,807 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.0.174.129:39501 (size: 4.3 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,807 INFO spark.SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,807 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[87] at parquet at StringIndexer.scala:498) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,807 INFO cluster.YarnScheduler: Adding task set 36.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,808 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 36.0 (TID 89, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7613 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,814 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on algo-1:38713 (size: 4.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,820 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 36.0 (TID 89) in 12 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,820 INFO cluster.YarnScheduler: Removed TaskSet 36.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,821 INFO scheduler.DAGScheduler: ShuffleMapStage 36 (parquet at StringIndexer.scala:498) finished in 0.018 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,821 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,821 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,821 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,821 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,838 INFO spark.SparkContext: Starting job: parquet at StringIndexer.scala:498\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,838 INFO scheduler.DAGScheduler: Got job 27 (parquet at StringIndexer.scala:498) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,839 INFO scheduler.DAGScheduler: Final stage: ResultStage 38 (parquet at StringIndexer.scala:498)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,839 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,839 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,839 INFO scheduler.DAGScheduler: Submitting ResultStage 38 (ShuffledRowRDD[88] at parquet at StringIndexer.scala:498), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,852 INFO memory.MemoryStore: Block broadcast_35 stored as values in memory (estimated size 179.1 KiB, free 1006.9 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,854 INFO memory.MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 1006.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,854 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.0.174.129:39501 (size: 64.2 KiB, free: 1007.6 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,854 INFO spark.SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,855 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (ShuffledRowRDD[88] at parquet at StringIndexer.scala:498) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,855 INFO cluster.YarnScheduler: Adding task set 38.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,855 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 38.0 (TID 90, algo-1, executor 1, partition 0, NODE_LOCAL, 7336 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,862 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on algo-1:38713 (size: 64.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,810 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,812 INFO broadcast.TorrentBroadcast: Reading broadcast variable 22 took 4 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,812 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 19.0 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,815 INFO datasources.FileScanRDD: TID: 78 - Reading current file: path: file:///opt/ml/processing/german.csv/german.csv, range: 0-137181, partition values: [empty row], isDataPresent: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,816 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 21 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,820 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,821 INFO broadcast.TorrentBroadcast: Reading broadcast variable 21 took 4 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,825 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 561.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,847 INFO executor.Executor: Finished task 0.0 in stage 21.0 (TID 78). 2166 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,881 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 79\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,881 INFO executor.Executor: Running task 0.0 in stage 23.0 (TID 79)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,881 INFO spark.MapOutputTrackerWorker: Updating epoch to 6 and clearing cache\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,882 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 23 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,886 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,887 INFO broadcast.TorrentBroadcast: Reading broadcast variable 23 took 5 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,888 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 21.8 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,891 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 5, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,891 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.0.174.129:35737)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,892 INFO spark.MapOutputTrackerWorker: Got the output locations\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,893 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,893 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,918 INFO executor.Executor: Finished task 0.0 in stage 23.0 (TID 79). 3543 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,970 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 80\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,970 INFO executor.Executor: Running task 0.0 in stage 24.0 (TID 80)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,972 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 24 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,975 INFO memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,976 INFO broadcast.TorrentBroadcast: Reading broadcast variable 24 took 4 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,977 INFO memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 85.6 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,980 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,980 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,980 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,981 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,984 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032026_0061_m_000000_0' to file:/tmp/tmp9b3p2bzw/model/metadata\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,984 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032026_0061_m_000000_0: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:26,984 INFO executor.Executor: Finished task 0.0 in stage 24.0 (TID 80). 1158 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,025 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 81\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,026 INFO executor.Executor: Running task 0.0 in stage 25.0 (TID 81)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,027 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 25 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,030 INFO memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,032 INFO broadcast.TorrentBroadcast: Reading broadcast variable 25 took 4 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,032 INFO memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 7.8 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,034 INFO executor.Executor: Finished task 0.0 in stage 25.0 (TID 81). 1608 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,075 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 82\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,075 INFO executor.Executor: Running task 0.0 in stage 27.0 (TID 82)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,075 INFO spark.MapOutputTrackerWorker: Updating epoch to 7 and clearing cache\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,076 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 26 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,079 INFO memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,080 INFO broadcast.TorrentBroadcast: Reading broadcast variable 26 took 4 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,081 INFO memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 179.1 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,086 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 6, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,086 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.0.174.129:35737)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,088 INFO spark.MapOutputTrackerWorker: Got the output locations\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,089 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,089 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,090 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,090 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,090 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,090 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,090 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,090 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,091 INFO codec.CodecConfig: Compression: SNAPPY\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,091 INFO codec.CodecConfig: Compression: SNAPPY\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,091 INFO hadoop.ParquetOutputFormat: Parquet block size to 134217728\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,091 INFO hadoop.ParquetOutputFormat: Parquet page size to 1048576\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,091 INFO hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,091 INFO hadoop.ParquetOutputFormat: Dictionary is on\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,091 INFO hadoop.ParquetOutputFormat: Validation is off\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,091 INFO hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,091 INFO hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,091 INFO hadoop.ParquetOutputFormat: Page size checking is: estimated\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,091 INFO hadoop.ParquetOutputFormat: Min row count for page size check is: 100\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,091 INFO hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,092 INFO parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   \"type\" : \"struct\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   \"fields\" : [ {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"name\" : \"labelsArray\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"type\" : {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"type\" : \"array\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"elementType\" : {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         \"type\" : \"array\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         \"elementType\" : \"string\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         \"containsNull\" : true\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       },\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"containsNull\" : true\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     },\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"nullable\" : true,\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"metadata\" : { }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   } ]\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] and corresponding Parquet message type:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] message spark_schema {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   optional group labelsArray (LIST) {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     repeated group list {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       optional group element (LIST) {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         repeated group list {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]           optional binary element (UTF8);\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]        \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,094 INFO hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 49\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,098 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032027_0027_m_000000_82' to file:/tmp/tmp9b3p2bzw/model/data\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,098 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032027_0027_m_000000_82: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,099 INFO executor.Executor: Finished task 0.0 in stage 27.0 (TID 82). 3195 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,186 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 83\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,186 INFO executor.Executor: Running task 0.0 in stage 28.0 (TID 83)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,187 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 27 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,190 INFO memory.MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,191 INFO broadcast.TorrentBroadcast: Reading broadcast variable 27 took 3 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,192 INFO memory.MemoryStore: Block broadcast_27 stored as values in memory (estimated size 85.6 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,195 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,195 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,195 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,195 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,198 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032027_0069_m_000000_0' to file:/tmp/tmpvxwcf_lx/model/metadata\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,198 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032027_0069_m_000000_0: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,199 INFO executor.Executor: Finished task 0.0 in stage 28.0 (TID 83). 1158 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,262 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 84\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,262 INFO executor.Executor: Running task 0.0 in stage 29.0 (TID 84)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,263 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 28 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,268 INFO memory.MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,269 INFO broadcast.TorrentBroadcast: Reading broadcast variable 28 took 5 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,269 INFO memory.MemoryStore: Block broadcast_28 stored as values in memory (estimated size 7.8 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,272 INFO executor.Executor: Finished task 0.0 in stage 29.0 (TID 84). 1608 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,314 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 85\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,314 INFO executor.Executor: Running task 0.0 in stage 31.0 (TID 85)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,314 INFO spark.MapOutputTrackerWorker: Updating epoch to 8 and clearing cache\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,315 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 29 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,318 INFO memory.MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,319 INFO broadcast.TorrentBroadcast: Reading broadcast variable 29 took 3 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,320 INFO memory.MemoryStore: Block broadcast_29 stored as values in memory (estimated size 179.0 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,325 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 7, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,325 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.0.174.129:35737)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,327 INFO spark.MapOutputTrackerWorker: Got the output locations\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,327 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,327 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,329 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,329 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,329 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,329 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,329 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,329 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,329 INFO codec.CodecConfig: Compression: SNAPPY\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,329 INFO codec.CodecConfig: Compression: SNAPPY\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,330 INFO hadoop.ParquetOutputFormat: Parquet block size to 134217728\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,330 INFO hadoop.ParquetOutputFormat: Parquet page size to 1048576\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,330 INFO hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,330 INFO hadoop.ParquetOutputFormat: Dictionary is on\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,330 INFO hadoop.ParquetOutputFormat: Validation is off\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,330 INFO hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,330 INFO hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,330 INFO hadoop.ParquetOutputFormat: Page size checking is: estimated\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,330 INFO hadoop.ParquetOutputFormat: Min row count for page size check is: 100\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,330 INFO hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,331 INFO parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   \"type\" : \"struct\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   \"fields\" : [ {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"name\" : \"categorySizes\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"type\" : {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"type\" : \"array\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"elementType\" : \"integer\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"containsNull\" : false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     },\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"nullable\" : true,\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"metadata\" : { }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   } ]\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] and corresponding Parquet message type:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] message spark_schema {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   optional group categorySizes (LIST) {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     repeated group list {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       required int32 element;\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]        \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,332 INFO hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 8\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,335 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032027_0031_m_000000_85' to file:/tmp/tmpvxwcf_lx/model/data\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,335 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032027_0031_m_000000_85: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,336 INFO executor.Executor: Finished task 0.0 in stage 31.0 (TID 85). 3195 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,597 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 86\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,598 INFO executor.Executor: Running task 0.0 in stage 32.0 (TID 86)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,599 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 31 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,602 INFO memory.MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,603 INFO broadcast.TorrentBroadcast: Reading broadcast variable 31 took 4 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,604 INFO memory.MemoryStore: Block broadcast_31 stored as values in memory (estimated size 19.0 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,606 INFO datasources.FileScanRDD: TID: 86 - Reading current file: path: file:///opt/ml/processing/german.csv/german.csv, range: 0-137181, partition values: [empty row], isDataPresent: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,607 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 30 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,609 INFO memory.MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,611 INFO broadcast.TorrentBroadcast: Reading broadcast variable 30 took 3 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,614 INFO memory.MemoryStore: Block broadcast_30 stored as values in memory (estimated size 561.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,635 INFO executor.Executor: Finished task 0.0 in stage 32.0 (TID 86). 2166 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,667 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 87\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,667 INFO executor.Executor: Running task 0.0 in stage 34.0 (TID 87)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,667 INFO spark.MapOutputTrackerWorker: Updating epoch to 9 and clearing cache\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,668 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 32 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,671 INFO memory.MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,672 INFO broadcast.TorrentBroadcast: Reading broadcast variable 32 took 3 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,672 INFO memory.MemoryStore: Block broadcast_32 stored as values in memory (estimated size 21.8 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,674 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 8, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,674 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.0.174.129:35737)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,675 INFO spark.MapOutputTrackerWorker: Got the output locations\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,676 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,676 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,697 INFO executor.Executor: Finished task 0.0 in stage 34.0 (TID 87). 3538 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,747 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 88\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,747 INFO executor.Executor: Running task 0.0 in stage 35.0 (TID 88)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,748 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 33 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,751 INFO memory.MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,752 INFO broadcast.TorrentBroadcast: Reading broadcast variable 33 took 4 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,753 INFO memory.MemoryStore: Block broadcast_33 stored as values in memory (estimated size 85.6 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,758 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,758 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,758 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,758 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,761 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032027_0084_m_000000_0' to file:/tmp/tmp50gh9lao/model/metadata\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,761 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032027_0084_m_000000_0: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,761 INFO executor.Executor: Finished task 0.0 in stage 35.0 (TID 88). 1158 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,809 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 89\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,809 INFO executor.Executor: Running task 0.0 in stage 36.0 (TID 89)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,810 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 34 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,813 INFO memory.MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,815 INFO broadcast.TorrentBroadcast: Reading broadcast variable 34 took 4 ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,894 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 10.0.174.129:47554\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,909 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 38.0 (TID 90) in 54 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,909 INFO cluster.YarnScheduler: Removed TaskSet 38.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,910 INFO scheduler.DAGScheduler: ResultStage 38 (parquet at StringIndexer.scala:498) finished in 0.071 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,910 INFO scheduler.DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,910 INFO cluster.YarnScheduler: Killing all running tasks in stage 38: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,910 INFO scheduler.DAGScheduler: Job 27 finished: parquet at StringIndexer.scala:498, took 0.072266 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,911 WARN hadoop.ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,911 INFO datasources.FileFormatWriter: Write Job 63f5fd9a-48c0-4c72-ad76-cd339aecdef2 committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,911 INFO datasources.FileFormatWriter: Finished processing stats for write job 63f5fd9a-48c0-4c72-ad76-cd339aecdef2.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,971 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,971 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,971 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,971 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,979 INFO spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,979 INFO scheduler.DAGScheduler: Got job 28 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,979 INFO scheduler.DAGScheduler: Final stage: ResultStage 39 (runJob at SparkHadoopWriter.scala:78)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,979 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,980 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,980 INFO scheduler.DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[92] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,987 INFO memory.MemoryStore: Block broadcast_36 stored as values in memory (estimated size 85.6 KiB, free 1006.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,988 INFO memory.MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 1006.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,988 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.0.174.129:39501 (size: 30.5 KiB, free: 1007.6 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,988 INFO spark.SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,989 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[92] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,989 INFO cluster.YarnScheduler: Adding task set 39.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,989 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 39.0 (TID 91, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7723 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:27,995 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on algo-1:38713 (size: 30.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,004 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 39.0 (TID 91) in 15 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,004 INFO cluster.YarnScheduler: Removed TaskSet 39.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,005 INFO scheduler.DAGScheduler: ResultStage 39 (runJob at SparkHadoopWriter.scala:78) finished in 0.024 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,005 INFO scheduler.DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,005 INFO cluster.YarnScheduler: Killing all running tasks in stage 39: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,005 INFO scheduler.DAGScheduler: Job 28 finished: runJob at SparkHadoopWriter.scala:78, took 0.025764 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,006 INFO io.SparkHadoopWriter: Job job_20210312032027_0092 committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,027 INFO parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,027 WARN hadoop.ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,027 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,027 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,027 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,028 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,028 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,028 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,033 INFO scheduler.DAGScheduler: Registering RDD 95 (parquet at OneHotEncoder.scala:408) as input to shuffle 10\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,033 INFO scheduler.DAGScheduler: Got map stage job 29 (parquet at OneHotEncoder.scala:408) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,033 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 40 (parquet at OneHotEncoder.scala:408)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,034 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,034 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,034 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[95] at parquet at OneHotEncoder.scala:408), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,036 INFO memory.MemoryStore: Block broadcast_37 stored as values in memory (estimated size 7.8 KiB, free 1006.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,036 INFO memory.MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 1006.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,037 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.0.174.129:39501 (size: 4.3 KiB, free: 1007.6 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,037 INFO spark.SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,037 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[95] at parquet at OneHotEncoder.scala:408) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,037 INFO cluster.YarnScheduler: Adding task set 40.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,038 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 40.0 (TID 92, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7549 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,043 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on algo-1:38713 (size: 4.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,047 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 40.0 (TID 92) in 9 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,048 INFO cluster.YarnScheduler: Removed TaskSet 40.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,048 INFO scheduler.DAGScheduler: ShuffleMapStage 40 (parquet at OneHotEncoder.scala:408) finished in 0.014 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,048 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,048 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,048 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,048 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,065 INFO spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:408\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,065 INFO scheduler.DAGScheduler: Got job 30 (parquet at OneHotEncoder.scala:408) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,065 INFO scheduler.DAGScheduler: Final stage: ResultStage 42 (parquet at OneHotEncoder.scala:408)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,065 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,065 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,066 INFO scheduler.DAGScheduler: Submitting ResultStage 42 (ShuffledRowRDD[96] at parquet at OneHotEncoder.scala:408), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,079 INFO memory.MemoryStore: Block broadcast_38 stored as values in memory (estimated size 179.0 KiB, free 1006.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,081 INFO memory.MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 1006.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,081 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.0.174.129:39501 (size: 64.2 KiB, free: 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,081 INFO spark.SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,082 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (ShuffledRowRDD[96] at parquet at OneHotEncoder.scala:408) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,082 INFO cluster.YarnScheduler: Adding task set 42.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,082 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 42.0 (TID 93, algo-1, executor 1, partition 0, NODE_LOCAL, 7336 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,088 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on algo-1:38713 (size: 64.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,096 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 10.0.174.129:47554\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,107 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 42.0 (TID 93) in 25 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,107 INFO cluster.YarnScheduler: Removed TaskSet 42.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,108 INFO scheduler.DAGScheduler: ResultStage 42 (parquet at OneHotEncoder.scala:408) finished in 0.042 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,108 INFO scheduler.DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,108 INFO cluster.YarnScheduler: Killing all running tasks in stage 42: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,108 INFO scheduler.DAGScheduler: Job 30 finished: parquet at OneHotEncoder.scala:408, took 0.043345 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,109 WARN hadoop.ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,109 INFO datasources.FileFormatWriter: Write Job cc03d023-046e-43b4-ba0d-1f6f9a319370 committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,109 INFO datasources.FileFormatWriter: Finished processing stats for write job cc03d023-046e-43b4-ba0d-1f6f9a319370.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,172 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on 10.0.174.129:39501 in memory (size: 9.5 KiB, free: 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,173 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on algo-1:38713 in memory (size: 9.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,176 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on 10.0.174.129:39501 in memory (size: 10.9 KiB, free: 1007.6 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,177 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on algo-1:38713 in memory (size: 10.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,178 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on 10.0.174.129:39501 in memory (size: 64.2 KiB, free: 1007.6 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,179 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on algo-1:38713 in memory (size: 64.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,181 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on 10.0.174.129:39501 in memory (size: 29.9 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,183 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on algo-1:38713 in memory (size: 29.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,184 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on 10.0.174.129:39501 in memory (size: 30.5 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,186 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on algo-1:38713 in memory (size: 30.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,188 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on 10.0.174.129:39501 in memory (size: 64.2 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,189 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on algo-1:38713 in memory (size: 64.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,191 INFO storage.BlockManagerInfo: Removed broadcast_38_piece0 on 10.0.174.129:39501 in memory (size: 64.2 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,191 INFO storage.BlockManagerInfo: Removed broadcast_38_piece0 on algo-1:38713 in memory (size: 64.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,193 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on 10.0.174.129:39501 in memory (size: 30.5 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,194 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on algo-1:38713 in memory (size: 30.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,196 INFO storage.BlockManagerInfo: Removed broadcast_37_piece0 on 10.0.174.129:39501 in memory (size: 4.3 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,197 INFO storage.BlockManagerInfo: Removed broadcast_37_piece0 on algo-1:38713 in memory (size: 4.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,199 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on 10.0.174.129:39501 in memory (size: 4.3 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,199 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on algo-1:38713 in memory (size: 4.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,200 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on 10.0.174.129:39501 in memory (size: 4.3 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,201 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on algo-1:38713 in memory (size: 4.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,355 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,355 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,355 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,355 INFO datasources.FileSourceStrategy: Output Data Schema: struct<housing: string>\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,373 INFO memory.MemoryStore: Block broadcast_39 stored as values in memory (estimated size 313.9 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,380 INFO memory.MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,381 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.0.174.129:39501 (size: 29.9 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,381 INFO spark.SparkContext: Created broadcast 39 from collect at StringIndexer.scala:204\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,382 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 1, prefetch: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,382 INFO execution.FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,1))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,384 INFO scheduler.DAGScheduler: Registering RDD 102 (collect at StringIndexer.scala:204) as input to shuffle 11\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,385 INFO scheduler.DAGScheduler: Got map stage job 31 (collect at StringIndexer.scala:204) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,385 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 43 (collect at StringIndexer.scala:204)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,385 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,385 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,385 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[102] at collect at StringIndexer.scala:204), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,392 INFO memory.MemoryStore: Block broadcast_40 stored as values in memory (estimated size 19.0 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,393 INFO memory.MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,394 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.0.174.129:39501 (size: 9.5 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,394 INFO spark.SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,394 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[102] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,394 INFO cluster.YarnScheduler: Adding task set 43.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,395 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 43.0 (TID 94, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7744 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,401 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on algo-1:38713 (size: 9.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,410 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on algo-1:38713 (size: 29.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,432 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 43.0 (TID 94) in 37 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,432 INFO cluster.YarnScheduler: Removed TaskSet 43.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,433 INFO scheduler.DAGScheduler: ShuffleMapStage 43 (collect at StringIndexer.scala:204) finished in 0.047 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,433 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,433 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,433 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,433 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,435 INFO adaptive.ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 43.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,455 INFO spark.SparkContext: Starting job: collect at StringIndexer.scala:204\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,456 INFO scheduler.DAGScheduler: Got job 32 (collect at StringIndexer.scala:204) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,456 INFO scheduler.DAGScheduler: Final stage: ResultStage 45 (collect at StringIndexer.scala:204)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,456 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,456 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,456 INFO scheduler.DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[105] at collect at StringIndexer.scala:204), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,458 INFO memory.MemoryStore: Block broadcast_41 stored as values in memory (estimated size 21.7 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,459 INFO memory.MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,459 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on 10.0.174.129:39501 (size: 10.9 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,459 INFO spark.SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,459 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[105] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,459 INFO cluster.YarnScheduler: Adding task set 45.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,460 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 45.0 (TID 95, algo-1, executor 1, partition 0, NODE_LOCAL, 7336 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,467 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on algo-1:38713 (size: 10.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,470 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 10.0.174.129:47554\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,495 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 45.0 (TID 95) in 35 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,495 INFO cluster.YarnScheduler: Removed TaskSet 45.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,496 INFO scheduler.DAGScheduler: ResultStage 45 (collect at StringIndexer.scala:204) finished in 0.039 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,496 INFO scheduler.DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,496 INFO cluster.YarnScheduler: Killing all running tasks in stage 45: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,496 INFO scheduler.DAGScheduler: Job 32 finished: collect at StringIndexer.scala:204, took 0.040910 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,523 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,523 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,523 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,523 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,531 INFO spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,531 INFO scheduler.DAGScheduler: Got job 33 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,531 INFO scheduler.DAGScheduler: Final stage: ResultStage 46 (runJob at SparkHadoopWriter.scala:78)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,531 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,532 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,532 INFO scheduler.DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[107] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,539 INFO memory.MemoryStore: Block broadcast_42 stored as values in memory (estimated size 85.6 KiB, free 1007.4 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,540 INFO memory.MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 1007.3 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,541 INFO storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on 10.0.174.129:39501 (size: 30.5 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,541 INFO spark.SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,541 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[107] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,541 INFO cluster.YarnScheduler: Adding task set 46.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,542 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 46.0 (TID 96, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7719 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,547 INFO storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on algo-1:38713 (size: 30.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,556 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 46.0 (TID 96) in 14 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,556 INFO cluster.YarnScheduler: Removed TaskSet 46.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,556 INFO scheduler.DAGScheduler: ResultStage 46 (runJob at SparkHadoopWriter.scala:78) finished in 0.024 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,557 INFO scheduler.DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,557 INFO cluster.YarnScheduler: Killing all running tasks in stage 46: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,557 INFO scheduler.DAGScheduler: Job 33 finished: runJob at SparkHadoopWriter.scala:78, took 0.025648 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,558 INFO io.SparkHadoopWriter: Job job_20210312032028_0107 committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,577 INFO parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,578 WARN hadoop.ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,578 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,578 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,578 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,578 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,578 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,579 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,585 INFO scheduler.DAGScheduler: Registering RDD 110 (parquet at StringIndexer.scala:498) as input to shuffle 12\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,585 INFO scheduler.DAGScheduler: Got map stage job 34 (parquet at StringIndexer.scala:498) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,585 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 47 (parquet at StringIndexer.scala:498)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,585 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,585 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,585 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[110] at parquet at StringIndexer.scala:498), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,587 INFO memory.MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.8 KiB, free 1007.3 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,588 INFO memory.MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 1007.3 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,588 INFO storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on 10.0.174.129:39501 (size: 4.3 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,588 INFO spark.SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,588 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[110] at parquet at StringIndexer.scala:498) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,588 INFO cluster.YarnScheduler: Adding task set 47.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,590 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 47.0 (TID 97, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7613 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,595 INFO storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on algo-1:38713 (size: 4.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,599 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 47.0 (TID 97) in 10 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,599 INFO cluster.YarnScheduler: Removed TaskSet 47.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,600 INFO scheduler.DAGScheduler: ShuffleMapStage 47 (parquet at StringIndexer.scala:498) finished in 0.015 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,600 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,600 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,600 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,600 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,617 INFO spark.SparkContext: Starting job: parquet at StringIndexer.scala:498\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,617 INFO scheduler.DAGScheduler: Got job 35 (parquet at StringIndexer.scala:498) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,617 INFO scheduler.DAGScheduler: Final stage: ResultStage 49 (parquet at StringIndexer.scala:498)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,618 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,618 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,618 INFO scheduler.DAGScheduler: Submitting ResultStage 49 (ShuffledRowRDD[111] at parquet at StringIndexer.scala:498), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,631 INFO memory.MemoryStore: Block broadcast_44 stored as values in memory (estimated size 179.1 KiB, free 1007.2 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,633 INFO memory.MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 1007.1 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,633 INFO storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on 10.0.174.129:39501 (size: 64.2 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,633 INFO spark.SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,634 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (ShuffledRowRDD[111] at parquet at StringIndexer.scala:498) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,634 INFO cluster.YarnScheduler: Adding task set 49.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,634 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 49.0 (TID 98, algo-1, executor 1, partition 0, NODE_LOCAL, 7336 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,640 INFO storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on algo-1:38713 (size: 64.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,647 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 10.0.174.129:47554\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,658 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 49.0 (TID 98) in 24 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,658 INFO cluster.YarnScheduler: Removed TaskSet 49.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,659 INFO scheduler.DAGScheduler: ResultStage 49 (parquet at StringIndexer.scala:498) finished in 0.040 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,659 INFO scheduler.DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,659 INFO cluster.YarnScheduler: Killing all running tasks in stage 49: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,659 INFO scheduler.DAGScheduler: Job 35 finished: parquet at StringIndexer.scala:498, took 0.041942 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,660 WARN hadoop.ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,660 INFO datasources.FileFormatWriter: Write Job 7578d91f-58a6-4359-994c-357d64920844 committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,660 INFO datasources.FileFormatWriter: Finished processing stats for write job 7578d91f-58a6-4359-994c-357d64920844.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,721 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,721 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,721 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,721 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,729 INFO spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,731 INFO scheduler.DAGScheduler: Got job 36 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,731 INFO scheduler.DAGScheduler: Final stage: ResultStage 50 (runJob at SparkHadoopWriter.scala:78)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,731 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,731 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,731 INFO scheduler.DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[115] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,738 INFO memory.MemoryStore: Block broadcast_45 stored as values in memory (estimated size 85.6 KiB, free 1007.0 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,739 INFO memory.MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 1007.0 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,740 INFO storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on 10.0.174.129:39501 (size: 30.5 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,740 INFO spark.SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,740 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[115] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,740 INFO cluster.YarnScheduler: Adding task set 50.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,741 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 50.0 (TID 99, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7723 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,747 INFO storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on algo-1:38713 (size: 30.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,755 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 50.0 (TID 99) in 14 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,755 INFO cluster.YarnScheduler: Removed TaskSet 50.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,755 INFO scheduler.DAGScheduler: ResultStage 50 (runJob at SparkHadoopWriter.scala:78) finished in 0.024 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,756 INFO scheduler.DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,756 INFO cluster.YarnScheduler: Killing all running tasks in stage 50: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,756 INFO scheduler.DAGScheduler: Job 36 finished: runJob at SparkHadoopWriter.scala:78, took 0.027024 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,757 INFO io.SparkHadoopWriter: Job job_20210312032028_0115 committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,774 INFO parquet.ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,775 WARN hadoop.ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,775 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,775 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,775 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,775 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,775 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,775 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,782 INFO scheduler.DAGScheduler: Registering RDD 118 (parquet at OneHotEncoder.scala:408) as input to shuffle 13\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,782 INFO scheduler.DAGScheduler: Got map stage job 37 (parquet at OneHotEncoder.scala:408) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,782 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 51 (parquet at OneHotEncoder.scala:408)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,782 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,782 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,782 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[118] at parquet at OneHotEncoder.scala:408), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,784 INFO memory.MemoryStore: Block broadcast_46 stored as values in memory (estimated size 7.8 KiB, free 1007.0 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,785 INFO memory.MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 1007.0 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,785 INFO storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on 10.0.174.129:39501 (size: 4.3 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,785 INFO spark.SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,785 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[118] at parquet at OneHotEncoder.scala:408) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,785 INFO cluster.YarnScheduler: Adding task set 51.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,786 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 51.0 (TID 100, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7549 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,791 INFO storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on algo-1:38713 (size: 4.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,795 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 51.0 (TID 100) in 9 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,795 INFO cluster.YarnScheduler: Removed TaskSet 51.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,796 INFO scheduler.DAGScheduler: ShuffleMapStage 51 (parquet at OneHotEncoder.scala:408) finished in 0.014 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,796 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,796 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,796 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,796 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,820 INFO spark.SparkContext: Starting job: parquet at OneHotEncoder.scala:408\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,821 INFO scheduler.DAGScheduler: Got job 38 (parquet at OneHotEncoder.scala:408) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,821 INFO scheduler.DAGScheduler: Final stage: ResultStage 53 (parquet at OneHotEncoder.scala:408)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,821 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,821 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,821 INFO scheduler.DAGScheduler: Submitting ResultStage 53 (ShuffledRowRDD[119] at parquet at OneHotEncoder.scala:408), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,835 INFO memory.MemoryStore: Block broadcast_47 stored as values in memory (estimated size 179.0 KiB, free 1006.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,836 INFO memory.MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 1006.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,836 INFO storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on 10.0.174.129:39501 (size: 64.2 KiB, free: 1007.6 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,837 INFO spark.SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,840 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (ShuffledRowRDD[119] at parquet at OneHotEncoder.scala:408) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,840 INFO cluster.YarnScheduler: Adding task set 53.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,840 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 53.0 (TID 101, algo-1, executor 1, partition 0, NODE_LOCAL, 7336 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,845 INFO storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on algo-1:38713 (size: 64.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,852 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 10.0.174.129:47554\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,862 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 53.0 (TID 101) in 22 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,862 INFO cluster.YarnScheduler: Removed TaskSet 53.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,863 INFO scheduler.DAGScheduler: ResultStage 53 (parquet at OneHotEncoder.scala:408) finished in 0.041 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,863 INFO scheduler.DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,863 INFO cluster.YarnScheduler: Killing all running tasks in stage 53: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,863 INFO scheduler.DAGScheduler: Job 38 finished: parquet at OneHotEncoder.scala:408, took 0.042989 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,864 WARN hadoop.ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,864 INFO datasources.FileFormatWriter: Write Job 7499b90b-56c5-4376-a9c6-0f10e8005403 committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,864 INFO datasources.FileFormatWriter: Finished processing stats for write job 7499b90b-56c5-4376-a9c6-0f10e8005403.\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,815 INFO memory.MemoryStore: Block broadcast_34 stored as values in memory (estimated size 7.8 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,819 INFO executor.Executor: Finished task 0.0 in stage 36.0 (TID 89). 1608 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,857 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 90\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,857 INFO executor.Executor: Running task 0.0 in stage 38.0 (TID 90)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,857 INFO spark.MapOutputTrackerWorker: Updating epoch to 10 and clearing cache\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,858 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 35 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,861 INFO memory.MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,862 INFO broadcast.TorrentBroadcast: Reading broadcast variable 35 took 4 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,863 INFO memory.MemoryStore: Block broadcast_35 stored as values in memory (estimated size 179.1 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,893 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 9, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,894 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.0.174.129:35737)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,895 INFO spark.MapOutputTrackerWorker: Got the output locations\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,896 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,896 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,897 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,897 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,897 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,897 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,897 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,897 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,898 INFO codec.CodecConfig: Compression: SNAPPY\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,898 INFO codec.CodecConfig: Compression: SNAPPY\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,898 INFO hadoop.ParquetOutputFormat: Parquet block size to 134217728\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,898 INFO hadoop.ParquetOutputFormat: Parquet page size to 1048576\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,898 INFO hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,898 INFO hadoop.ParquetOutputFormat: Dictionary is on\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,898 INFO hadoop.ParquetOutputFormat: Validation is off\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,898 INFO hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,898 INFO hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,898 INFO hadoop.ParquetOutputFormat: Page size checking is: estimated\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,898 INFO hadoop.ParquetOutputFormat: Min row count for page size check is: 100\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,898 INFO hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,900 INFO parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   \"type\" : \"struct\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   \"fields\" : [ {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"name\" : \"labelsArray\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"type\" : {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"type\" : \"array\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"elementType\" : {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         \"type\" : \"array\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         \"elementType\" : \"string\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         \"containsNull\" : true\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       },\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"containsNull\" : true\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     },\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"nullable\" : true,\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"metadata\" : { }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   } ]\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] and corresponding Parquet message type:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] message spark_schema {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   optional group labelsArray (LIST) {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     repeated group list {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       optional group element (LIST) {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         repeated group list {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]           optional binary element (UTF8);\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]        \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,901 INFO hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 38\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,907 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032027_0038_m_000000_90' to file:/tmp/tmp50gh9lao/model/data\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,907 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032027_0038_m_000000_90: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,908 INFO executor.Executor: Finished task 0.0 in stage 38.0 (TID 90). 3238 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,990 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 91\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,991 INFO executor.Executor: Running task 0.0 in stage 39.0 (TID 91)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,992 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 36 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,995 INFO memory.MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,996 INFO broadcast.TorrentBroadcast: Reading broadcast variable 36 took 3 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,996 INFO memory.MemoryStore: Block broadcast_36 stored as values in memory (estimated size 85.6 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:27,999 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,000 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,000 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,000 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,002 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032027_0092_m_000000_0' to file:/tmp/tmpav093mlz/model/metadata\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,003 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032027_0092_m_000000_0: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,003 INFO executor.Executor: Finished task 0.0 in stage 39.0 (TID 91). 1158 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,039 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 92\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,039 INFO executor.Executor: Running task 0.0 in stage 40.0 (TID 92)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,040 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 37 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,043 INFO memory.MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,044 INFO broadcast.TorrentBroadcast: Reading broadcast variable 37 took 3 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,044 INFO memory.MemoryStore: Block broadcast_37 stored as values in memory (estimated size 7.8 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,046 INFO executor.Executor: Finished task 0.0 in stage 40.0 (TID 92). 1608 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,084 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 93\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,084 INFO executor.Executor: Running task 0.0 in stage 42.0 (TID 93)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,084 INFO spark.MapOutputTrackerWorker: Updating epoch to 11 and clearing cache\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,085 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 38 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,088 INFO memory.MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,089 INFO broadcast.TorrentBroadcast: Reading broadcast variable 38 took 3 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,089 INFO memory.MemoryStore: Block broadcast_38 stored as values in memory (estimated size 179.0 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,095 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 10, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,095 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.0.174.129:35737)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,096 INFO spark.MapOutputTrackerWorker: Got the output locations\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,097 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,097 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,098 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,098 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,098 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,099 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,099 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,099 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,099 INFO codec.CodecConfig: Compression: SNAPPY\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,099 INFO codec.CodecConfig: Compression: SNAPPY\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,100 INFO hadoop.ParquetOutputFormat: Parquet block size to 134217728\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,100 INFO hadoop.ParquetOutputFormat: Parquet page size to 1048576\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,100 INFO hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,100 INFO hadoop.ParquetOutputFormat: Dictionary is on\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,100 INFO hadoop.ParquetOutputFormat: Validation is off\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,100 INFO hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,100 INFO hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,100 INFO hadoop.ParquetOutputFormat: Page size checking is: estimated\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,100 INFO hadoop.ParquetOutputFormat: Min row count for page size check is: 100\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,100 INFO hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,100 INFO parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   \"type\" : \"struct\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   \"fields\" : [ {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"name\" : \"categorySizes\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"type\" : {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"type\" : \"array\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"elementType\" : \"integer\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"containsNull\" : false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     },\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"nullable\" : true,\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"metadata\" : { }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   } ]\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] and corresponding Parquet message type:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] message spark_schema {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   optional group categorySizes (LIST) {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     repeated group list {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       required int32 element;\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]        \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,102 INFO hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 8\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,105 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032028_0042_m_000000_93' to file:/tmp/tmpav093mlz/model/data\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,105 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032028_0042_m_000000_93: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,106 INFO executor.Executor: Finished task 0.0 in stage 42.0 (TID 93). 3195 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,397 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 94\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,397 INFO executor.Executor: Running task 0.0 in stage 43.0 (TID 94)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,398 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 40 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,401 INFO memory.MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,403 INFO broadcast.TorrentBroadcast: Reading broadcast variable 40 took 4 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,403 INFO memory.MemoryStore: Block broadcast_40 stored as values in memory (estimated size 19.0 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,405 INFO datasources.FileScanRDD: TID: 94 - Reading current file: path: file:///opt/ml/processing/german.csv/german.csv, range: 0-137181, partition values: [empty row], isDataPresent: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,407 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 39 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,410 INFO memory.MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,411 INFO broadcast.TorrentBroadcast: Reading broadcast variable 39 took 4 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,414 INFO memory.MemoryStore: Block broadcast_39 stored as values in memory (estimated size 561.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,431 INFO executor.Executor: Finished task 0.0 in stage 43.0 (TID 94). 2166 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,461 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 95\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,462 INFO executor.Executor: Running task 0.0 in stage 45.0 (TID 95)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,462 INFO spark.MapOutputTrackerWorker: Updating epoch to 12 and clearing cache\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,463 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 41 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,466 INFO memory.MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,467 INFO broadcast.TorrentBroadcast: Reading broadcast variable 41 took 4 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,468 INFO memory.MemoryStore: Block broadcast_41 stored as values in memory (estimated size 21.7 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,470 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 11, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,470 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.0.174.129:35737)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,471 INFO spark.MapOutputTrackerWorker: Got the output locations\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,472 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,472 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,493 INFO executor.Executor: Finished task 0.0 in stage 45.0 (TID 95). 3540 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,543 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 96\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,543 INFO executor.Executor: Running task 0.0 in stage 46.0 (TID 96)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,544 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 42 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,546 INFO memory.MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,547 INFO broadcast.TorrentBroadcast: Reading broadcast variable 42 took 3 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,548 INFO memory.MemoryStore: Block broadcast_42 stored as values in memory (estimated size 85.6 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,551 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,551 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,551 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,551 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,554 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032028_0107_m_000000_0' to file:/tmp/tmpfrlp_p70/model/metadata\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,554 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032028_0107_m_000000_0: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,555 INFO executor.Executor: Finished task 0.0 in stage 46.0 (TID 96). 1158 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,591 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 97\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,591 INFO executor.Executor: Running task 0.0 in stage 47.0 (TID 97)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,592 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 43 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,594 INFO memory.MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,595 INFO broadcast.TorrentBroadcast: Reading broadcast variable 43 took 3 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,596 INFO memory.MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.8 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,598 INFO executor.Executor: Finished task 0.0 in stage 47.0 (TID 97). 1608 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,636 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 98\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,636 INFO executor.Executor: Running task 0.0 in stage 49.0 (TID 98)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,636 INFO spark.MapOutputTrackerWorker: Updating epoch to 13 and clearing cache\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,637 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 44 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,639 INFO memory.MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,640 INFO broadcast.TorrentBroadcast: Reading broadcast variable 44 took 3 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,641 INFO memory.MemoryStore: Block broadcast_44 stored as values in memory (estimated size 179.1 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,646 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 12, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,647 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.0.174.129:35737)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,648 INFO spark.MapOutputTrackerWorker: Got the output locations\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,648 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,648 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,649 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,649 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,649 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,650 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,650 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,650 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,650 INFO codec.CodecConfig: Compression: SNAPPY\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,650 INFO codec.CodecConfig: Compression: SNAPPY\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,651 INFO hadoop.ParquetOutputFormat: Parquet block size to 134217728\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,651 INFO hadoop.ParquetOutputFormat: Parquet page size to 1048576\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,651 INFO hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,651 INFO hadoop.ParquetOutputFormat: Dictionary is on\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,651 INFO hadoop.ParquetOutputFormat: Validation is off\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,651 INFO hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,651 INFO hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,651 INFO hadoop.ParquetOutputFormat: Page size checking is: estimated\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,651 INFO hadoop.ParquetOutputFormat: Min row count for page size check is: 100\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,651 INFO hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,652 INFO parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   \"type\" : \"struct\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   \"fields\" : [ {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"name\" : \"labelsArray\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"type\" : {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"type\" : \"array\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"elementType\" : {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         \"type\" : \"array\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         \"elementType\" : \"string\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         \"containsNull\" : true\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       },\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"containsNull\" : true\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     },\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"nullable\" : true,\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"metadata\" : { }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   } ]\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] and corresponding Parquet message type:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] message spark_schema {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   optional group labelsArray (LIST) {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     repeated group list {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       optional group element (LIST) {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         repeated group list {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]           optional binary element (UTF8);\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]         }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]        \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,653 INFO hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 39\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,656 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032028_0049_m_000000_98' to file:/tmp/tmpfrlp_p70/model/data\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,656 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032028_0049_m_000000_98: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,656 INFO executor.Executor: Finished task 0.0 in stage 49.0 (TID 98). 3195 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,742 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 99\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,742 INFO executor.Executor: Running task 0.0 in stage 50.0 (TID 99)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,743 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 45 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,746 INFO memory.MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 30.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,747 INFO broadcast.TorrentBroadcast: Reading broadcast variable 45 took 3 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,748 INFO memory.MemoryStore: Block broadcast_45 stored as values in memory (estimated size 85.6 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,751 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,751 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,751 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,751 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,753 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032028_0115_m_000000_0' to file:/tmp/tmpk1wpbj6f/model/metadata\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,753 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032028_0115_m_000000_0: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,754 INFO executor.Executor: Finished task 0.0 in stage 50.0 (TID 99). 1158 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,787 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 100\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,787 INFO executor.Executor: Running task 0.0 in stage 51.0 (TID 100)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,788 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 46 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,791 INFO memory.MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,792 INFO broadcast.TorrentBroadcast: Reading broadcast variable 46 took 3 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,792 INFO memory.MemoryStore: Block broadcast_46 stored as values in memory (estimated size 7.8 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,794 INFO executor.Executor: Finished task 0.0 in stage 51.0 (TID 100). 1608 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,841 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 101\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,842 INFO executor.Executor: Running task 0.0 in stage 53.0 (TID 101)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,842 INFO spark.MapOutputTrackerWorker: Updating epoch to 14 and clearing cache\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,843 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 47 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,845 INFO memory.MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 64.2 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,846 INFO broadcast.TorrentBroadcast: Reading broadcast variable 47 took 2 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,846 INFO memory.MemoryStore: Block broadcast_47 stored as values in memory (estimated size 179.0 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,852 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 13, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,852 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.0.174.129:35737)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,853 INFO spark.MapOutputTrackerWorker: Got the output locations\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,853 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,853 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,855 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,855 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,855 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,855 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,855 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,855 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,855 INFO codec.CodecConfig: Compression: SNAPPY\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,855 INFO codec.CodecConfig: Compression: SNAPPY\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,856 INFO hadoop.ParquetOutputFormat: Parquet block size to 134217728\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,856 INFO hadoop.ParquetOutputFormat: Parquet page size to 1048576\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,856 INFO hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,856 INFO hadoop.ParquetOutputFormat: Dictionary is on\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,856 INFO hadoop.ParquetOutputFormat: Validation is off\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,856 INFO hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,856 INFO hadoop.ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,856 INFO hadoop.ParquetOutputFormat: Page size checking is: estimated\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,856 INFO hadoop.ParquetOutputFormat: Min row count for page size check is: 100\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,856 INFO hadoop.ParquetOutputFormat: Max row count for page size check is: 10000\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,856 INFO parquet.ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   \"type\" : \"struct\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   \"fields\" : [ {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"name\" : \"categorySizes\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"type\" : {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"type\" : \"array\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"elementType\" : \"integer\",\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       \"containsNull\" : false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     },\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"nullable\" : true,\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     \"metadata\" : { }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   } ]\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] and corresponding Parquet message type:\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] message spark_schema {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   optional group categorySizes (LIST) {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     repeated group list {\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]       required int32 element;\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]     }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]   }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] }\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,983 INFO storage.BlockManagerInfo: Removed broadcast_45_piece0 on 10.0.174.129:39501 in memory (size: 30.5 KiB, free: 1007.6 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,984 INFO storage.BlockManagerInfo: Removed broadcast_45_piece0 on algo-1:38713 in memory (size: 30.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,985 INFO storage.BlockManagerInfo: Removed broadcast_47_piece0 on 10.0.174.129:39501 in memory (size: 64.2 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,986 INFO storage.BlockManagerInfo: Removed broadcast_47_piece0 on algo-1:38713 in memory (size: 64.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,988 INFO storage.BlockManagerInfo: Removed broadcast_40_piece0 on 10.0.174.129:39501 in memory (size: 9.5 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,988 INFO storage.BlockManagerInfo: Removed broadcast_40_piece0 on algo-1:38713 in memory (size: 9.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,990 INFO storage.BlockManagerInfo: Removed broadcast_41_piece0 on 10.0.174.129:39501 in memory (size: 10.9 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,991 INFO storage.BlockManagerInfo: Removed broadcast_41_piece0 on algo-1:38713 in memory (size: 10.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,992 INFO storage.BlockManagerInfo: Removed broadcast_43_piece0 on 10.0.174.129:39501 in memory (size: 4.3 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,993 INFO storage.BlockManagerInfo: Removed broadcast_43_piece0 on algo-1:38713 in memory (size: 4.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,994 INFO storage.BlockManagerInfo: Removed broadcast_42_piece0 on 10.0.174.129:39501 in memory (size: 30.5 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,995 INFO storage.BlockManagerInfo: Removed broadcast_42_piece0 on algo-1:38713 in memory (size: 30.5 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,997 INFO storage.BlockManagerInfo: Removed broadcast_46_piece0 on 10.0.174.129:39501 in memory (size: 4.3 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,997 INFO storage.BlockManagerInfo: Removed broadcast_46_piece0 on algo-1:38713 in memory (size: 4.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,999 INFO storage.BlockManagerInfo: Removed broadcast_44_piece0 on 10.0.174.129:39501 in memory (size: 64.2 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:28,999 INFO storage.BlockManagerInfo: Removed broadcast_44_piece0 on algo-1:38713 in memory (size: 64.2 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:29,001 INFO storage.BlockManagerInfo: Removed broadcast_39_piece0 on 10.0.174.129:39501 in memory (size: 29.9 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:29,001 INFO storage.BlockManagerInfo: Removed broadcast_39_piece0 on algo-1:38713 in memory (size: 29.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:29,493 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:29,510 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:29,510 INFO impl.MetricsSystemImpl: s3a-file-system metrics system started\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:30,598 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:30,599 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:30,599 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:30,599 INFO datasources.FileSourceStrategy: Output Data Schema: struct<checking_acct_status: string, duration_months: string, credit_history: string, purpose: string, credit_amount: string ... 19 more fields>\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:30,743 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:30,744 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:30,744 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:30,744 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,533 INFO codegen.CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext is 11582 bytes\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,533 INFO codegen.CodeGenerator: Code generated in 135.798627 ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,536 INFO memory.MemoryStore: Block broadcast_48 stored as values in memory (estimated size 313.9 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,551 INFO memory.MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 1007.5 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,551 INFO storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on 10.0.174.129:39501 (size: 29.9 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,552 INFO spark.SparkContext: Created broadcast 48 from csv at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,553 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 1, prefetch: false\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,553 INFO execution.FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,1))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,609 INFO scheduler.DAGScheduler: Registering RDD 129 (csv at NativeMethodAccessorImpl.java:0) as input to shuffle 14\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,609 INFO scheduler.DAGScheduler: Got map stage job 39 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,609 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 54 (csv at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,609 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,609 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,610 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[129] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,616 INFO memory.MemoryStore: Block broadcast_49 stored as values in memory (estimated size 120.4 KiB, free 1007.4 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,617 INFO memory.MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 36.0 KiB, free 1007.4 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,617 INFO storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on 10.0.174.129:39501 (size: 36.0 KiB, free: 1007.8 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,618 INFO spark.SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,618 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[129] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,618 INFO cluster.YarnScheduler: Adding task set 54.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,619 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 54.0 (TID 102, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7744 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:31,626 INFO storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on algo-1:38713 (size: 36.0 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:32,970 INFO storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on algo-1:38713 (size: 29.9 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,294 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on algo-1:38713 (size: 266.0 B, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,753 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 54.0 (TID 102) in 2134 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,753 INFO cluster.YarnScheduler: Removed TaskSet 54.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,754 INFO python.PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 42717\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,755 INFO scheduler.DAGScheduler: ShuffleMapStage 54 (csv at NativeMethodAccessorImpl.java:0) finished in 2.145 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,755 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,755 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,755 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,755 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,760 INFO adaptive.ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 15068.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,816 INFO codegen.CodeGenerator: Code generated in 17.472018 ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,837 INFO codegen.CodeGenerator: Code generated in 13.169572 ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,861 INFO codegen.CodeGenerator: Code generated in 16.145827 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr]        \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,858 INFO hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 8\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,860 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032028_0053_m_000000_101' to file:/tmp/tmpk1wpbj6f/model/data\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,860 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032028_0053_m_000000_101: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:28,861 INFO executor.Executor: Finished task 0.0 in stage 53.0 (TID 101). 3195 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:31,620 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 102\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:31,621 INFO executor.Executor: Running task 0.0 in stage 54.0 (TID 102)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:31,622 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 49 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:31,625 INFO memory.MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 36.0 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:31,626 INFO broadcast.TorrentBroadcast: Reading broadcast variable 49 took 4 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:31,627 INFO memory.MemoryStore: Block broadcast_49 stored as values in memory (estimated size 120.4 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:32,026 INFO codegen.CodeGenerator: Code generated in 7.620418 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:32,566 INFO codegen.CodeGenerator: Code generated in 16.849798 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:32,761 INFO codegen.CodeGenerator: Code generated in 98.161535 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:32,818 INFO codegen.CodeGenerator: Code generated in 23.597365 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:32,938 INFO codegen.CodeGenerator: Generated method too long to be JIT compiled: org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext is 11582 bytes\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:32,939 INFO codegen.CodeGenerator: Code generated in 117.203324 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:32,946 INFO datasources.FileScanRDD: TID: 102 - Reading current file: path: file:///opt/ml/processing/german.csv/german.csv, range: 0-137181, partition values: [empty row], isDataPresent: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:32,963 INFO codegen.CodeGenerator: Code generated in 11.180839 ms\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,928 INFO spark.SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,929 INFO scheduler.DAGScheduler: Got job 40 (csv at NativeMethodAccessorImpl.java:0) with 5 output partitions\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,929 INFO scheduler.DAGScheduler: Final stage: ResultStage 56 (csv at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,929 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 55)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,929 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,929 INFO scheduler.DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[135] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,947 INFO memory.MemoryStore: Block broadcast_50 stored as values in memory (estimated size 282.3 KiB, free 1007.1 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,949 INFO memory.MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 99.3 KiB, free 1007.0 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,949 INFO storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on 10.0.174.129:39501 (size: 99.3 KiB, free: 1007.7 MiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,949 INFO spark.SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1240\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,950 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 56 (MapPartitionsRDD[135] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,950 INFO cluster.YarnScheduler: Adding task set 56.0 with 5 tasks\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,951 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 56.0 (TID 103, algo-1, executor 1, partition 0, PROCESS_LOCAL, 7336 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,951 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 56.0 (TID 104, algo-1, executor 1, partition 1, PROCESS_LOCAL, 7336 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,951 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 56.0 (TID 105, algo-1, executor 1, partition 2, PROCESS_LOCAL, 7336 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,951 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 56.0 (TID 106, algo-1, executor 1, partition 3, PROCESS_LOCAL, 7336 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,951 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 56.0 (TID 107, algo-1, executor 1, partition 4, PROCESS_LOCAL, 7336 bytes)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:33,958 INFO storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on algo-1:38713 (size: 99.3 KiB, free: 28.9 GiB)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:34,057 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 10.0.174.129:47554\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:32,965 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 48 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:32,966 INFO codegen.CodeGenerator: Code generated in 13.609892 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:32,969 INFO memory.MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:32,970 INFO broadcast.TorrentBroadcast: Reading broadcast variable 48 took 5 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:32,979 INFO memory.MemoryStore: Block broadcast_48 stored as values in memory (estimated size 561.5 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,290 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 11 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,293 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 266.0 B, free 28.7 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,294 INFO broadcast.TorrentBroadcast: Reading broadcast variable 11 took 4 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,295 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 920.0 B, free 28.7 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,389 INFO python.ArrowPythonRunner: Times: total = 1216, boot = 451, init = 585, finish = 180\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,736 INFO python.PythonUDFRunner: Times: total = 847, boot = 4, init = 608, finish = 235\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,751 INFO executor.Executor: Finished task 0.0 in stage 54.0 (TID 102). 4802 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,952 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 103\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,952 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 104\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,952 INFO executor.Executor: Running task 0.0 in stage 56.0 (TID 103)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,952 INFO executor.Executor: Running task 1.0 in stage 56.0 (TID 104)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,953 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 105\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,953 INFO executor.Executor: Running task 2.0 in stage 56.0 (TID 105)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,953 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 106\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,953 INFO executor.Executor: Running task 3.0 in stage 56.0 (TID 106)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,953 INFO executor.YarnCoarseGrainedExecutorBackend: Got assigned task 107\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,953 INFO spark.MapOutputTrackerWorker: Updating epoch to 15 and clearing cache\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,953 INFO executor.Executor: Running task 4.0 in stage 56.0 (TID 107)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,954 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 50 with 1 pieces (estimated total size 4.0 MiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,958 INFO memory.MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 99.3 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,959 INFO broadcast.TorrentBroadcast: Reading broadcast variable 50 took 5 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:33,960 INFO memory.MemoryStore: Block broadcast_50 stored as values in memory (estimated size 282.3 KiB, free 28.9 GiB)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,057 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 14, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,057 INFO spark.MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.0.174.129:35737)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,058 INFO spark.MapOutputTrackerWorker: Don't have map outputs for shuffle 14, fetching them\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,059 INFO spark.MapOutputTrackerWorker: Got the output locations\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,060 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,060 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,060 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,060 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,069 INFO storage.ShuffleBlockFetcherIterator: Getting 1 (56.2 KiB) non-empty blocks including 1 (56.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,069 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,070 INFO storage.ShuffleBloc[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stdout] 2021-03-12T03:20:13.521+0000: [GC (Allocation Failure) [PSYoungGen: 252416K->14325K(294400K)] 252416K->14349K(967680K), 0.0114764 secs] [Times: user=0.03 sys=0.01, real=0.01 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stdout] 2021-03-12T03:20:13.883+0000: [GC (Metadata GC Threshold) [PSYoungGen: 119328K->11391K(294400K)] 119352K->11423K(967680K), 0.0059902 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stdout] 2021-03-12T03:20:13.889+0000: [Full GC (Metadata GC Threshold) [PSYoungGen: 11391K->0K(294400K)] [ParOldGen: 32K->10858K(380928K)] 11423K->10858K(675328K), [Metaspace: 20348K->20348K(22528K)], 0.0198643 secs] [Times: user=0.11 sys=0.01, real=0.02 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stdout] 2021-03-12T03:20:14.694+0000: [GC (Allocation Failure) [PSYoungGen: 252416K->9307K(294400K)] 263274K->20173K(675328K), 0.0043045 secs] [Times: user=0.02 sys=0.00, real=0.00 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stdout] 2021-03-12T03:20:15.090+0000: [GC (Metadata GC Threshold) [PSYoungGen: 167089K->9777K(417792K)] 177955K->20651K(798720K), 0.0053454 secs] [Times: user=0.02 sys=0.01, real=0.00 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stdout] 2021-03-12T03:20:15.095+0000: [Full GC (Metadata GC Threshold) [PSYoungGen: 9777K->0K(417792K)] [ParOldGen: 10874K->17572K(604160K)] 20651K->17572K(1021952K), [Metaspace: 33984K->33981K(36864K)], 0.0238083 secs] [Times: user=0.12 sys=0.02, real=0.03 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stdout] 2021-03-12T03:20:18.719+0000: [GC (Allocation Failure) [PSYoungGen: 375808K->18176K(417792K)] 393380K->35756K(1021952K), 0.0103138 secs] [Times: user=0.04 sys=0.01, real=0.01 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stdout] 2021-03-12T03:20:20.824+0000: [GC (Metadata GC Threshold) [PSYoungGen: 160863K->16361K(516608K)] 178444K->33950K(1120768K), 0.0071414 secs] [Times: user=0.04 sys=0.00, real=0.01 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stdout] 2021-03-12T03:20:20.831+0000: [Full GC (Metadata GC Threshold) [PSYoungGen: 16361K->0K(516608K)] [ParOldGen: 17588K->29695K(849408K)] 33950K->29695K(1366016K), [Metaspace: 54494K->54494K(59392K)], 0.0745567 secs] [Times: user=0.57 sys=0.00, real=0.07 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stdout] 2021-03-12T03:20:23.796+0000: [GC (Allocation Failure) [PSYoungGen: 500224K->20468K(529408K)] 529919K->50652K(1378816K), 0.0133143 secs] [Times: user=0.06 sys=0.01, real=0.02 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stdout] 2021-03-12T03:20:27.871+0000: [GC (Allocation Failure) [PSYoungGen: 529396K->23524K(677376K)] 559580K->58189K(1526784K), 0.0208372 secs] [Times: user=0.07 sys=0.01, real=0.02 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stdout] 2021-03-12T03:20:32.666+0000: [GC (Metadata GC Threshold) [PSYoungGen: 310289K->25516K(681984K)] 344954K->60189K(1531392K), 0.0140224 secs] [Times: user=0.04 sys=0.04, real=0.02 secs] \u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stdout] 2021-03-12T03:20:32.680+0000: [Full GC (Metadata GC Threshold) [PSYoungGen: 25516K->0K(681984K)] [ParOldGen: 34672K->49359K(1211392K)] 60189K->49359K(1893376K), [Metaspace: 89177K->88185K(100352K)], 0.0682970 secs] [Times: user=0.26 sys=0.03, real=0.07 secs] \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:36,394 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 56.0 (TID 107) in 2443 ms on algo-1 (executor 1) (1/5)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:36,395 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 56.0 (TID 105) in 2444 ms on algo-1 (executor 1) (2/5)\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stdkFetcherIterator: Getting 1 (23.8 KiB) non-empty blocks including 1 (23.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,070 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,071 INFO storage.ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,071 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,081 INFO codegen.CodeGenerator: Code generated in 19.964592 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,102 INFO codegen.CodeGenerator: Code generated in 12.265708 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,127 INFO codegen.CodeGenerator: Code generated in 7.192528 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,172 INFO codegen.CodeGenerator: Code generated in 18.873377 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,182 INFO codegen.CodeGenerator: Code generated in 6.145718 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,207 INFO codegen.CodeGenerator: Code generated in 6.160086 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,220 INFO codegen.CodeGenerator: Code generated in 6.982287 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,229 INFO codegen.CodeGenerator: Code generated in 5.503641 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,246 INFO codegen.CodeGenerator: Code generated in 14.280756 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,277 INFO codegen.CodeGenerator: Code generated in 18.80082 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,297 INFO codegen.CodeGenerator: Code generated in 7.424323 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,312 INFO codegen.CodeGenerator: Code generated in 8.332021 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,322 INFO codegen.CodeGenerator: Code generated in 7.239124 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,342 INFO codegen.CodeGenerator: Code generated in 17.689919 ms\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:34,507 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:35,140 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:35,140 INFO impl.MetricsSystemImpl: s3a-file-system metrics system started\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,257 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,257 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,257 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,257 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,257 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,257 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,257 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,257 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,258 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,258 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,258 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,258 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,258 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,259 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,259 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,259 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,259 INFO output.DirectFileOutputCommitter: Direct Write: DISABLED\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,259 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:37,882 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 56.0 (TID 106) in 3931 ms on algo-1 (executor 1) (3/5)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:37,968 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 56.0 (TID 103) in 4018 ms on algo-1 (executor 1) (4/5)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:37,989 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 56.0 (TID 104) in 4038 ms on algo-1 (executor 1) (5/5)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:37,989 INFO cluster.YarnScheduler: Removed TaskSet 56.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:37,990 INFO scheduler.DAGScheduler: ResultStage 56 (csv at NativeMethodAccessorImpl.java:0) finished in 4.059 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:37,990 INFO scheduler.DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:37,990 INFO cluster.YarnScheduler: Killing all running tasks in stage 56: Stage finished\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:37,990 INFO scheduler.DAGScheduler: Job 40 finished: csv at NativeMethodAccessorImpl.java:0, took 4.061986 s\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:38,335 INFO datasources.FileFormatWriter: Write Job 724a9124-6faf-4c7a-bb9a-de8134f66e0c committed.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:38,335 INFO datasources.FileFormatWriter: Finished processing stats for write job 724a9124-6faf-4c7a-bb9a-de8134f66e0c.\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/cINFO:sagemaker_dataprep:{\"event_type\": \"mohave.backend.spark.performance\", \"request_context\": {\"client_request_id\": null}, \"app_context\": {\"wrangler_version\": \"1.3.0\", \"spark_version\": \"3.0.0+amzn.0\"}, \"engine\": \"spark\", \"metadata\": {\"operator_name\": \"sagemaker.spark.cast_single_data_type_0.1\"}, \"spark\": {\"stage_ids\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56], \"stages\": [{\"stage_id\": 0, \"task_metrics\": [{\"executor_runtime\": 743.0, \"executor_deserialize_time\": 711.0, \"scheduler_delay\": 65.0, \"gc_time\": 11.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1888.0, \"bytes_read\": 65536.0, \"records_read\": 1.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 1, \"task_metrics\": [{\"executor_runtime\": 348.0, \"executor_deserialize_time\": 1438.0, \"scheduler_delay\": 10.0, \"gc_time\": 82.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1665.0, \"bytes_read\": 137181.0, \"records_read\": 1000.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 2, \"task_metrics\": [{\"executor_runtime\": 78.0, \"executor_deserialize_time\": 68.0, \"scheduler_delay\": 13.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 2488.0, \"result_size\": 1929.0, \"bytes_read\": 206808.0, \"records_read\": 1000.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 3, \"task_metrics\": [{\"executor_runtime\": 32.0, \"executor_deserialize_time\": 1.0, \"scheduler_delay\": 10.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1305.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 4, \"task_metrics\": [{\"attempt_id\": 0, \"attempt_status\": \"SKIPPED\"}]}, {\"stage_id\": 5, \"task_metrics\": [{\"executor_runtime\": 0.0, \"executor_deserialize_time\": 2.0, \"scheduler_delay\": 11.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 2383.0, \"bytes_read\": 24.0, \"records_read\": 0.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 6, \"task_metrics\": [{\"executor_runtime\": 62.0, \"executor_deserialize_time\": 36.0, \"scheduler_delay\": 9.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1158.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 449.0, \"records_written\": 1.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 7, \"task_metrics\": [{\"executor_runtime\": 37.0, \"executor_deserialize_time\": 32.0, \"scheduler_delay\": 7.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1608.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 8, \"task_metrics\": [{\"attempt_id\": 0, \"attempt_status\": \"SKIPPED\"}]}, {\"stage_id\": 9, \"task_metrics\": [{\"executor_runtime\": 796.0, \"executor_deserialize_time\": 61.0, \"scheduler_delay\": 11.0, \"gc_time\": 13.0, \"result_serialization_time\": 2.0, \"peak_execution_memory\": 0.0, \"result_size\": 3281.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 596.0, \"records_written\": 1.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 10, \"task_metrics\": [{\"executor_runtime\": 451.0, \"executor_deserialize_time\": 35.0, \"scheduler_delay\": 6.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 2166.0, \"bytes_read\": 137181.0, \"records_read\": 1000.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 11, \"task_metrics\": [{\"attempt_id\": 0, \"attempt_status\": \"SKIPPED\"}]}, {\"stage_id\": 12, \"task_metrics\": [{\"executor_runtime\": 78.0, \"executor_deserialize_time\": 20.0, \"scheduler_delay\": 6.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 3675.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 13, \"task_metrics\": [{\"executor_runtime\": 6.0, \"executor_deserialize_time\": 10.0, \"scheduler_delay\": 5.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1158.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 361.0, \"records_written\": 1.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 14, \"task_metrics\": [{\"executor_runtime\": 1.0, \"executor_deserialize_time\": 8.0, \"scheduler_delay\": 5.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1607.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 15, \"task_metrics\": [{\"attempt_id\": 0, \"attempt_status\": \"SKIPPED\"}]}, {\"stage_id\": 16, \"task_metrics\": [{\"executor_runtime\": 13.0, \"executor_deserialize_time\": 16.0, \"scheduler_delay\": 5.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 3195.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 787.0, \"records_written\": 1.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 17, \"task_metrics\": [{\"executor_runtime\": 5.0, \"executor_deserialize_time\": 9.0, \"scheduler_delay\": 4.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1158.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 365.0, \"records_written\": 1.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 18, \"task_metrics\": [{\"executor_runtime\": 1.0, \"executor_deserialize_time\": 7.0, \"scheduler_delay\": 4.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1608.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 19, \"task_metrics\": [{\"attempt_id\": 0, \"attempt_status\": \"SKIPPED\"}]}, {\"stage_id\": 20, \"task_metrics\": [{\"executor_runtime\": 24.0, \"executor_deserialize_time\": 14.0, \"scheduler_delay\": 5.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 3195.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 560.0, \"records_written\": 1.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 21, \"task_metrics\": [{\"executor_runtime\": 32.0, \"executor_deserialize_time\": 8.0, \"scheduler_delay\": 6.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 2166.0, \"bytes_read\": 137181.0, \"records_read\": 1000.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 22, \"task_metrics\": [{\"attempt_id\": 0, \"attempt_status\": \"SKIPPED\"}]}, {\"stage_id\": 23, \"task_metrics\": [{\"executor_runtime\": 27.0, \"executor_deserialize_time\": 9.0, \"scheduler_delay\": 4.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 3543.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 24, \"task_metrics\": [{\"executor_runtime\": 4.0, \"executor_deserialize_time\": 9.0, \"scheduler_delay\": 4.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1158.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 367.0, \"records_written\": 1.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 25, \"task_metrics\": [{\"executor_runtime\": 1.0, \"executor_deserialize_time\": 7.0, \"scheduler_delay\": 4.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1608.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 26, \"task_metrics\": [{\"attempt_id\": 0, \"attempt_status\": \"SKIPPED\"}]}, {\"stage_id\": 27, \"task_metrics\": [{\"executor_runtime\": 12.0, \"executor_deserialize_time\": 11.0, \"scheduler_delay\": 4.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 3195.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 671.0, \"records_written\": 1.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 28, \"task_metrics\": [{\"executor_runtime\": 3.0, \"executor_deserialize_time\": 8.0, \"scheduler_delay\": 4.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1158.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 365.0, \"records_written\": 1.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 29, \"task_metrics\": [{\"executor_runtime\": 1.0, \"executor_deserialize_time\": 8.0, \"scheduler_delay\": 5.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1608.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 30, \"task_metrics\": [{\"attempt_id\": 0, \"attempt_status\": \"SKIPPED\"}]}, {\"stage_id\": 31, \"task_metrics\": [{\"executor_runtime\": 10.0, \"executor_deserialize_time\": 10.0, \"scheduler_delay\": 5.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 3195.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 560.0, \"records_written\": 1.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 32, \"task_metrics\": [{\"executor_runtime\": 29.0, \"executor_deserialize_time\": 7.0, \"scheduler_delay\": 4.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 2166.0, \"bytes_read\": 137181.0, \"records_read\": 1000.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 33, \"task_metrics\": [{\"attempt_id\": 0, \"attempt_status\": \"SKIPPED\"}]}, {\"stage_id\": 34, \"task_metrics\": [{\"executor_runtime\": 22.0, \"executor_deserialize_time\": 7.0, \"scheduler_delay\": 5.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 3538.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 35, \"task_metrics\": [{\"executor_runtime\": 4.0, \"executor_deserialize_time\": 9.0, \"scheduler_delay\": 4.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1158.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 377.0, \"records_written\": 1.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 36, \"task_metrics\": [{\"executor_runtime\": 1.0, \"executor_deserialize_time\": 7.0, \"scheduler_delay\": 4.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1608.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 37, \"task_metrics\": [{\"attempt_id\": 0, \"attempt_status\": \"SKIPPED\"}]}, {\"stage_id\": 38, \"task_metrics\": [{\"executor_runtime\": 14.0, \"executor_deserialize_time\": 36.0, \"scheduler_delay\": 4.0, \"gc_time\": 21.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 3238.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 647.0, \"records_written\": 1.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 39, \"task_metrics\": [{\"executor_runtime\": 3.0, \"executor_deserialize_time\": 7.0, \"scheduler_delay\": 5.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1158.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 365.0, \"records_written\": 1.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 40, \"task_metrics\": [{\"executor_runtime\": 1.0, \"executor_deserialize_time\": 5.0, \"scheduler_delay\": 3.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1608.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 41, \"task_metrics\": [{\"attempt_id\": 0, \"attempt_status\": \"SKIPPED\"}]}, {\"stage_id\": 42, \"task_metrics\": [{\"executor_runtime\": 10.0, \"executor_deserialize_time\": 10.0, \"scheduler_delay\": 5.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 3195.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 560.0, \"records_written\": 1.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 43, \"task_metrics\": [{\"executor_runtime\": 25.0, \"executor_deserialize_time\": 7.0, \"scheduler_delay\": 5.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 2166.0, \"bytes_read\": 137181.0, \"records_read\": 1000.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 44, \"task_metrics\": [{\"attempt_id\": 0, \"attempt_status\": \"SKIPPED\"}]}, {\"stage_id\": 45, \"task_metrics\": [{\"executor_runtime\": 23.0, \"executor_deserialize_time\": 8.0, \"scheduler_delay\": 4.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 3540.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 46, \"task_metrics\": [{\"executor_runtime\": 4.0, \"executor_deserialize_time\": 7.0, \"scheduler_delay\": 3.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1158.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 361.0, \"records_written\": 1.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 47, \"task_metrics\": [{\"executor_runtime\": 1.0, \"executor_deserialize_time\": 5.0, \"scheduler_delay\": 4.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1608.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 48, \"task_metrics\": [{\"attempt_id\": 0, \"attempt_status\": \"SKIPPED\"}]}, {\"stage_id\": 49, \"task_metrics\": [{\"executor_runtime\": 9.0, \"executor_deserialize_time\": 10.0, \"scheduler_delay\": 5.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 3195.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 653.0, \"records_written\": 1.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 50, \"task_metrics\": [{\"executor_runtime\": 3.0, \"executor_deserialize_time\": 7.0, \"scheduler_delay\": 4.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1158.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 365.0, \"records_written\": 1.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 51, \"task_metrics\": [{\"executor_runtime\": 1.0, \"executor_deserialize_time\": 5.0, \"scheduler_delay\": 3.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 1608.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 52, \"task_metrics\": [{\"attempt_id\": 0, \"attempt_status\": \"SKIPPED\"}]}, {\"stage_id\": 53, \"task_metrics\": [{\"executor_runtime\": 9.0, \"executor_deserialize_time\": 9.0, \"scheduler_delay\": 4.0, \"gc_time\": 0.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 0.0, \"result_size\": 3195.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 560.0, \"records_written\": 1.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 54, \"task_metrics\": [{\"executor_runtime\": 1753.0, \"executor_deserialize_time\": 376.0, \"scheduler_delay\": 5.0, \"gc_time\": 82.0, \"result_serialization_time\": 0.0, \"peak_execu\u001b[0m\n",
      "\u001b[34mtion_memory\": 67141632.0, \"result_size\": 4802.0, \"bytes_read\": 65536.0, \"records_read\": 1000.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}, {\"stage_id\": 55, \"task_metrics\": [{\"attempt_id\": 0, \"attempt_status\": \"SKIPPED\"}]}, {\"stage_id\": 56, \"task_metrics\": [{\"executor_runtime\": 2321.0, \"executor_deserialize_time\": 103.0, \"scheduler_delay\": 4.0, \"gc_time\": 128.0, \"result_serialization_time\": 0.0, \"peak_execution_memory\": 65536.0, \"result_size\": 4588.0, \"bytes_read\": 0.0, \"records_read\": 0.0, \"bytes_written\": 0.0, \"records_written\": 0.0, \"attempt_id\": 0, \"attempt_status\": \"COMPLETE\"}]}], \"aggregate_metrics\": [{\"executor_id\": \"driver\", \"total_runtime\": 0, \"total_storage_memory\": 1056807321, \"storage_memory_used\": 169434, \"peak_memory_metrics\": {\"storage_memory\": 352096, \"execution_memory\": 0}}, {\"executor_id\": \"1\", \"total_runtime\": 31256, \"total_storage_memory\": 30984477081, \"storage_memory_used\": 169434, \"peak_memory_metrics\": {\"storage_memory\": 169434, \"execution_memory\": 0}}]}}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,401 INFO spark.SparkContext: Invoking stop() from shutdown hook\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,408 INFO server.AbstractConnector: Stopped Spark@516afbcd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,409 INFO ui.SparkUI: Stopped Spark web UI at http://10.0.174.129:4040\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,413 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,431 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,431 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,539 INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend Stopped\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,547 INFO launcher.ContainerLaunch: Container container_1615519194501_0001_01_000002 succeeded \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,547 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,555 INFO container.ContainerImpl: Container container_1615519194501_0001_01_000002 transitioned from RUNNING to EXITED_WITH_SUCCESS\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,557 INFO launcher.ContainerCleanup: Cleaning up container container_1615519194501_0001_01_000002\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,558 INFO nodemanager.NMAuditLogger: USER=root#011OPERATION=Container Finished - Succeeded#011TARGET=ContainerImpl#011RESULT=SUCCESS#011APPID=application_1615519194501_0001#011CONTAINERID=container_1615519194501_0001_01_000002\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,559 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001/container_1615519194501_0001_01_000002\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,560 INFO container.ContainerImpl: Container container_1615519194501_0001_01_000002 transitioned from EXITED_WITH_SUCCESS to DONE\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,560 INFO application.ApplicationImpl: Removing container_1615519194501_0001_01_000002 from application application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,561 INFO monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1615519194501_0001_01_000002\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,561 INFO containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,563 INFO rmcontainer.RMContainerImpl: container_1615519194501_0001_01_000002 Container Transitioned from RUNNING to COMPLETED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,563 INFO resourcemanager.RMAuditLogger: USER=root#011OPERATION=AM Released Container#011TARGET=SchedulerApp#011RESULT=SUCCESS#011APPID=application_1615519194501_0001#011CONTAINERID=container_1615519194501_0001_01_000002#011RESOURCE=<memory:61316, vCores:1>#011QUEUENAME=default\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,566 INFO memory.MemoryStore: MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,566 INFO storage.BlockManager: BlockManager stopped\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,569 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,575 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,575 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001/container_1615519194501_0001_01_000002/launch_container.sh\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,575 WARN nodemanager.DefaultContainerExecutor: delete returned false for path: [/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001/container_1615519194501_0001_01_000002/launch_container.sh]\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,575 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001/container_1615519194501_0001_01_000002/container_tokens\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,576 WARN nodemanager.DefaultContainerExecutor: delete returned false for path: [/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001/container_1615519194501_0001_01_000002/container_tokens]\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,576 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001/container_1615519194501_0001_01_000002/sysfs\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,576 WARN nodemanager.DefaultContainerExecutor: delete returned false for path: [/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001/container_1615519194501_0001_01_000002/sysfs]\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,582 INFO spark.SparkContext: Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,582 INFO util.ShutdownHookManager: Shutdown hook called\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,583 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-9a6f8b64-8a34-41cd-8360-75da66f6f494\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,586 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-99741e4a-173a-475b-bd1a-6b33b541f744/pyspark-1764435b-f97a-4c0c-98b8-30fc945ceb8e\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,590 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-99741e4a-173a-475b-bd1a-6b33b541f744\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,595 INFO impl.MetricsSystemImpl: Stopping s3a-file-system metrics system...\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,595 INFO impl.MetricsSystemImpl: s3a-file-system metrics system stopped.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,595 INFO impl.MetricsSystemImpl: s3a-file-system metrics system shutdown complete.\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,596 INFO attempt.RMAppAttemptImpl: Updating application attempt appattempt_1615519194501_0001_000001 with final state: FINISHING, and exit status: -1000\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,597 INFO attempt.RMAppAttemptImpl: appattempt_1615519194501_0001_000001 State change from RUNNING to FINAL_SAVING on event = UNREGISTERED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,597 INFO rmapp.RMAppImpl: Updating application application_1615519194501_0001 with final state: FINISHING\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,597 INFO recovery.RMStateStore: Updating info for app: application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,597 INFO rmapp.RMAppImpl: application_1615519194501_0001 State change from RUNNING to FINAL_SAVING on event = ATTEMPT_UNREGISTERED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,597 INFO attempt.RMAppAttemptImpl: appattempt_1615519194501_0001_000001 State change from FINAL_SAVING to FINISHING on event = ATTEMPT_UPDATE_SAVED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,597 INFO rmapp.RMAppImpl: application_1615519194501_0001 State change from FINAL_SAVING to FINISHING on event = APP_UPDATE_SAVED\u001b[0m\n",
      "\u001b[34m03-12 03:20 smspark-submit INFO     spark submit was successful. primary node exiting.\u001b[0m\n",
      "\u001b[34mStarting clean up\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:39,697 INFO resourcemanager.ApplicationMasterService: application_1615519194501_0001 unregistered successfully. \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,085 INFO launcher.ContainerLaunch: Container container_1615519194501_0001_01_000001 succeeded \u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,085 INFO container.ContainerImpl: Container container_1615519194501_0001_01_000001 transitioned from RUNNING to EXITED_WITH_SUCCESS\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,086 INFO launcher.ContainerCleanup: Cleaning up container container_1615519194501_0001_01_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,086 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001/container_1615519194501_0001_01_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,086 INFO nodemanager.NMAuditLogger: USER=root#011OPERATION=Container Finished - Succeeded#011TARGET=ContainerImpl#011RESULT=SUCCESS#011APPID=application_1615519194501_0001#011CONTAINERID=container_1615519194501_0001_01_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,087 INFO container.ContainerImpl: Container container_1615519194501_0001_01_000001 transitioned from EXITED_WITH_SUCCESS to DONE\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,087 INFO application.ApplicationImpl: Removing container_1615519194501_0001_01_000001 from application application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,087 INFO monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1615519194501_0001_01_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,087 INFO containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,089 INFO rmcontainer.RMContainerImpl: container_1615519194501_0001_01_000001 Container Transitioned from RUNNING to COMPLETED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,089 INFO resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1615519194501_0001_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,089 INFO resourcemanager.RMAuditLogger: USER=root#011OPERATION=AM Released Container#011TARGET=SchedulerApp#011RESULT=SUCCESS#011APPID=application_1615519194501_0001#011CONTAINERID=container_1615519194501_0001_01_000001#011RESOURCE=<memory:896, vCores:1>#011QUEUENAME=default\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,090 INFO security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1615519194501_0001_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,092 INFO attempt.RMAppAttemptImpl: appattempt_1615519194501_0001_000001 State change from FINISHING to FINISHED on event = CONTAINER_FINISHED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,094 INFO rmapp.RMAppImpl: application_1615519194501_0001 State change from FINISHING to FINISHED on event = ATTEMPT_FINISHED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,094 INFO capacity.CapacityScheduler: Application Attempt appattempt_1615519194501_0001_000001 is done. finalState=FINISHED\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,095 INFO scheduler.AppSchedulingInfo: Application application_1615519194501_0001 requests cleared\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,095 INFO amlauncher.AMLauncher: Cleaning master appattempt_1615519194501_0001_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,095 INFO capacity.LeafQueue: Application removed - appId: application_1615519194501_0001 user: root queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,096 INFO capacity.ParentQueue: Application removed - appId: application_1615519194501_0001 user: root leaf-queue of parent: root #applications: 0\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,096 INFO resourcemanager.RMAuditLogger: USER=root#011OPERATION=Application Finished - Succeeded#011TARGET=RMAppManager#011RESULT=SUCCESS#011APPID=application_1615519194501_0001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,098 INFO resourcemanager.RMAppManager$ApplicationSummary: appId=application_1615519194501_0001,name=processing_entrypoint.py,user=root,queue=default,state=FINISHED,trackingUrl=http://algo-1:8088/proxy/application_1615519194501_0001/,appMasterHost=10.0.174.129,submitTime=1615519205086,startTime=1615519205144,launchTime=1615519205940,finishTime=1615519239597,finalStatus=SUCCEEDED,memorySeconds=1746680,vcoreSeconds=61,preemptedMemorySeconds=0,preemptedVcoreSeconds=0,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\\, vCores:0>,applicationType=SPARK,resourceSeconds=1746680 MB-seconds\\, 61 vcore-seconds,preemptedResourceSeconds=0 MB-seconds\\, 0 vcore-seconds,applicationTags=\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,100 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001/container_1615519194501_0001_01_000001/launch_container.sh\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,100 WARN nodemanager.DefaultContainerExecutor: delete returned false for path: [/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001/container_1615519194501_0001_01_000001/launch_container.sh]\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,100 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001/container_1615519194501_0001_01_000001/container_tokens\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,100 WARN nodemanager.DefaultContainerExecutor: delete returned false for path: [/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001/container_1615519194501_0001_01_000001/container_tokens]\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,101 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001/container_1615519194501_0001_01_000001/sysfs\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,101 WARN nodemanager.DefaultContainerExecutor: delete returned false for path: [/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1615519194501_0001/container_1615519194501_0001_01_000001/sysfs]\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,102 INFO ipc.Server: Auth successful for appattempt_1615519194501_0001_000001 (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,106 INFO containermanager.ContainerManagerImpl: Stopping container with container Id: container_1615519194501_0001_01_000001\u001b[0m\n",
      "\u001b[34m2021-03-12 03:20:40,106 INFO nodemanager.NMAuditLogger: USER=root#011IP=10.0.174.129#011OPERATION=Stop Container Request#011TARGET=ContainerManageImpl#011RESULT=SUCCESS#011APPID=application_1615519194501_0001#011CONTAINERID=container_1615519194501_0001_01_000001\u001b[0m\n",
      "\u001b[34montainer_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,259 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,259 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.DirectFileOutputCommitter\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,391 INFO mapred.SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210312032033_0056_m_000002_105\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,391 INFO mapred.SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210312032033_0056_m_000004_107\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,392 INFO executor.Executor: Finished task 2.0 in stage 56.0 (TID 105). 4588 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:36,392 INFO executor.Executor: Finished task 4.0 in stage 56.0 (TID 107). 4588 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:37,879 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032033_0056_m_000003_106' to s3a://creditmodel-mlsandbox-024103970757-ap-northeast-1/data-wrangler/credit-flow-2021-03-12-03-14-57/e4adff78-b977-4b75-b975-ef25e26f348f/default\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:37,879 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032033_0056_m_000003_106: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:37,880 INFO executor.Executor: Finished task 3.0 in stage 56.0 (TID 106). 4674 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:37,966 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032033_0056_m_000000_103' to s3a://creditmodel-mlsandbox-024103970757-ap-northeast-1/data-wrangler/credit-flow-2021-03-12-03-14-57/e4adff78-b977-4b75-b975-ef25e26f348f/default\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:37,966 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032033_0056_m_000000_103: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:37,967 INFO executor.Executor: Finished task 0.0 in stage 56.0 (TID 103). 4631 bytes result sent to driver\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:37,987 INFO output.FileOutputCommitter: Saved output of task 'attempt_20210312032033_0056_m_000001_104' to s3a://creditmodel-mlsandbox-024103970757-ap-northeast-1/data-wrangler/credit-flow-2021-03-12-03-14-57/e4adff78-b977-4b75-b975-ef25e26f348f/default\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:37,987 INFO mapred.SparkHadoopMapRedUtil: attempt_20210312032033_0056_m_000001_104: Committed\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:37,988 INFO executor.Executor: Finished task 1.0 in stage 56.0 (TID 104). 4674 bytes result sent to driver\u001b[0m\n",
      "\u001b[34mINFO:entrypoint:Processing Job Config: {\n",
      "    \"ProcessingJobArn\": \"arn:aws:sagemaker:ap-northeast-1:024103970757:processing-job/credit-flow-2021-03-12-03-14-57\",\n",
      "    \"ProcessingJobName\": \"credit-flow-2021-03-12-03-14-57\",\n",
      "    \"AppSpecification\": {\n",
      "        \"ImageUri\": \"649008135260.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-data-wrangler-container:1.3.0\",\n",
      "        \"ContainerEntrypoint\": null,\n",
      "        \"ContainerArguments\": [\n",
      "            \"--output-config '{\\\"e4adff78-b977-4b75-b975-ef25e26f348f.default\\\": {\\\"content_type\\\": \\\"CSV\\\"}}'\"\n",
      "        ]\n",
      "    },\n",
      "    \"ProcessingInputs\": [\n",
      "        {\n",
      "            \"InputName\": \"flow\",\n",
      "            \"AppManaged\": false,\n",
      "            \"S3Input\": {\n",
      "                \"LocalPath\": \"/opt/ml/processing/flow\",\n",
      "                \"S3Uri\": \"s3://creditmodel-mlsandbox-024103970757-ap-northeast-1/data-wrangler/credit-flow-2021-03-12-03-14-57/flow/credit-data.flow\",\n",
      "                \"S3DataDistributionType\": \"FullyReplicated\",\n",
      "                \"S3DataType\": \"S3Prefix\",\n",
      "                \"S3InputMode\": \"File\",\n",
      "                \"S3CompressionType\": \"None\",\n",
      "                \"S3DownloadMode\": \"StartOfJob\"\n",
      "            },\n",
      "            \"DatasetDefinition\": null\n",
      "        },\n",
      "        {\n",
      "            \"InputName\": \"german.csv\",\n",
      "            \"AppManaged\": false,\n",
      "            \"S3Input\": {\n",
      "                \"LocalPath\": \"/opt/ml/processing/german.csv\",\n",
      "                \"S3Uri\": \"s3://creditmodel-mlrawdata-024103970757-ap-northeast-1/german.csv\",\n",
      "                \"S3DataDistributionType\": \"FullyReplicated\",\n",
      "                \"S3DataType\": \"S3Prefix\",\n",
      "                \"S3InputMode\": \"File\",\n",
      "                \"S3CompressionType\": \"None\",\n",
      "                \"S3DownloadMode\": \"StartOfJob\"\n",
      "            },\n",
      "            \"DatasetDefinition\": null\n",
      "        }\n",
      "    ],\n",
      "    \"ProcessingOutputConfig\": {\n",
      "        \"Outputs\": [\n",
      "            {\n",
      "                \"OutputName\": \"e4adff78-b977-4b75-b975-ef25e26f348f.default\",\n",
      "                \"AppManaged\": false,\n",
      "                \"S3Output\": {\n",
      "                    \"LocalPath\": \"/opt/ml/processing/output\",\n",
      "                    \"S3Uri\": \"s3://creditmodel-mlsandbox-024103970757-ap-northeast-1/data-wrangler\",\n",
      "                    \"S3UploadMode\": \"EndOfJob\"\n",
      "                },\n",
      "                \"FeatureStoreOutput\": null\n",
      "            }\n",
      "        ],\n",
      "        \"KmsKeyId\": null\n",
      "    },\n",
      "    \"ProcessingResources\": {\n",
      "        \"ClusterConfig\": {\n",
      "            \"InstanceCount\": 1,\n",
      "            \"InstanceType\": \"ml.m5.4xlarge\",\n",
      "            \"VolumeSizeInGB\": 30,\n",
      "            \"VolumeKmsKeyId\": null\n",
      "        }\n",
      "    },\n",
      "    \"RoleArn\": \"arn:aws:iam::024103970757:role/mlopsintro-SageMakerExecutionRole-TK3Y6YQI58VH\",\n",
      "    \"StoppingCondition\": {\n",
      "        \"MaxRuntimeInSeconds\": 86400\n",
      "    }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[/var/log/yarn/userlogs/application_1615519194501_0001/container_1615519194501_0001_01_000002/stderr] 2021-03-12 03:20:39,437 INFO executor.YarnCoarseGrainedExecutorBackend: Driver commanded\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processing_job_name = util.uid.append_timestamp(\"credit-flow\")\n",
    "print(f\"Creating Processing job with name {processing_job_name}\")\n",
    "\n",
    "flow_upload_s3uri = f\"s3://{project_config.sandbox_bucket}/data-wrangler/{processing_job_name}/flow/credit-data.flow\"\n",
    "print(f\"Uploading flow file to {flow_upload_s3uri}\")\n",
    "\n",
    "# Outputs automatically create jobname/outputnames subfolders:\n",
    "base_output_s3uri = f\"s3://{project_config.sandbox_bucket}/data-wrangler\"\n",
    "print(f\"Storing results to {flow_output_s3uri}\")\n",
    "\n",
    "processor.run(\n",
    "    inputs=util.wrangler.create_processing_inputs(\"credit-data.flow\", flow_upload_s3uri),\n",
    "    outputs=[\n",
    "        util.wrangler.create_s3_output(target_output_name, base_output_s3uri),\n",
    "#         util.wrangler.create_featurestore_output(\n",
    "#             target_output_name,\n",
    "#             feature_group_name,\n",
    "#         )\n",
    "    ],\n",
    "    arguments=util.wrangler.create_container_arguments(target_output_name),\n",
    "    wait=True,\n",
    "    #logs=False,\n",
    "    job_name=processing_job_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://creditmodel-mlsandbox-024103970757-ap-northeast-1/data-wrangler/credit-flow-2021-03-12-03-14-57/e4adff78-b977-4b75-b975-ef25e26f348f/default/\n",
      "2021-03-12 03:20:38        839 part-00000-a0a68684-681c-42c1-a344-fac03278a44c-c000.csv\n",
      "2021-03-12 03:20:38      43345 part-00001-a0a68684-681c-42c1-a344-fac03278a44c-c000.csv\n",
      "2021-03-12 03:20:38      99965 part-00003-a0a68684-681c-42c1-a344-fac03278a44c-c000.csv\n"
     ]
    }
   ],
   "source": [
    "flow_output_s3uri = f\"{base_output_s3uri}/{processing_job_name}/{target_output_name.replace('.', '/')}/\"\n",
    "print(flow_output_s3uri)\n",
    "!aws s3 ls $flow_output_s3uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data-wrangler/credit-flow-2021-03-12-03-14-57/e4adff78-b977-4b75-b975-ef25e26f348f/default/part-00000-a0a68684-681c-42c1-a344-fac03278a44c-c000.csv\n",
      "Loading data-wrangler/credit-flow-2021-03-12-03-14-57/e4adff78-b977-4b75-b975-ef25e26f348f/default/part-00001-a0a68684-681c-42c1-a344-fac03278a44c-c000.csv\n",
      "Loading data-wrangler/credit-flow-2021-03-12-03-14-57/e4adff78-b977-4b75-b975-ef25e26f348f/default/part-00003-a0a68684-681c-42c1-a344-fac03278a44c-c000.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_default</th>\n",
       "      <th>duration_months</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>present_employment_yrs_lt</th>\n",
       "      <th>installment_rate_disp_income_pct</th>\n",
       "      <th>present_residence_since</th>\n",
       "      <th>age_in_years</th>\n",
       "      <th>n_existing_credits_this_bank</th>\n",
       "      <th>job_type</th>\n",
       "      <th>...</th>\n",
       "      <th>other_parties_none</th>\n",
       "      <th>other_parties_guarantor</th>\n",
       "      <th>other_parties_coapplicant</th>\n",
       "      <th>other_installment_plans_none</th>\n",
       "      <th>other_installment_plans_bank</th>\n",
       "      <th>other_installment_plans_stores</th>\n",
       "      <th>housing_own</th>\n",
       "      <th>housing_rent</th>\n",
       "      <th>housing_for_free</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>2225</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1082</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>3915</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>7485</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3384</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  credit_default duration_months credit_history credit_amount  \\\n",
       "0              1              36              3          2225   \n",
       "1              1              12              0          1082   \n",
       "2              1              27              2          3915   \n",
       "3              1              30              1          7485   \n",
       "4              1               6              4          3384   \n",
       "\n",
       "  present_employment_yrs_lt installment_rate_disp_income_pct  \\\n",
       "0                        10                                4   \n",
       "1                         4                                4   \n",
       "2                         4                                4   \n",
       "3                         0                                4   \n",
       "4                         4                                1   \n",
       "\n",
       "  present_residence_since age_in_years n_existing_credits_this_bank job_type  \\\n",
       "0                       4           57                            2        2   \n",
       "1                       4           48                            2        2   \n",
       "2                       2           36                            1        2   \n",
       "3                       1           53                            1        3   \n",
       "4                       4           44                            1        3   \n",
       "\n",
       "   ... other_parties_none other_parties_guarantor other_parties_coapplicant  \\\n",
       "0  ...                1.0                     0.0                       0.0   \n",
       "1  ...                1.0                     0.0                       0.0   \n",
       "2  ...                1.0                     0.0                       0.0   \n",
       "3  ...                1.0                     0.0                       0.0   \n",
       "4  ...                1.0                     0.0                       0.0   \n",
       "\n",
       "  other_installment_plans_none other_installment_plans_bank  \\\n",
       "0                          0.0                          1.0   \n",
       "1                          0.0                          1.0   \n",
       "2                          1.0                          0.0   \n",
       "3                          0.0                          1.0   \n",
       "4                          1.0                          0.0   \n",
       "\n",
       "  other_installment_plans_stores housing_own  housing_rent  housing_for_free  \\\n",
       "0                            0.0         0.0           0.0               1.0   \n",
       "1                            0.0         1.0           0.0               0.0   \n",
       "2                            0.0         1.0           0.0               0.0   \n",
       "3                            0.0         1.0           0.0               0.0   \n",
       "4                            0.0         0.0           1.0               0.0   \n",
       "\n",
       "   dataset  \n",
       "0    train  \n",
       "1    train  \n",
       "2    train  \n",
       "3    train  \n",
       "4    train  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = util.data.dataframe_from_s3_folder(flow_output_s3uri)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "test          0.152\n",
       "train         0.698\n",
       "validation    0.150\n",
       "Name: credit_default, dtype: float64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataset split is OK:\n",
    "dataset_lens = df.groupby([\"dataset\"])[\"credit_default\"].count()\n",
    "dataset_lens / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset     credit_default\n",
       "test        0                 0.697368\n",
       "            1                 0.302632\n",
       "train       0                 0.700573\n",
       "            1                 0.299427\n",
       "validation  0                 0.700000\n",
       "            1                 0.300000\n",
       "Name: credit_default, dtype: float64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check stratification has worked:\n",
    "df.groupby([\"dataset\", \"credit_default\"])[\"credit_default\"].count() / dataset_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset     gender_is_male\n",
       "test        0                 0.328947\n",
       "            1                 0.671053\n",
       "train       0                 0.312321\n",
       "            1                 0.687679\n",
       "validation  0                 0.280000\n",
       "            1                 0.720000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How about the distribution of non-stratified fields:\n",
    "df.groupby([\"dataset\", \"gender_is_male\"])[\"gender_is_male\"].count() / dataset_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data-wrangler/credit-flow-2021-03-12-03-14-57/e4adff78-b977-4b75-b975-ef25e26f348f/default/part-00000-a0a68684-681c-42c1-a344-fac03278a44c-c000.csv\n",
      "Loading data-wrangler/credit-flow-2021-03-12-03-14-57/e4adff78-b977-4b75-b975-ef25e26f348f/default/part-00001-a0a68684-681c-42c1-a344-fac03278a44c-c000.csv\n",
      "Loading data-wrangler/credit-flow-2021-03-12-03-14-57/e4adff78-b977-4b75-b975-ef25e26f348f/default/part-00003-a0a68684-681c-42c1-a344-fac03278a44c-c000.csv\n",
      "\n",
      "Split datasets out to:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': ['s3://creditmodel-mlsandbox-024103970757-ap-northeast-1/model-datasets/train/part0.csv'],\n",
       " 'validation': ['s3://creditmodel-mlsandbox-024103970757-ap-northeast-1/model-datasets/validation/part0.csv'],\n",
       " 'test': ['s3://creditmodel-mlsandbox-024103970757-ap-northeast-1/model-datasets/test/part0.csv']}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hack around Feature Store not being supported on EE platform:\n",
    "model_datasets_s3uri = f\"s3://{project_config.sandbox_bucket}/model-datasets\"\n",
    "\n",
    "model_datasets = util.data.mock_featurestore_dataset_split(\n",
    "    flow_output_s3uri,\n",
    "    model_datasets_s3uri,\n",
    "    dataset_label_col=\"dataset\",\n",
    "    datasets_with_headers=r\"train.*\",  # Only include headers on the 'train' set\n",
    ")\n",
    "\n",
    "print(f\"\\nSplit datasets out to:\")\n",
    "model_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an initial model with SageMaker XGBoost Algorithm\n",
    "\n",
    "- Query the feature store to realise separate training/val/test sets?\n",
    "- XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354813040037.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3\n"
     ]
    }
   ],
   "source": [
    "training_image = sagemaker.image_uris.retrieve(\"xgboost\", region=region, version=\"1.0-1\")\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: s3://creditmodel-mlsandbox-024103970757-ap-northeast-1/model-datasets/train\n",
      "Validation data: s3://creditmodel-mlsandbox-024103970757-ap-northeast-1/model-datasets/validation\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace '???' with the path where you saved your training file in S3\n",
    "train_uri = f\"{model_datasets_s3uri}/train\"\n",
    "print(f\"Training data: {train_uri}\")\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(train_uri, content_type=\"csv\")\n",
    "\n",
    "# TODO: Replace '???' with the path where you saved your training file in S3\n",
    "val_uri = f\"{model_datasets_s3uri}/validation\"\n",
    "print(f\"Validation data: {val_uri}\")\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(val_uri, content_type=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-12 03:23:19 Starting - Starting the training job."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-7a8f49282e12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# start a training (fitting) job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms3_input_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms3_input_validation\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1586\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1588\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1589\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3588\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLogState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOB_COMPLETE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instantiate an XGBoost estimator object\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=training_image,  # XGBoost algorithm container\n",
    "    instance_type=\"ml.m5.xlarge\",  # type of training instance\n",
    "    instance_count=1,  # number of instances to be used\n",
    "    role=sagemaker.get_execution_role(),  # Just use the current notebook's IAM role\n",
    "    max_run=20*60,  # Maximum allowed active runtime\n",
    "    use_spot_instances=True,  # Use spot instances to reduce cost\n",
    "    max_wait=30*60,  # Maximum clock time (including spot delays)\n",
    "    base_job_name=f\"{project_id}-xgboost\",\n",
    "    output_folder=f\"s3://{project_config.sandbox_bucket}/model-training\",  # TODO: Maybe not respecting this?\n",
    ")\n",
    "\n",
    "# define its hyperparameters\n",
    "estimator.set_hyperparameters(\n",
    "    num_round=150,  # int: [1,300]\n",
    "    max_depth=5,  # int: [1,10]\n",
    "    alpha=2.5,  # float: [0,5]\n",
    "    eta=0.5,  # float: [0,1]\n",
    "    objective=\"binary:logistic\",\n",
    ")\n",
    "\n",
    "# start a training (fitting) job\n",
    "estimator.fit({ \"train\": s3_input_train, \"validation\": s3_input_validation })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model with SageMaker Batch Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "\u001b[34m[2021-03-12:04:09:49:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-12:04:09:49:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-12:04:09:49:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2021/03/12 04:09:50 [crit] 19#19: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Mar/2021:04:09:50 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021/03/12 04:09:50 [crit] 19#19: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Mar/2021:04:09:50 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-03-12 04:09:50 +0000] [17] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2021-03-12 04:09:50 +0000] [17] [INFO] Listening at: unix:/tmp/gunicorn.sock (17)\u001b[0m\n",
      "\u001b[34m[2021-03-12 04:09:50 +0000] [17] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-03-12 04:09:50 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m[2021-03-12 04:09:50 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2021-03-12 04:09:50 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2021-03-12 04:09:50 +0000] [30] [INFO] Booting worker with pid: 30\u001b[0m\n",
      "\u001b[34m[2021-03-12:04:09:51:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Mar/2021:04:09:51 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Mar/2021:04:09:51 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-03-12:04:09:52:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-03-12:04:09:52:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [12/Mar/2021:04:09:52 +0000] \"POST /invocations HTTP/1.1\" 200 2981 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2021-03-12T04:09:51.940:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# TODO: Need to save the test file (at least) with no header!\n",
    "\n",
    "test_data_uri = f\"{model_datasets_s3uri}/test\"\n",
    "test_output_uri = f\"s3://{project_config.sandbox_bucket}/model-eval/{estimator.latest_training_job.name}\"\n",
    "\n",
    "transformer = estimator.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    output_path=test_output_uri,\n",
    "    accept=\"text/csv\",\n",
    "    assemble_with=\"Line\",\n",
    ")\n",
    "\n",
    "# calls that object's transform method to create a transform job\n",
    "transformer.transform(\n",
    "    data=test_data_uri,\n",
    "    data_type=\"S3Prefix\",\n",
    "    content_type=\"text/csv\",\n",
    "    split_type=\"Line\",\n",
    "    join_source=\"Input\",\n",
    "    input_filter=\"$[1:]\",\n",
    ")\n",
    "\n",
    "# wait=True by default right? Or transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-12 04:09:53      23505 model-eval/creditmodel-xgboost-2021-03-12-03-23-19-092/part0.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls --recursive $test_output_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model-eval/creditmodel-xgboost-2021-03-12-03-23-19-092/part0.csv.out\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_default</th>\n",
       "      <th>duration_months</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>present_employment_yrs_lt</th>\n",
       "      <th>installment_rate_disp_income_pct</th>\n",
       "      <th>present_residence_since</th>\n",
       "      <th>age_in_years</th>\n",
       "      <th>n_existing_credits_this_bank</th>\n",
       "      <th>job_type</th>\n",
       "      <th>...</th>\n",
       "      <th>other_parties_none</th>\n",
       "      <th>other_parties_guarantor</th>\n",
       "      <th>other_parties_coapplicant</th>\n",
       "      <th>other_installment_plans_none</th>\n",
       "      <th>other_installment_plans_bank</th>\n",
       "      <th>other_installment_plans_stores</th>\n",
       "      <th>housing_own</th>\n",
       "      <th>housing_rent</th>\n",
       "      <th>housing_for_free</th>\n",
       "      <th>credit_default_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>674</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1808</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>5096</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.418617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>939</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>4605</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.699565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_default  duration_months  credit_history  credit_amount  \\\n",
       "0               1               12               2            674   \n",
       "1               1               18               3           1808   \n",
       "2               1               48               4           5096   \n",
       "3               1               12               4            939   \n",
       "4               1               48               0           4605   \n",
       "\n",
       "   present_employment_yrs_lt  installment_rate_disp_income_pct  \\\n",
       "0                          7                                 4   \n",
       "1                          7                                 4   \n",
       "2                          4                                 2   \n",
       "3                          7                                 4   \n",
       "4                         10                                 3   \n",
       "\n",
       "   present_residence_since  age_in_years  n_existing_credits_this_bank  \\\n",
       "0                        1            20                             1   \n",
       "1                        1            22                             1   \n",
       "2                        3            30                             1   \n",
       "3                        2            28                             3   \n",
       "4                        4            24                             2   \n",
       "\n",
       "   job_type  ...  other_parties_none  other_parties_guarantor  \\\n",
       "0         2  ...                 1.0                      0.0   \n",
       "1         2  ...                 1.0                      0.0   \n",
       "2         3  ...                 1.0                      0.0   \n",
       "3         2  ...                 1.0                      0.0   \n",
       "4         2  ...                 1.0                      0.0   \n",
       "\n",
       "   other_parties_coapplicant  other_installment_plans_none  \\\n",
       "0                        0.0                           1.0   \n",
       "1                        0.0                           1.0   \n",
       "2                        0.0                           1.0   \n",
       "3                        0.0                           1.0   \n",
       "4                        0.0                           1.0   \n",
       "\n",
       "   other_installment_plans_bank  other_installment_plans_stores  housing_own  \\\n",
       "0                           0.0                             0.0          1.0   \n",
       "1                           0.0                             0.0          1.0   \n",
       "2                           0.0                             0.0          1.0   \n",
       "3                           0.0                             0.0          1.0   \n",
       "4                           0.0                             0.0          0.0   \n",
       "\n",
       "   housing_rent  housing_for_free  credit_default_pred  \n",
       "0           0.0               0.0             0.222375  \n",
       "1           0.0               0.0             0.023244  \n",
       "2           0.0               0.0             0.418617  \n",
       "3           0.0               0.0             0.151963  \n",
       "4           0.0               1.0             0.699565  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = list(filter(lambda c: c != \"dataset\", df.columns.tolist())) + [\"credit_default_pred\"]\n",
    "test_result_df = util.data.dataframe_from_s3_folder(test_output_uri, header=None, names=colnames)\n",
    "test_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "util.plotting.generate_classification_report(\n",
    "    y_real=test_result_df[\"credit_default\"],\n",
    "    y_predict_proba=test_result_df[\"credit_default_pred\"],\n",
    "    decision_threshold=0.5,\n",
    "    class_names_list=[\"good\", \"default\"],\n",
    "    title=\"Initial credit risk model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-1:102112518831:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
